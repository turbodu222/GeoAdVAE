{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab9eff0e",
   "metadata": {},
   "source": [
    "## MMD-MA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb20d40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/turbodu/miniconda3/envs/cross_modal_cpu_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded successfully:\n",
      "  - GEX data shape: (645, 2000)\n",
      "  - Morpho data shape: (645, 645)\n",
      "  - RNA family labels: 10 unique types\n",
      "\n",
      "Initializing MMD-DA model...\n",
      "Training MMD-DA model...\n",
      "Epoch [10/200], Loss: 0.149540\n",
      "Epoch [20/200], Loss: 0.119339\n",
      "Epoch [30/200], Loss: 0.124792\n",
      "Epoch [40/200], Loss: 0.099399\n",
      "Epoch [50/200], Loss: 0.115688\n",
      "Epoch [60/200], Loss: 0.072340\n",
      "Epoch [70/200], Loss: 0.091670\n",
      "Epoch [80/200], Loss: 0.088127\n",
      "Epoch [90/200], Loss: 0.078209\n",
      "Epoch [100/200], Loss: 0.091072\n",
      "Epoch [110/200], Loss: 0.100726\n",
      "Epoch [120/200], Loss: 0.100471\n",
      "Epoch [130/200], Loss: 0.085039\n",
      "Epoch [140/200], Loss: 0.074465\n",
      "Epoch [150/200], Loss: 0.057716\n",
      "Epoch [160/200], Loss: 0.075180\n",
      "Epoch [170/200], Loss: 0.063125\n",
      "Epoch [180/200], Loss: 0.062496\n",
      "Epoch [190/200], Loss: 0.078186\n",
      "Epoch [200/200], Loss: 0.068741\n",
      "\n",
      "Transforming data to common latent space...\n",
      "Encoded data shapes:\n",
      "  - GEX encoded: (645, 128)\n",
      "  - Morpho encoded: (645, 128)\n",
      "\n",
      "Calculating celltype accuracy...\n",
      "\n",
      "==================================================\n",
      "CELLTYPE ACCURACY RESULTS:\n",
      "==================================================\n",
      "Morpho to GEX accuracy: 0.2372\n",
      "GEX to Morpho accuracy: 0.1225\n",
      "Average accuracy: 0.1798\n",
      "==================================================\n",
      "\n",
      "Performing UMAP dimensionality reduction...\n",
      "  - Computing GEX UMAP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/turbodu/miniconda3/envs/cross_modal_cpu_env/lib/python3.8/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - GEX UMAP saved to: /home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/writeup20/MMDDA/gex_umap.csv\n",
      "  - Computing Morpho UMAP...\n",
      "  - Morpho UMAP saved to: /home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/writeup20/MMDDA/morpho_umap.csv\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "import umap\n",
    "import os\n",
    "\n",
    "\n",
    "class MMDLoss(nn.Module):\n",
    "    \"\"\"Maximum Mean Discrepancy Loss\"\"\"\n",
    "    def __init__(self, kernel_type='rbf', kernel_mul=2.0, kernel_num=5):\n",
    "        super(MMDLoss, self).__init__()\n",
    "        self.kernel_num = kernel_num\n",
    "        self.kernel_mul = kernel_mul\n",
    "        self.fix_sigma = None\n",
    "        self.kernel_type = kernel_type\n",
    "\n",
    "    def guassian_kernel(self, source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "        \"\"\"计算高斯核矩阵\"\"\"\n",
    "        n_samples = int(source.size()[0]) + int(target.size()[0])\n",
    "        total = torch.cat([source, target], dim=0)\n",
    "        \n",
    "        total0 = total.unsqueeze(0).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "        total1 = total.unsqueeze(1).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "        \n",
    "        L2_distance = ((total0-total1)**2).sum(2)\n",
    "        \n",
    "        if fix_sigma:\n",
    "            bandwidth = fix_sigma\n",
    "        else:\n",
    "            bandwidth = torch.sum(L2_distance.data) / (n_samples**2-n_samples)\n",
    "        \n",
    "        bandwidth /= kernel_mul ** (kernel_num // 2)\n",
    "        bandwidth_list = [bandwidth * (kernel_mul**i) for i in range(kernel_num)]\n",
    "        \n",
    "        kernel_val = [torch.exp(-L2_distance / bandwidth_temp) for bandwidth_temp in bandwidth_list]\n",
    "        return sum(kernel_val)\n",
    "\n",
    "    def forward(self, source, target):\n",
    "        batch_size = int(source.size()[0])\n",
    "        kernels = self.guassian_kernel(source, target, kernel_mul=self.kernel_mul, \n",
    "                                     kernel_num=self.kernel_num, fix_sigma=self.fix_sigma)\n",
    "        \n",
    "        XX = kernels[:batch_size, :batch_size]\n",
    "        YY = kernels[batch_size:, batch_size:]\n",
    "        XY = kernels[:batch_size, batch_size:]\n",
    "        YX = kernels[batch_size:, :batch_size]\n",
    "        \n",
    "        loss = torch.mean(XX + YY - XY - YX)\n",
    "        return loss\n",
    "\n",
    "\n",
    "class FeatureEncoder(nn.Module):\n",
    "    \"\"\"特征编码器网络\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim, dropout_rate=0.2):\n",
    "        super(FeatureEncoder, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "            layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "        \n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "\n",
    "class MMDDAIntegrator:\n",
    "    \"\"\"MMD-DA多模态数据整合器\"\"\"\n",
    "    \n",
    "    def __init__(self, gex_dim, morpho_dim, latent_dim=128, hidden_dims=None, \n",
    "                 device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.device = device\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [256, 128]\n",
    "        \n",
    "        # 创建编码器\n",
    "        self.gex_encoder = FeatureEncoder(gex_dim, hidden_dims, latent_dim).to(device)\n",
    "        self.morpho_encoder = FeatureEncoder(morpho_dim, hidden_dims, latent_dim).to(device)\n",
    "        \n",
    "        # MMD损失函数\n",
    "        self.mmd_loss = MMDLoss().to(device)\n",
    "        \n",
    "        # 优化器\n",
    "        self.optimizer = optim.Adam(\n",
    "            list(self.gex_encoder.parameters()) + list(self.morpho_encoder.parameters()),\n",
    "            lr=0.001, weight_decay=1e-5\n",
    "        )\n",
    "        \n",
    "        # 标准化器\n",
    "        self.gex_scaler = StandardScaler()\n",
    "        self.morpho_scaler = StandardScaler()\n",
    "        \n",
    "    def train(self, gex_data, morpho_data, epochs=100, batch_size=128, lambda_mmd=1.0, \n",
    "              verbose=True, reconstruction_loss=True):\n",
    "        \"\"\"训练MMD-DA模型\"\"\"\n",
    "        \n",
    "        # 数据标准化\n",
    "        gex_data_norm = self.gex_scaler.fit_transform(gex_data)\n",
    "        morpho_data_norm = self.morpho_scaler.fit_transform(morpho_data)\n",
    "        \n",
    "        # 转换为张量\n",
    "        gex_tensor = torch.FloatTensor(gex_data_norm).to(self.device)\n",
    "        morpho_tensor = torch.FloatTensor(morpho_data_norm).to(self.device)\n",
    "        \n",
    "        # 创建数据加载器\n",
    "        gex_dataset = TensorDataset(gex_tensor)\n",
    "        morpho_dataset = TensorDataset(morpho_tensor)\n",
    "        \n",
    "        gex_loader = DataLoader(gex_dataset, batch_size=batch_size, shuffle=True)\n",
    "        morpho_loader = DataLoader(morpho_dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        # 训练循环\n",
    "        losses = []\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0.0\n",
    "            num_batches = 0\n",
    "            \n",
    "            # 获取数据迭代器\n",
    "            gex_iter = iter(gex_loader)\n",
    "            morpho_iter = iter(morpho_loader)\n",
    "            \n",
    "            while True:\n",
    "                try:\n",
    "                    gex_batch = next(gex_iter)[0]\n",
    "                except StopIteration:\n",
    "                    gex_iter = iter(gex_loader)\n",
    "                    gex_batch = next(gex_iter)[0]\n",
    "                \n",
    "                try:\n",
    "                    morpho_batch = next(morpho_iter)[0]\n",
    "                except StopIteration:\n",
    "                    break\n",
    "                \n",
    "                # 确保批次大小一致\n",
    "                min_size = min(gex_batch.size(0), morpho_batch.size(0))\n",
    "                gex_batch = gex_batch[:min_size]\n",
    "                morpho_batch = morpho_batch[:min_size]\n",
    "                \n",
    "                # 前向传播\n",
    "                gex_encoded = self.gex_encoder(gex_batch)\n",
    "                morpho_encoded = self.morpho_encoder(morpho_batch)\n",
    "                \n",
    "                # 计算MMD损失\n",
    "                mmd_loss = self.mmd_loss(gex_encoded, morpho_encoded)\n",
    "                \n",
    "                total_loss = lambda_mmd * mmd_loss\n",
    "                \n",
    "                # 反向传播\n",
    "                self.optimizer.zero_grad()\n",
    "                total_loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                epoch_loss += total_loss.item()\n",
    "                num_batches += 1\n",
    "            \n",
    "            avg_loss = epoch_loss / num_batches\n",
    "            losses.append(avg_loss)\n",
    "            \n",
    "            if verbose and (epoch + 1) % 10 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.6f}')\n",
    "        \n",
    "        return losses\n",
    "    \n",
    "    def transform(self, gex_data, morpho_data):\n",
    "        \"\"\"将数据转换到共同的潜在空间\"\"\"\n",
    "        self.gex_encoder.eval()\n",
    "        self.morpho_encoder.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # 标准化\n",
    "            gex_data_norm = self.gex_scaler.transform(gex_data)\n",
    "            morpho_data_norm = self.morpho_scaler.transform(morpho_data)\n",
    "            \n",
    "            # 转换为张量\n",
    "            gex_tensor = torch.FloatTensor(gex_data_norm).to(self.device)\n",
    "            morpho_tensor = torch.FloatTensor(morpho_data_norm).to(self.device)\n",
    "            \n",
    "            # 编码\n",
    "            gex_encoded = self.gex_encoder(gex_tensor).cpu().numpy()\n",
    "            morpho_encoded = self.morpho_encoder(morpho_tensor).cpu().numpy()\n",
    "            \n",
    "        return gex_encoded, morpho_encoded\n",
    "\n",
    "\n",
    "def calculate_celltype_accuracy(gex_encoded, morpho_encoded, rna_family_labels, k=1):\n",
    "    \"\"\"计算细胞类型匹配准确率\"\"\"\n",
    "    \n",
    "    # 计算从Morpho到GEX的匹配率\n",
    "    nbrs_gex = NearestNeighbors(n_neighbors=k+1, algorithm='ball_tree').fit(gex_encoded)\n",
    "    distances_m2g, indices_m2g = nbrs_gex.kneighbors(morpho_encoded)\n",
    "    \n",
    "    # 获取最近邻的标签（排除自身）\n",
    "    nearest_gex_labels = rna_family_labels[indices_m2g[:, 1:]]  # 排除第一个（自身）\n",
    "    morpho_labels = rna_family_labels\n",
    "    \n",
    "    # 计算匹配数量\n",
    "    matches_m2g = 0\n",
    "    for i in range(len(morpho_labels)):\n",
    "        if morpho_labels[i] in nearest_gex_labels[i]:\n",
    "            matches_m2g += 1\n",
    "    \n",
    "    morpho_to_gex_accuracy = matches_m2g / len(morpho_labels)\n",
    "    \n",
    "    # 计算从GEX到Morpho的匹配率\n",
    "    nbrs_morpho = NearestNeighbors(n_neighbors=k+1, algorithm='ball_tree').fit(morpho_encoded)\n",
    "    distances_g2m, indices_g2m = nbrs_morpho.kneighbors(gex_encoded)\n",
    "    \n",
    "    nearest_morpho_labels = rna_family_labels[indices_g2m[:, 1:]]  # 排除第一个（自身）\n",
    "    gex_labels = rna_family_labels\n",
    "    \n",
    "    matches_g2m = 0\n",
    "    for i in range(len(gex_labels)):\n",
    "        if gex_labels[i] in nearest_morpho_labels[i]:\n",
    "            matches_g2m += 1\n",
    "    \n",
    "    gex_to_morpho_accuracy = matches_g2m / len(gex_labels)\n",
    "    \n",
    "    # 计算平均准确率\n",
    "    average_accuracy = (morpho_to_gex_accuracy + gex_to_morpho_accuracy) / 2\n",
    "    \n",
    "    return morpho_to_gex_accuracy, gex_to_morpho_accuracy, average_accuracy\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数：完整的MMD-DA整合流程\"\"\"\n",
    "    \n",
    "    # 数据路径\n",
    "    gene_expression_path = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/scala/exon_data_top2000.csv\"\n",
    "    morphology_path = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/scala/gw_dist.csv\"\n",
    "    rna_family_path = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/scala/rna_family_matched.csv\"\n",
    "    \n",
    "    # 输出路径\n",
    "    output_dir = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/writeup20/MMDDA/\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"Loading data...\")\n",
    "    \n",
    "    # 加载基因表达数据\n",
    "    gex_df = pd.read_csv(gene_expression_path, header=None)\n",
    "    gex_data = gex_df.iloc[:, 1:].to_numpy().astype(np.float32)\n",
    "    \n",
    "    # 加载形态学数据\n",
    "    morpho_df = pd.read_csv(morphology_path, header=0)\n",
    "    morpho_data = morpho_df.iloc[:, 1:].to_numpy().astype(np.float32)\n",
    "    \n",
    "    # 加载RNA family标签\n",
    "    try:\n",
    "        rna_df = pd.read_csv(rna_family_path, header=0)\n",
    "        if rna_df.shape[1] == 1:\n",
    "            rna_family_labels = rna_df.iloc[:, 0].values\n",
    "        else:\n",
    "            rna_family_labels = rna_df.iloc[:, 1].values\n",
    "        \n",
    "        # 确保所有数据长度一致\n",
    "        min_samples = min(len(gex_data), len(morpho_data), len(rna_family_labels))\n",
    "        gex_data = gex_data[:min_samples]\n",
    "        morpho_data = morpho_data[:min_samples]\n",
    "        rna_family_labels = rna_family_labels[:min_samples]\n",
    "        \n",
    "        print(f\"Data loaded successfully:\")\n",
    "        print(f\"  - GEX data shape: {gex_data.shape}\")\n",
    "        print(f\"  - Morpho data shape: {morpho_data.shape}\")\n",
    "        print(f\"  - RNA family labels: {len(np.unique(rna_family_labels))} unique types\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading RNA family labels: {e}\")\n",
    "        return\n",
    "    \n",
    "    # 创建并训练MMD-DA模型\n",
    "    print(\"\\nInitializing MMD-DA model...\")\n",
    "    integrator = MMDDAIntegrator(\n",
    "        gex_dim=gex_data.shape[1],\n",
    "        morpho_dim=morpho_data.shape[1],\n",
    "        latent_dim=128,\n",
    "        hidden_dims=[256, 128]\n",
    "    )\n",
    "    \n",
    "    print(\"Training MMD-DA model...\")\n",
    "    losses = integrator.train(\n",
    "        gex_data, morpho_data, \n",
    "        epochs=200, \n",
    "        batch_size=64, \n",
    "        lambda_mmd=1.0,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # 转换数据到共同空间\n",
    "    print(\"\\nTransforming data to common latent space...\")\n",
    "    gex_encoded, morpho_encoded = integrator.transform(gex_data, morpho_data)\n",
    "    \n",
    "    print(f\"Encoded data shapes:\")\n",
    "    print(f\"  - GEX encoded: {gex_encoded.shape}\")\n",
    "    print(f\"  - Morpho encoded: {morpho_encoded.shape}\")\n",
    "    \n",
    "    # 计算细胞类型匹配准确率\n",
    "    print(\"\\nCalculating celltype accuracy...\")\n",
    "    morpho_to_gex_acc, gex_to_morpho_acc, avg_acc = calculate_celltype_accuracy(\n",
    "        gex_encoded, morpho_encoded, rna_family_labels\n",
    "    )\n",
    "    \n",
    "    # 输出结果\n",
    "    print(f\"\\n\" + \"=\"*50)\n",
    "    print(f\"CELLTYPE ACCURACY RESULTS:\")\n",
    "    print(f\"=\"*50)\n",
    "    print(f\"Morpho to GEX accuracy: {morpho_to_gex_acc:.4f}\")\n",
    "    print(f\"GEX to Morpho accuracy: {gex_to_morpho_acc:.4f}\")\n",
    "    print(f\"Average accuracy: {avg_acc:.4f}\")\n",
    "    print(f\"=\"*50)\n",
    "    \n",
    "    # UMAP降维\n",
    "    print(\"\\nPerforming UMAP dimensionality reduction...\")\n",
    "    reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "    \n",
    "    # GEX UMAP\n",
    "    print(\"  - Computing GEX UMAP...\")\n",
    "    gex_umap = reducer.fit_transform(gex_encoded)\n",
    "    gex_umap_df = pd.DataFrame(gex_umap, columns=['UMAP1', 'UMAP2'])\n",
    "    gex_umap_path = os.path.join(output_dir, \"gex_umap.csv\")\n",
    "    gex_umap_df.to_csv(gex_umap_path, index=False)\n",
    "    print(f\"  - GEX UMAP saved to: {gex_umap_path}\")\n",
    "    \n",
    "    # Morpho UMAP\n",
    "    print(\"  - Computing Morpho UMAP...\")\n",
    "    morpho_umap = reducer.fit_transform(morpho_encoded)\n",
    "    morpho_umap_df = pd.DataFrame(morpho_umap, columns=['UMAP1', 'UMAP2'])\n",
    "    morpho_umap_path = os.path.join(output_dir, \"morpho_umap.csv\")\n",
    "    morpho_umap_df.to_csv(morpho_umap_path, index=False)\n",
    "    print(f\"  - Morpho UMAP saved to: {morpho_umap_path}\")\n",
    "    \n",
    "    print(\"\\nDone!\")\n",
    "    \n",
    "    return {\n",
    "        'morpho_to_gex_accuracy': morpho_to_gex_acc,\n",
    "        'gex_to_morpho_accuracy': gex_to_morpho_acc,\n",
    "        'average_accuracy': avg_acc,\n",
    "        'gex_encoded': gex_encoded,\n",
    "        'morpho_encoded': morpho_encoded,\n",
    "        'integrator': integrator\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d1d39b",
   "metadata": {},
   "source": [
    "## Cycel GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caa11ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "RNA family labels loaded: 10 unique types\n",
      "Data shapes - GEX: (645, 2000), Morpho: (645, 645)\n",
      "Starting CycleGAN training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 10/200 [00:51<17:55,  5.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200\n",
      "  G Loss: 12.3280, D Loss: 1.2921\n",
      "  GEX->Morpho Acc: 0.1907\n",
      "  Morpho->GEX Acc: 0.0899\n",
      "  Average Acc: 0.1403\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 20/200 [01:29<12:09,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/200\n",
      "  G Loss: 11.5809, D Loss: 1.1592\n",
      "  GEX->Morpho Acc: 0.1752\n",
      "  Morpho->GEX Acc: 0.1891\n",
      "  Average Acc: 0.1822\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 30/200 [02:09<12:28,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/200\n",
      "  G Loss: 12.1029, D Loss: 1.0447\n",
      "  GEX->Morpho Acc: 0.1597\n",
      "  Morpho->GEX Acc: 0.1054\n",
      "  Average Acc: 0.1326\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 40/200 [03:06<12:48,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200\n",
      "  G Loss: 12.4366, D Loss: 1.2524\n",
      "  GEX->Morpho Acc: 0.1674\n",
      "  Morpho->GEX Acc: 0.1070\n",
      "  Average Acc: 0.1372\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▌       | 50/200 [03:50<09:34,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/200\n",
      "  G Loss: 11.1682, D Loss: 1.5045\n",
      "  GEX->Morpho Acc: 0.1690\n",
      "  Morpho->GEX Acc: 0.1054\n",
      "  Average Acc: 0.1372\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|███       | 60/200 [04:32<09:50,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/200\n",
      "  G Loss: 11.2318, D Loss: 0.9618\n",
      "  GEX->Morpho Acc: 0.1612\n",
      "  Morpho->GEX Acc: 0.1814\n",
      "  Average Acc: 0.1713\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|███▌      | 70/200 [05:37<18:08,  8.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/200\n",
      "  G Loss: 11.0012, D Loss: 1.1030\n",
      "  GEX->Morpho Acc: 0.1271\n",
      "  Morpho->GEX Acc: 0.1147\n",
      "  Average Acc: 0.1209\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|████      | 80/200 [06:17<08:05,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200\n",
      "  G Loss: 10.9131, D Loss: 1.0765\n",
      "  GEX->Morpho Acc: 0.1349\n",
      "  Morpho->GEX Acc: 0.1023\n",
      "  Average Acc: 0.1186\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|████▌     | 90/200 [07:03<09:20,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/200\n",
      "  G Loss: 11.0908, D Loss: 1.2711\n",
      "  GEX->Morpho Acc: 0.2357\n",
      "  Morpho->GEX Acc: 0.1349\n",
      "  Average Acc: 0.1853\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|█████     | 100/200 [07:48<06:44,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200\n",
      "  G Loss: 11.7458, D Loss: 0.8237\n",
      "  GEX->Morpho Acc: 0.1442\n",
      "  Morpho->GEX Acc: 0.1178\n",
      "  Average Acc: 0.1310\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|█████▌    | 110/200 [08:30<05:51,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/200\n",
      "  G Loss: 11.6305, D Loss: 1.1920\n",
      "  GEX->Morpho Acc: 0.1628\n",
      "  Morpho->GEX Acc: 0.1535\n",
      "  Average Acc: 0.1581\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|██████    | 120/200 [09:16<06:53,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/200\n",
      "  G Loss: 10.9671, D Loss: 1.1249\n",
      "  GEX->Morpho Acc: 0.2202\n",
      "  Morpho->GEX Acc: 0.1008\n",
      "  Average Acc: 0.1605\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|██████▌   | 130/200 [09:58<04:35,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/200\n",
      "  G Loss: 12.1283, D Loss: 1.0639\n",
      "  GEX->Morpho Acc: 0.1287\n",
      "  Morpho->GEX Acc: 0.1860\n",
      "  Average Acc: 0.1574\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|███████   | 140/200 [10:37<04:08,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/200\n",
      "  G Loss: 11.5284, D Loss: 0.9027\n",
      "  GEX->Morpho Acc: 0.1628\n",
      "  Morpho->GEX Acc: 0.1054\n",
      "  Average Acc: 0.1341\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|███████▌  | 150/200 [11:22<03:23,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/200\n",
      "  G Loss: 13.1879, D Loss: 0.8193\n",
      "  GEX->Morpho Acc: 0.1767\n",
      "  Morpho->GEX Acc: 0.2357\n",
      "  Average Acc: 0.2062\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|████████  | 160/200 [12:54<11:34, 17.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/200\n",
      "  G Loss: 12.7722, D Loss: 0.5358\n",
      "  GEX->Morpho Acc: 0.1659\n",
      "  Morpho->GEX Acc: 0.1488\n",
      "  Average Acc: 0.1574\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 170/200 [13:48<02:16,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/200\n",
      "  G Loss: 12.1149, D Loss: 0.7979\n",
      "  GEX->Morpho Acc: 0.1876\n",
      "  Morpho->GEX Acc: 0.1426\n",
      "  Average Acc: 0.1651\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|█████████ | 180/200 [14:23<01:10,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/200\n",
      "  G Loss: 12.1058, D Loss: 0.8732\n",
      "  GEX->Morpho Acc: 0.1736\n",
      "  Morpho->GEX Acc: 0.2047\n",
      "  Average Acc: 0.1891\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|█████████▌| 190/200 [15:14<00:48,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190/200\n",
      "  G Loss: 13.6506, D Loss: 1.0646\n",
      "  GEX->Morpho Acc: 0.1597\n",
      "  Morpho->GEX Acc: 0.0837\n",
      "  Average Acc: 0.1217\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [15:59<00:00,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200\n",
      "  G Loss: 11.9456, D Loss: 0.8363\n",
      "  GEX->Morpho Acc: 0.1845\n",
      "  Morpho->GEX Acc: 0.1473\n",
      "  Average Acc: 0.1659\n",
      "--------------------------------------------------\n",
      "\n",
      "Getting latent space embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL RESULTS:\n",
      "============================================================\n",
      "GEX -> Morpho Accuracy: 0.1845\n",
      "Morpho -> GEX Accuracy: 0.1473\n",
      "Average Accuracy: 0.1659\n",
      "============================================================\n",
      "\n",
      "Performing UMAP dimensionality reduction...\n",
      "  - Computing GEX UMAP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/turbodu/miniconda3/envs/cross_modal_cpu_env/lib/python3.8/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - GEX UMAP saved to: /home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/writeup20/CycleGAN/gex_umap.csv\n",
      "  - Computing Morpho UMAP...\n",
      "  - Morpho UMAP saved to: /home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/writeup20/CycleGAN/morpho_umap.csv\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import accuracy_score\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"Generator network for CycleGAN\"\"\"\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim=512):\n",
    "        super(Generator, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Discriminator network for CycleGAN\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim=512):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim // 4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim // 4, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "class CycleGANIntegrator:\n",
    "    def __init__(self, gex_dim=2000, morpho_dim=645, latent_dim=256, device='cuda'):\n",
    "        self.device = device if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # 初始化生成器和判别器\n",
    "        self.G_gex2morpho = Generator(gex_dim, latent_dim).to(self.device)\n",
    "        self.G_morpho2gex = Generator(morpho_dim, latent_dim).to(self.device)\n",
    "        self.D_gex = Discriminator(latent_dim).to(self.device)\n",
    "        self.D_morpho = Discriminator(latent_dim).to(self.device)\n",
    "        \n",
    "        # 重建生成器（用于cycle consistency）\n",
    "        self.G_gex_recon = Generator(latent_dim, gex_dim).to(self.device)\n",
    "        self.G_morpho_recon = Generator(latent_dim, morpho_dim).to(self.device)\n",
    "        \n",
    "        # 损失函数\n",
    "        self.adversarial_loss = nn.BCELoss()\n",
    "        self.cycle_loss = nn.L1Loss()\n",
    "        self.identity_loss = nn.L1Loss()\n",
    "        \n",
    "        # 优化器\n",
    "        self.optimizer_G = optim.Adam(\n",
    "            list(self.G_gex2morpho.parameters()) + \n",
    "            list(self.G_morpho2gex.parameters()) +\n",
    "            list(self.G_gex_recon.parameters()) + \n",
    "            list(self.G_morpho_recon.parameters()),\n",
    "            lr=0.0002, betas=(0.5, 0.999)\n",
    "        )\n",
    "        self.optimizer_D = optim.Adam(\n",
    "            list(self.D_gex.parameters()) + list(self.D_morpho.parameters()),\n",
    "            lr=0.0002, betas=(0.5, 0.999)\n",
    "        )\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"加载数据\"\"\"\n",
    "        # 基因表达数据\n",
    "        gene_expression_path = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/scala/exon_data_top2000.csv\"\n",
    "        gex_df = pd.read_csv(gene_expression_path, header=None)\n",
    "        self.gex_data = gex_df.iloc[:, 1:].to_numpy().astype(np.float32)\n",
    "        \n",
    "        # 形态学数据\n",
    "        morphology_path = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/scala/gw_dist.csv\"\n",
    "        morpho_df = pd.read_csv(morphology_path, header=0)\n",
    "        self.morpho_data = morpho_df.iloc[:, 1:].to_numpy().astype(np.float32)\n",
    "        \n",
    "        # RNA family标签\n",
    "        rna_family_path = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/scala/rna_family_matched.csv\"\n",
    "        try:\n",
    "            rna_df = pd.read_csv(rna_family_path, header=0)\n",
    "            if rna_df.shape[1] == 1:\n",
    "                self.rna_family_labels = rna_df.iloc[:, 0].values\n",
    "            else:\n",
    "                self.rna_family_labels = rna_df.iloc[:, 1].values\n",
    "            \n",
    "            min_samples = min(len(self.gex_data), len(self.morpho_data))\n",
    "            self.rna_family_labels = self.rna_family_labels[:min_samples]\n",
    "            self.gex_data = self.gex_data[:min_samples]\n",
    "            self.morpho_data = self.morpho_data[:min_samples]\n",
    "            \n",
    "            print(f\"RNA family labels loaded: {len(np.unique(self.rna_family_labels))} unique types\")\n",
    "            print(f\"Data shapes - GEX: {self.gex_data.shape}, Morpho: {self.morpho_data.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not load RNA family labels: {e}\")\n",
    "            self.rna_family_labels = None\n",
    "        \n",
    "        # 数据标准化\n",
    "        self.gex_data = (self.gex_data - np.mean(self.gex_data, axis=0)) / (np.std(self.gex_data, axis=0) + 1e-8)\n",
    "        self.morpho_data = (self.morpho_data - np.mean(self.morpho_data, axis=0)) / (np.std(self.morpho_data, axis=0) + 1e-8)\n",
    "        \n",
    "        # 转换为tensor\n",
    "        self.gex_tensor = torch.FloatTensor(self.gex_data).to(self.device)\n",
    "        self.morpho_tensor = torch.FloatTensor(self.morpho_data).to(self.device)\n",
    "        \n",
    "    def train_epoch(self, epoch):\n",
    "        \"\"\"训练一个epoch\"\"\"\n",
    "        batch_size = 64\n",
    "        n_batches = len(self.gex_data) // batch_size\n",
    "        \n",
    "        total_g_loss = 0\n",
    "        total_d_loss = 0\n",
    "        \n",
    "        for i in range(n_batches):\n",
    "            start_idx = i * batch_size\n",
    "            end_idx = min((i + 1) * batch_size, len(self.gex_data))\n",
    "            \n",
    "            real_gex = self.gex_tensor[start_idx:end_idx]\n",
    "            real_morpho = self.morpho_tensor[start_idx:end_idx]\n",
    "            \n",
    "            batch_size_actual = real_gex.size(0)\n",
    "            valid = torch.ones(batch_size_actual, 1).to(self.device)\n",
    "            fake = torch.zeros(batch_size_actual, 1).to(self.device)\n",
    "            \n",
    "            # =======================\n",
    "            # 训练生成器\n",
    "            # =======================\n",
    "            self.optimizer_G.zero_grad()\n",
    "            \n",
    "            # GEX -> 潜在空间 -> Morpho -> 潜在空间 -> GEX (cycle)\n",
    "            gex_latent = self.G_gex2morpho(real_gex)\n",
    "            morpho_recon = self.G_morpho_recon(gex_latent)\n",
    "            gex_cycle = self.G_gex_recon(self.G_morpho2gex(morpho_recon))\n",
    "            \n",
    "            # Morpho -> 潜在空间 -> GEX -> 潜在空间 -> Morpho (cycle)\n",
    "            morpho_latent = self.G_morpho2gex(real_morpho)\n",
    "            gex_recon = self.G_gex_recon(morpho_latent)\n",
    "            morpho_cycle = self.G_morpho_recon(self.G_gex2morpho(gex_recon))\n",
    "            \n",
    "            # 对抗损失\n",
    "            d_gex_fake = self.D_gex(morpho_latent)\n",
    "            d_morpho_fake = self.D_morpho(gex_latent)\n",
    "            \n",
    "            loss_GAN_gex = self.adversarial_loss(d_gex_fake, valid)\n",
    "            loss_GAN_morpho = self.adversarial_loss(d_morpho_fake, valid)\n",
    "            \n",
    "            # Cycle consistency损失\n",
    "            loss_cycle_gex = self.cycle_loss(gex_cycle, real_gex)\n",
    "            loss_cycle_morpho = self.cycle_loss(morpho_cycle, real_morpho)\n",
    "            \n",
    "            # Identity损失（可选，帮助保持数据特性）\n",
    "            identity_gex = self.G_gex_recon(self.G_gex2morpho(real_gex))\n",
    "            identity_morpho = self.G_morpho_recon(self.G_morpho2gex(real_morpho))\n",
    "            loss_identity_gex = self.identity_loss(identity_gex, real_gex)\n",
    "            loss_identity_morpho = self.identity_loss(identity_morpho, real_morpho)\n",
    "            \n",
    "            # 总生成器损失\n",
    "            loss_G = (loss_GAN_gex + loss_GAN_morpho + \n",
    "                     10 * (loss_cycle_gex + loss_cycle_morpho) + \n",
    "                     0.5 * (loss_identity_gex + loss_identity_morpho))\n",
    "            \n",
    "            loss_G.backward()\n",
    "            self.optimizer_G.step()\n",
    "            \n",
    "            # =======================\n",
    "            # 训练判别器\n",
    "            # =======================\n",
    "            self.optimizer_D.zero_grad()\n",
    "            \n",
    "            # 真实数据\n",
    "            d_gex_real = self.D_gex(self.G_gex2morpho(real_gex).detach())\n",
    "            d_morpho_real = self.D_morpho(self.G_morpho2gex(real_morpho).detach())\n",
    "            \n",
    "            loss_D_real_gex = self.adversarial_loss(d_gex_real, valid)\n",
    "            loss_D_real_morpho = self.adversarial_loss(d_morpho_real, valid)\n",
    "            \n",
    "            # 假数据\n",
    "            d_gex_fake = self.D_gex(morpho_latent.detach())\n",
    "            d_morpho_fake = self.D_morpho(gex_latent.detach())\n",
    "            \n",
    "            loss_D_fake_gex = self.adversarial_loss(d_gex_fake, fake)\n",
    "            loss_D_fake_morpho = self.adversarial_loss(d_morpho_fake, fake)\n",
    "            \n",
    "            # 总判别器损失\n",
    "            loss_D = ((loss_D_real_gex + loss_D_fake_gex) + \n",
    "                     (loss_D_real_morpho + loss_D_fake_morpho)) / 2\n",
    "            \n",
    "            loss_D.backward()\n",
    "            self.optimizer_D.step()\n",
    "            \n",
    "            total_g_loss += loss_G.item()\n",
    "            total_d_loss += loss_D.item()\n",
    "        \n",
    "        return total_g_loss / n_batches, total_d_loss / n_batches\n",
    "    \n",
    "    def get_integrated_embeddings(self):\n",
    "        \"\"\"获取整合后的嵌入\"\"\"\n",
    "        self.G_gex2morpho.eval()\n",
    "        self.G_morpho2gex.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            gex_embeddings = self.G_gex2morpho(self.gex_tensor).cpu().numpy()\n",
    "            morpho_embeddings = self.G_morpho2gex(self.morpho_tensor).cpu().numpy()\n",
    "        \n",
    "        return gex_embeddings, morpho_embeddings\n",
    "    \n",
    "    def calculate_celltype_accuracy(self, gex_embeddings, morpho_embeddings):\n",
    "        \"\"\"计算细胞类型匹配准确率\"\"\"\n",
    "        if self.rna_family_labels is None:\n",
    "            print(\"No RNA family labels available for accuracy calculation\")\n",
    "            return None, None, None\n",
    "        \n",
    "        # 使用最近邻搜索\n",
    "        nbrs_morpho = NearestNeighbors(n_neighbors=1, metric='euclidean').fit(morpho_embeddings)\n",
    "        nbrs_gex = NearestNeighbors(n_neighbors=1, metric='euclidean').fit(gex_embeddings)\n",
    "        \n",
    "        # GEX到Morpho的匹配率\n",
    "        _, indices_gex2morpho = nbrs_morpho.kneighbors(gex_embeddings)\n",
    "        gex2morpho_matches = 0\n",
    "        for i, nearest_idx in enumerate(indices_gex2morpho.flatten()):\n",
    "            if self.rna_family_labels[i] == self.rna_family_labels[nearest_idx]:\n",
    "                gex2morpho_matches += 1\n",
    "        gex2morpho_accuracy = gex2morpho_matches / len(self.rna_family_labels)\n",
    "        \n",
    "        # Morpho到GEX的匹配率\n",
    "        _, indices_morpho2gex = nbrs_gex.kneighbors(morpho_embeddings)\n",
    "        morpho2gex_matches = 0\n",
    "        for i, nearest_idx in enumerate(indices_morpho2gex.flatten()):\n",
    "            if self.rna_family_labels[i] == self.rna_family_labels[nearest_idx]:\n",
    "                morpho2gex_matches += 1\n",
    "        morpho2gex_accuracy = morpho2gex_matches / len(self.rna_family_labels)\n",
    "        \n",
    "        # 平均匹配率\n",
    "        average_accuracy = (gex2morpho_accuracy + morpho2gex_accuracy) / 2\n",
    "        \n",
    "        return gex2morpho_accuracy, morpho2gex_accuracy, average_accuracy\n",
    "    \n",
    "    def train(self, epochs=200):\n",
    "        \"\"\"训练CycleGAN模型\"\"\"\n",
    "        print(\"Starting CycleGAN training...\")\n",
    "        \n",
    "        for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
    "            g_loss, d_loss = self.train_epoch(epoch)\n",
    "            \n",
    "            # 每10个epoch打印一次\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                gex_emb, morpho_emb = self.get_integrated_embeddings()\n",
    "                gex2morpho_acc, morpho2gex_acc, avg_acc = self.calculate_celltype_accuracy(gex_emb, morpho_emb)\n",
    "                \n",
    "                print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "                print(f\"  G Loss: {g_loss:.4f}, D Loss: {d_loss:.4f}\")\n",
    "                if avg_acc is not None:\n",
    "                    print(f\"  GEX->Morpho Acc: {gex2morpho_acc:.4f}\")\n",
    "                    print(f\"  Morpho->GEX Acc: {morpho2gex_acc:.4f}\")\n",
    "                    print(f\"  Average Acc: {avg_acc:.4f}\")\n",
    "                print(\"-\" * 50)\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    # 创建输出目录\n",
    "    output_dir = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/writeup20/CycleGAN/\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 初始化模型\n",
    "    integrator = CycleGANIntegrator(gex_dim=2000, morpho_dim=645, latent_dim=256)\n",
    "    \n",
    "    # 加载数据\n",
    "    integrator.load_data()\n",
    "    \n",
    "    # 训练模型\n",
    "    integrator.train(epochs=200)\n",
    "    \n",
    "    # 获取最终的整合嵌入\n",
    "    print(\"\\nGetting latent space embeddings...\")\n",
    "    final_gex_embeddings, final_morpho_embeddings = integrator.get_integrated_embeddings()\n",
    "    \n",
    "    # 计算最终准确率\n",
    "    final_gex2morpho_acc, final_morpho2gex_acc, final_avg_acc = integrator.calculate_celltype_accuracy(\n",
    "        final_gex_embeddings, final_morpho_embeddings\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL RESULTS:\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"GEX -> Morpho Accuracy: {final_gex2morpho_acc:.4f}\")\n",
    "    print(f\"Morpho -> GEX Accuracy: {final_morpho2gex_acc:.4f}\")\n",
    "    print(f\"Average Accuracy: {final_avg_acc:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # UMAP降维\n",
    "    print(\"\\nPerforming UMAP dimensionality reduction...\")\n",
    "    reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "    \n",
    "    # GEX UMAP\n",
    "    print(\"  - Computing GEX UMAP...\")\n",
    "    gex_umap = reducer.fit_transform(final_gex_embeddings)\n",
    "    gex_umap_df = pd.DataFrame(gex_umap, columns=['UMAP1', 'UMAP2'])\n",
    "    gex_umap_path = os.path.join(output_dir, \"gex_umap.csv\")\n",
    "    gex_umap_df.to_csv(gex_umap_path, index=False)\n",
    "    print(f\"  - GEX UMAP saved to: {gex_umap_path}\")\n",
    "    \n",
    "    # Morpho UMAP\n",
    "    print(\"  - Computing Morpho UMAP...\")\n",
    "    morpho_umap = reducer.fit_transform(final_morpho_embeddings)\n",
    "    morpho_umap_df = pd.DataFrame(morpho_umap, columns=['UMAP1', 'UMAP2'])\n",
    "    morpho_umap_path = os.path.join(output_dir, \"morpho_umap.csv\")\n",
    "    morpho_umap_df.to_csv(morpho_umap_path, index=False)\n",
    "    print(f\"  - Morpho UMAP saved to: {morpho_umap_path}\")\n",
    "    \n",
    "    print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902d6e5e",
   "metadata": {},
   "source": [
    "## DCCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f69a45b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded successfully:\n",
      "  - GEX data shape: (645, 2000)\n",
      "  - Morpho data shape: (645, 645)\n",
      "  - RNA family labels: 10 unique types\n",
      "\n",
      "Initializing DCCA model...\n",
      "Training DCCA model...\n",
      "Preprocessing data...\n",
      "Starting DCCA training for 200 epochs...\n",
      "Epoch [20/200], Loss: -6086.182886, Correlation: 0.787640, Best: 0.791076\n",
      "Epoch [40/200], Loss: -6238.226270, Correlation: 0.832393, Best: 0.832393\n",
      "Epoch [60/200], Loss: -6286.326758, Correlation: 0.839704, Best: 0.840527\n",
      "Epoch [80/200], Loss: -6304.940503, Correlation: 0.843580, Best: 0.850997\n",
      "Epoch [100/200], Loss: -6337.102148, Correlation: 0.853867, Best: 0.860918\n",
      "Epoch [120/200], Loss: -6373.642456, Correlation: 0.858300, Best: 0.861411\n",
      "Epoch [140/200], Loss: -6463.071997, Correlation: 0.867312, Best: 0.867312\n",
      "Epoch [160/200], Loss: -6494.428760, Correlation: 0.869706, Best: 0.871038\n",
      "Epoch [180/200], Loss: -6484.048901, Correlation: 0.870034, Best: 0.871038\n",
      "Epoch [200/200], Loss: -6593.796240, Correlation: 0.879479, Best: 0.882477\n",
      "Loaded best model with correlation: 0.882477\n",
      "\n",
      "Transforming data to DCCA representation space...\n",
      "Encoded data shapes:\n",
      "  - GEX encoded: (645, 64)\n",
      "  - Morpho encoded: (645, 64)\n",
      "\n",
      "Calculating celltype accuracy...\n",
      "\n",
      "============================================================\n",
      "DCCA INTEGRATION RESULTS:\n",
      "============================================================\n",
      "  Morpho to GEX accuracy: 0.1519\n",
      "  GEX to Morpho accuracy: 0.1736\n",
      "  Average accuracy: 0.1628\n",
      "============================================================\n",
      "\n",
      "Performing UMAP dimensionality reduction...\n",
      "  - Computing GEX UMAP...\n",
      "  - GEX UMAP saved to: /home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/writeup20/DCCA/gex_umap.csv\n",
      "  - Computing Morpho UMAP...\n",
      "  - Morpho UMAP saved to: /home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/writeup20/DCCA/morpho_umap.csv\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import umap\n",
    "import os\n",
    "from scipy.linalg import sqrtm, inv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class DCCAEncoder(nn.Module):\n",
    "    \"\"\"DCCA编码器网络\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim, dropout_rate=0.1):\n",
    "        super(DCCAEncoder, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for i, hidden_dim in enumerate(hidden_dims):\n",
    "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "            layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            if i < len(hidden_dims) - 1:\n",
    "                layers.append(nn.Dropout(dropout_rate))\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "        \n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "        \n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight, gain=0.1)\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, nn.BatchNorm1d):\n",
    "            nn.init.constant_(module.weight, 1)\n",
    "            nn.init.constant_(module.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if torch.isnan(x).any():\n",
    "            x = torch.nan_to_num(x, nan=0.0)\n",
    "        \n",
    "        output = self.encoder(x)\n",
    "        \n",
    "        if torch.isnan(output).any():\n",
    "            output = torch.nan_to_num(output, nan=0.0)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "class DCCALoss(nn.Module):\n",
    "    \"\"\"DCCA损失函数\"\"\"\n",
    "    def __init__(self, outdim_size, use_all_singular_values=False, regularization=1e-3):\n",
    "        super(DCCALoss, self).__init__()\n",
    "        self.outdim_size = outdim_size\n",
    "        self.use_all_singular_values = use_all_singular_values\n",
    "        self.regularization = regularization\n",
    "\n",
    "    def forward(self, H1, H2):\n",
    "        batch_size = H1.size(0)\n",
    "        \n",
    "        if torch.isnan(H1).any() or torch.isnan(H2).any():\n",
    "            return torch.tensor(0.01, device=H1.device, requires_grad=True)\n",
    "        \n",
    "        if torch.isinf(H1).any() or torch.isinf(H2).any():\n",
    "            return torch.tensor(0.01, device=H1.device, requires_grad=True)\n",
    "        \n",
    "        H1_centered = H1 - H1.mean(dim=0, keepdim=True)\n",
    "        H2_centered = H2 - H2.mean(dim=0, keepdim=True)\n",
    "        \n",
    "        if H1_centered.std() < 1e-8 or H2_centered.std() < 1e-8:\n",
    "            return torch.tensor(0.01, device=H1.device, requires_grad=True)\n",
    "        \n",
    "        try:\n",
    "            SigmaHat12 = torch.matmul(H1_centered.t(), H2_centered) / (batch_size - 1)\n",
    "            SigmaHat11 = torch.matmul(H1_centered.t(), H1_centered) / (batch_size - 1)\n",
    "            SigmaHat22 = torch.matmul(H2_centered.t(), H2_centered) / (batch_size - 1)\n",
    "            \n",
    "            SigmaHat11 += self.regularization * torch.eye(H1.size(1), device=H1.device)\n",
    "            SigmaHat22 += self.regularization * torch.eye(H2.size(1), device=H2.device)\n",
    "            \n",
    "            if torch.isnan(SigmaHat11).any() or torch.isnan(SigmaHat22).any() or torch.isnan(SigmaHat12).any():\n",
    "                return torch.tensor(0.01, device=H1.device, requires_grad=True)\n",
    "            \n",
    "            try:\n",
    "                L11 = torch.linalg.cholesky(SigmaHat11)\n",
    "                SigmaHat11_inv_sqrt = torch.cholesky_inverse(L11)\n",
    "                \n",
    "                L22 = torch.linalg.cholesky(SigmaHat22)\n",
    "                SigmaHat22_inv_sqrt = torch.cholesky_inverse(L22)\n",
    "                \n",
    "            except RuntimeError:\n",
    "                eigenvalues1, eigenvectors1 = torch.linalg.eigh(SigmaHat11)\n",
    "                eigenvalues1 = torch.clamp(eigenvalues1, min=1e-6)\n",
    "                SigmaHat11_inv_sqrt = torch.matmul(\n",
    "                    torch.matmul(eigenvectors1, torch.diag(1.0 / torch.sqrt(eigenvalues1))),\n",
    "                    eigenvectors1.t()\n",
    "                )\n",
    "                \n",
    "                eigenvalues2, eigenvectors2 = torch.linalg.eigh(SigmaHat22)\n",
    "                eigenvalues2 = torch.clamp(eigenvalues2, min=1e-6)\n",
    "                SigmaHat22_inv_sqrt = torch.matmul(\n",
    "                    torch.matmul(eigenvectors2, torch.diag(1.0 / torch.sqrt(eigenvalues2))),\n",
    "                    eigenvectors2.t()\n",
    "                )\n",
    "            \n",
    "            T = torch.matmul(torch.matmul(SigmaHat11_inv_sqrt, SigmaHat12), SigmaHat22_inv_sqrt)\n",
    "            \n",
    "            if torch.isnan(T).any() or torch.isinf(T).any():\n",
    "                return torch.tensor(0.01, device=H1.device, requires_grad=True)\n",
    "            \n",
    "            U, S, V = torch.linalg.svd(T)\n",
    "            \n",
    "            if torch.isnan(S).any() or torch.isinf(S).any():\n",
    "                return torch.tensor(0.01, device=H1.device, requires_grad=True)\n",
    "            \n",
    "            if self.use_all_singular_values:\n",
    "                corr = torch.sum(S)\n",
    "            else:\n",
    "                corr = torch.sum(S[:min(self.outdim_size, len(S))])\n",
    "            \n",
    "            return -corr\n",
    "            \n",
    "        except Exception as e:\n",
    "            return torch.tensor(0.01, device=H1.device, requires_grad=True)\n",
    "\n",
    "\n",
    "class DCCAIntegrator:\n",
    "    \"\"\"DCCA多模态数据整合器\"\"\"\n",
    "    \n",
    "    def __init__(self, gex_dim, morpho_dim, latent_dim=64, hidden_dims=None, \n",
    "                 use_all_singular_values=False, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.device = device\n",
    "        self.latent_dim = latent_dim\n",
    "        self.use_all_singular_values = use_all_singular_values\n",
    "        \n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [256, 128]\n",
    "        \n",
    "        self.gex_encoder = DCCAEncoder(gex_dim, hidden_dims, latent_dim).to(device)\n",
    "        self.morpho_encoder = DCCAEncoder(morpho_dim, hidden_dims, latent_dim).to(device)\n",
    "        \n",
    "        self.dcca_loss = DCCALoss(latent_dim, use_all_singular_values).to(device)\n",
    "        \n",
    "        self.optimizer = optim.Adam(\n",
    "            list(self.gex_encoder.parameters()) + list(self.morpho_encoder.parameters()),\n",
    "            lr=0.001, weight_decay=1e-4\n",
    "        )\n",
    "        \n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer, mode='max', patience=20, factor=0.5, verbose=True\n",
    "        )\n",
    "        \n",
    "        self.gex_scaler = StandardScaler()\n",
    "        self.morpho_scaler = StandardScaler()\n",
    "        \n",
    "        self.losses = []\n",
    "        self.correlations = []\n",
    "        \n",
    "    def compute_correlation(self, H1, H2):\n",
    "        \"\"\"计算两个表示之间的典型相关性\"\"\"\n",
    "        H1_centered = H1 - H1.mean(dim=0)\n",
    "        H2_centered = H2 - H2.mean(dim=0)\n",
    "        \n",
    "        correlation_matrix = torch.corrcoef(torch.cat([H1_centered.t(), H2_centered.t()], dim=0))\n",
    "        cross_corr = correlation_matrix[:H1.size(1), H1.size(1):]\n",
    "        \n",
    "        U, S, V = torch.linalg.svd(cross_corr)\n",
    "        \n",
    "        if self.use_all_singular_values:\n",
    "            return torch.mean(S)\n",
    "        else:\n",
    "            return torch.mean(S[:min(self.latent_dim, len(S))])\n",
    "    \n",
    "    def train(self, gex_data, morpho_data, epochs=200, batch_size=128, verbose=True):\n",
    "        \"\"\"训练DCCA模型\"\"\"\n",
    "        \n",
    "        print(\"Preprocessing data...\")\n",
    "        \n",
    "        gex_data = np.nan_to_num(gex_data, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "        morpho_data = np.nan_to_num(morpho_data, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "        \n",
    "        gex_data_norm = self.gex_scaler.fit_transform(gex_data)\n",
    "        morpho_data_norm = self.morpho_scaler.fit_transform(morpho_data)\n",
    "        \n",
    "        gex_data_norm = np.nan_to_num(gex_data_norm, nan=0.0)\n",
    "        morpho_data_norm = np.nan_to_num(morpho_data_norm, nan=0.0)\n",
    "        \n",
    "        gex_tensor = torch.FloatTensor(gex_data_norm).to(self.device)\n",
    "        morpho_tensor = torch.FloatTensor(morpho_data_norm).to(self.device)\n",
    "        \n",
    "        dataset = TensorDataset(gex_tensor, morpho_tensor)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "        \n",
    "        print(f\"Starting DCCA training for {epochs} epochs...\")\n",
    "        \n",
    "        best_correlation = -1\n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0.0\n",
    "            epoch_corr = 0.0\n",
    "            num_batches = 0\n",
    "            \n",
    "            self.gex_encoder.train()\n",
    "            self.morpho_encoder.train()\n",
    "            \n",
    "            for batch_idx, (gex_batch, morpho_batch) in enumerate(dataloader):\n",
    "                if gex_batch.size(0) < 8:\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    gex_encoded = self.gex_encoder(gex_batch)\n",
    "                    morpho_encoded = self.morpho_encoder(morpho_batch)\n",
    "                    \n",
    "                    if torch.isnan(gex_encoded).any() or torch.isnan(morpho_encoded).any():\n",
    "                        continue\n",
    "                    \n",
    "                    loss = self.dcca_loss(gex_encoded, morpho_encoded)\n",
    "                    \n",
    "                    if torch.isnan(loss) or torch.isinf(loss):\n",
    "                        continue\n",
    "                    \n",
    "                    self.optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    \n",
    "                    torch.nn.utils.clip_grad_norm_(\n",
    "                        list(self.gex_encoder.parameters()) + list(self.morpho_encoder.parameters()), \n",
    "                        max_norm=1.0\n",
    "                    )\n",
    "                    \n",
    "                    self.optimizer.step()\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        correlation = self.compute_correlation(gex_encoded, morpho_encoded)\n",
    "                        if not torch.isnan(correlation):\n",
    "                            epoch_corr += correlation.item()\n",
    "                    \n",
    "                    epoch_loss += loss.item()\n",
    "                    num_batches += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    continue\n",
    "            \n",
    "            if num_batches == 0:\n",
    "                continue\n",
    "            \n",
    "            avg_loss = epoch_loss / num_batches\n",
    "            avg_corr = epoch_corr / num_batches\n",
    "            \n",
    "            self.losses.append(avg_loss)\n",
    "            self.correlations.append(avg_corr)\n",
    "            \n",
    "            self.scheduler.step(avg_corr)\n",
    "            \n",
    "            if avg_corr > best_correlation:\n",
    "                best_correlation = avg_corr\n",
    "                patience_counter = 0\n",
    "                self.best_gex_encoder_state = self.gex_encoder.state_dict().copy()\n",
    "                self.best_morpho_encoder_state = self.morpho_encoder.state_dict().copy()\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            if verbose and (epoch + 1) % 20 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.6f}, '\n",
    "                      f'Correlation: {avg_corr:.6f}, Best: {best_correlation:.6f}')\n",
    "            \n",
    "            if patience_counter >= 50:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "        \n",
    "        if hasattr(self, 'best_gex_encoder_state'):\n",
    "            self.gex_encoder.load_state_dict(self.best_gex_encoder_state)\n",
    "            self.morpho_encoder.load_state_dict(self.best_morpho_encoder_state)\n",
    "            print(f\"Loaded best model with correlation: {best_correlation:.6f}\")\n",
    "        \n",
    "        return self.losses, self.correlations\n",
    "    \n",
    "    def transform(self, gex_data, morpho_data):\n",
    "        \"\"\"将数据转换到DCCA学习的表示空间\"\"\"\n",
    "        self.gex_encoder.eval()\n",
    "        self.morpho_encoder.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            gex_data_norm = self.gex_scaler.transform(gex_data)\n",
    "            morpho_data_norm = self.morpho_scaler.transform(morpho_data)\n",
    "            \n",
    "            gex_tensor = torch.FloatTensor(gex_data_norm).to(self.device)\n",
    "            morpho_tensor = torch.FloatTensor(morpho_data_norm).to(self.device)\n",
    "            \n",
    "            gex_encoded = self.gex_encoder(gex_tensor).cpu().numpy()\n",
    "            morpho_encoded = self.morpho_encoder(morpho_tensor).cpu().numpy()\n",
    "            \n",
    "        return gex_encoded, morpho_encoded\n",
    "\n",
    "\n",
    "def calculate_celltype_accuracy(gex_encoded, morpho_encoded, rna_family_labels, k=1):\n",
    "    \"\"\"计算细胞类型匹配准确率\"\"\"\n",
    "    \n",
    "    nbrs_gex = NearestNeighbors(n_neighbors=k+1, algorithm='ball_tree').fit(gex_encoded)\n",
    "    distances_m2g, indices_m2g = nbrs_gex.kneighbors(morpho_encoded)\n",
    "    \n",
    "    nearest_gex_indices = indices_m2g[:, 0]\n",
    "    nearest_gex_labels = rna_family_labels[nearest_gex_indices]\n",
    "    morpho_labels = rna_family_labels\n",
    "    \n",
    "    matches_m2g = np.sum(morpho_labels == nearest_gex_labels)\n",
    "    morpho_to_gex_accuracy = matches_m2g / len(morpho_labels)\n",
    "    \n",
    "    nbrs_morpho = NearestNeighbors(n_neighbors=k+1, algorithm='ball_tree').fit(morpho_encoded)\n",
    "    distances_g2m, indices_g2m = nbrs_morpho.kneighbors(gex_encoded)\n",
    "    \n",
    "    nearest_morpho_indices = indices_g2m[:, 0]\n",
    "    nearest_morpho_labels = rna_family_labels[nearest_morpho_indices]\n",
    "    gex_labels = rna_family_labels\n",
    "    \n",
    "    matches_g2m = np.sum(gex_labels == nearest_morpho_labels)\n",
    "    gex_to_morpho_accuracy = matches_g2m / len(gex_labels)\n",
    "    \n",
    "    average_accuracy = (morpho_to_gex_accuracy + gex_to_morpho_accuracy) / 2\n",
    "    \n",
    "    return morpho_to_gex_accuracy, gex_to_morpho_accuracy, average_accuracy\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数：完整的DCCA整合流程\"\"\"\n",
    "    \n",
    "    # 数据路径\n",
    "    gene_expression_path = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/scala/exon_data_top2000.csv\"\n",
    "    morphology_path = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/scala/gw_dist.csv\"\n",
    "    rna_family_path = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/scala/rna_family_matched.csv\"\n",
    "    \n",
    "    # 输出路径\n",
    "    output_dir = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/writeup20/DCCA/\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"Loading data...\")\n",
    "    \n",
    "    # 加载基因表达数据\n",
    "    gex_df = pd.read_csv(gene_expression_path, header=None)\n",
    "    gex_data = gex_df.iloc[:, 1:].to_numpy().astype(np.float32)\n",
    "    \n",
    "    # 加载形态学数据\n",
    "    morpho_df = pd.read_csv(morphology_path, header=0)\n",
    "    morpho_data = morpho_df.iloc[:, 1:].to_numpy().astype(np.float32)\n",
    "    \n",
    "    # 加载RNA family标签\n",
    "    try:\n",
    "        rna_df = pd.read_csv(rna_family_path, header=0)\n",
    "        if rna_df.shape[1] == 1:\n",
    "            rna_family_labels = rna_df.iloc[:, 0].values\n",
    "        else:\n",
    "            rna_family_labels = rna_df.iloc[:, 1].values\n",
    "        \n",
    "        min_samples = min(len(gex_data), len(morpho_data), len(rna_family_labels))\n",
    "        gex_data = gex_data[:min_samples]\n",
    "        morpho_data = morpho_data[:min_samples]\n",
    "        rna_family_labels = rna_family_labels[:min_samples]\n",
    "        \n",
    "        print(f\"Data loaded successfully:\")\n",
    "        print(f\"  - GEX data shape: {gex_data.shape}\")\n",
    "        print(f\"  - Morpho data shape: {morpho_data.shape}\")\n",
    "        print(f\"  - RNA family labels: {len(np.unique(rna_family_labels))} unique types\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading RNA family labels: {e}\")\n",
    "        return\n",
    "    \n",
    "    # 创建并训练DCCA模型\n",
    "    print(\"\\nInitializing DCCA model...\")\n",
    "    integrator = DCCAIntegrator(\n",
    "        gex_dim=gex_data.shape[1],\n",
    "        morpho_dim=morpho_data.shape[1],\n",
    "        latent_dim=64,\n",
    "        hidden_dims=[256, 128],\n",
    "        use_all_singular_values=False\n",
    "    )\n",
    "    \n",
    "    print(\"Training DCCA model...\")\n",
    "    losses, correlations = integrator.train(\n",
    "        gex_data, morpho_data,\n",
    "        epochs=200,\n",
    "        batch_size=32,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # 转换数据到DCCA表示空间\n",
    "    print(\"\\nTransforming data to DCCA representation space...\")\n",
    "    gex_encoded, morpho_encoded = integrator.transform(gex_data, morpho_data)\n",
    "    \n",
    "    print(f\"Encoded data shapes:\")\n",
    "    print(f\"  - GEX encoded: {gex_encoded.shape}\")\n",
    "    print(f\"  - Morpho encoded: {morpho_encoded.shape}\")\n",
    "    \n",
    "    # 计算细胞类型匹配准确率\n",
    "    print(\"\\nCalculating celltype accuracy...\")\n",
    "    morpho_to_gex_acc, gex_to_morpho_acc, avg_acc = calculate_celltype_accuracy(\n",
    "        gex_encoded, morpho_encoded, rna_family_labels\n",
    "    )\n",
    "    \n",
    "    # 输出结果\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(f\"DCCA INTEGRATION RESULTS:\")\n",
    "    print(f\"=\"*60)\n",
    "    print(f\"  Morpho to GEX accuracy: {morpho_to_gex_acc:.4f}\")\n",
    "    print(f\"  GEX to Morpho accuracy: {gex_to_morpho_acc:.4f}\")\n",
    "    print(f\"  Average accuracy: {avg_acc:.4f}\")\n",
    "    print(f\"=\"*60)\n",
    "    \n",
    "    # UMAP降维\n",
    "    print(\"\\nPerforming UMAP dimensionality reduction...\")\n",
    "    reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "    \n",
    "    # GEX UMAP\n",
    "    print(\"  - Computing GEX UMAP...\")\n",
    "    gex_umap = reducer.fit_transform(gex_encoded)\n",
    "    gex_umap_df = pd.DataFrame(gex_umap, columns=['UMAP1', 'UMAP2'])\n",
    "    gex_umap_path = os.path.join(output_dir, \"gex_umap.csv\")\n",
    "    gex_umap_df.to_csv(gex_umap_path, index=False)\n",
    "    print(f\"  - GEX UMAP saved to: {gex_umap_path}\")\n",
    "    \n",
    "    # Morpho UMAP\n",
    "    print(\"  - Computing Morpho UMAP...\")\n",
    "    morpho_umap = reducer.fit_transform(morpho_encoded)\n",
    "    morpho_umap_df = pd.DataFrame(morpho_umap, columns=['UMAP1', 'UMAP2'])\n",
    "    morpho_umap_path = os.path.join(output_dir, \"morpho_umap.csv\")\n",
    "    morpho_umap_df.to_csv(morpho_umap_path, index=False)\n",
    "    print(f\"  - Morpho UMAP saved to: {morpho_umap_path}\")\n",
    "    \n",
    "    print(\"\\nDone!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc043606",
   "metadata": {},
   "source": [
    "## UnionCom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "307216ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "RNA family labels loaded: 10 unique types\n",
      "Data shapes - GEX: (645, 2000), Morpho: (645, 645)\n",
      "Building KNN graphs...\n",
      "KNN graphs built with k=10\n",
      "Starting UnionCom training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UnionCom:   5%|▌         | 25/500 [00:38<15:13,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 25/500\n",
      "  Total Loss: 153.3509\n",
      "  Structure Loss: 151.6015\n",
      "  Feature Loss: 1.7415\n",
      "  Domain Loss: 0.0079\n",
      "  GEX->Morpho Acc: 0.2078\n",
      "  Morpho->GEX Acc: 0.1845\n",
      "  Average Acc: 0.1961\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UnionCom:  10%|█         | 50/500 [01:09<08:57,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 50/500\n",
      "  Total Loss: 37.8613\n",
      "  Structure Loss: 34.8849\n",
      "  Feature Loss: 2.9522\n",
      "  Domain Loss: 0.0242\n",
      "  GEX->Morpho Acc: 0.1705\n",
      "  Morpho->GEX Acc: 0.2171\n",
      "  Average Acc: 0.1938\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UnionCom:  15%|█▌        | 75/500 [01:38<07:35,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 75/500\n",
      "  Total Loss: 15.1456\n",
      "  Structure Loss: 14.5406\n",
      "  Feature Loss: 0.5881\n",
      "  Domain Loss: 0.0169\n",
      "  GEX->Morpho Acc: 0.1798\n",
      "  Morpho->GEX Acc: 0.1659\n",
      "  Average Acc: 0.1729\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UnionCom:  20%|██        | 100/500 [02:07<08:42,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 100/500\n",
      "  Total Loss: 8.1320\n",
      "  Structure Loss: 7.7341\n",
      "  Feature Loss: 0.3800\n",
      "  Domain Loss: 0.0178\n",
      "  GEX->Morpho Acc: 0.1473\n",
      "  Morpho->GEX Acc: 0.1628\n",
      "  Average Acc: 0.1550\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UnionCom:  25%|██▌       | 125/500 [02:39<08:16,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 125/500\n",
      "  Total Loss: 5.1507\n",
      "  Structure Loss: 4.8344\n",
      "  Feature Loss: 0.2968\n",
      "  Domain Loss: 0.0195\n",
      "  GEX->Morpho Acc: 0.1721\n",
      "  Morpho->GEX Acc: 0.1643\n",
      "  Average Acc: 0.1682\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UnionCom:  30%|███       | 150/500 [03:06<06:53,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 150/500\n",
      "  Total Loss: 3.6101\n",
      "  Structure Loss: 3.3535\n",
      "  Feature Loss: 0.2376\n",
      "  Domain Loss: 0.0190\n",
      "  GEX->Morpho Acc: 0.1845\n",
      "  Morpho->GEX Acc: 0.1767\n",
      "  Average Acc: 0.1806\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UnionCom:  35%|███▌      | 175/500 [03:36<06:19,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 175/500\n",
      "  Total Loss: 2.6644\n",
      "  Structure Loss: 2.4539\n",
      "  Feature Loss: 0.1923\n",
      "  Domain Loss: 0.0182\n",
      "  GEX->Morpho Acc: 0.1953\n",
      "  Morpho->GEX Acc: 0.1829\n",
      "  Average Acc: 0.1891\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UnionCom:  40%|████      | 200/500 [04:06<06:03,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 200/500\n",
      "  Total Loss: 2.0448\n",
      "  Structure Loss: 1.8556\n",
      "  Feature Loss: 0.1714\n",
      "  Domain Loss: 0.0179\n",
      "  GEX->Morpho Acc: 0.2016\n",
      "  Morpho->GEX Acc: 0.1798\n",
      "  Average Acc: 0.1907\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UnionCom:  45%|████▌     | 225/500 [04:38<05:06,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 225/500\n",
      "  Total Loss: 1.6197\n",
      "  Structure Loss: 1.4416\n",
      "  Feature Loss: 0.1603\n",
      "  Domain Loss: 0.0177\n",
      "  GEX->Morpho Acc: 0.1953\n",
      "  Morpho->GEX Acc: 0.1798\n",
      "  Average Acc: 0.1876\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UnionCom:  50%|█████     | 250/500 [05:09<04:42,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 250/500\n",
      "  Total Loss: 1.3161\n",
      "  Structure Loss: 1.1466\n",
      "  Feature Loss: 0.1519\n",
      "  Domain Loss: 0.0177\n",
      "  GEX->Morpho Acc: 0.1969\n",
      "  Morpho->GEX Acc: 0.1783\n",
      "  Average Acc: 0.1876\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UnionCom:  55%|█████▌    | 275/500 [05:41<04:22,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 275/500\n",
      "  Total Loss: 1.0908\n",
      "  Structure Loss: 0.9296\n",
      "  Feature Loss: 0.1436\n",
      "  Domain Loss: 0.0176\n",
      "  GEX->Morpho Acc: 0.1907\n",
      "  Morpho->GEX Acc: 0.1736\n",
      "  Average Acc: 0.1822\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UnionCom:  60%|██████    | 300/500 [06:13<04:09,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 300/500\n",
      "  Total Loss: 0.9203\n",
      "  Structure Loss: 0.7669\n",
      "  Feature Loss: 0.1359\n",
      "  Domain Loss: 0.0175\n",
      "  GEX->Morpho Acc: 0.1876\n",
      "  Morpho->GEX Acc: 0.1643\n",
      "  Average Acc: 0.1760\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UnionCom:  65%|██████▌   | 325/500 [06:45<04:06,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 325/500\n",
      "  Total Loss: 0.7887\n",
      "  Structure Loss: 0.6426\n",
      "  Feature Loss: 0.1287\n",
      "  Domain Loss: 0.0174\n",
      "  GEX->Morpho Acc: 0.1798\n",
      "  Morpho->GEX Acc: 0.1628\n",
      "  Average Acc: 0.1713\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UnionCom:  70%|███████   | 350/500 [07:18<03:41,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 350/500\n",
      "  Total Loss: 0.6864\n",
      "  Structure Loss: 0.5457\n",
      "  Feature Loss: 0.1233\n",
      "  Domain Loss: 0.0175\n",
      "  GEX->Morpho Acc: 0.1752\n",
      "  Morpho->GEX Acc: 0.1566\n",
      "  Average Acc: 0.1659\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UnionCom:  75%|███████▌  | 375/500 [07:48<02:31,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 375/500\n",
      "  Total Loss: 0.6013\n",
      "  Structure Loss: 0.4692\n",
      "  Feature Loss: 0.1149\n",
      "  Domain Loss: 0.0172\n",
      "  GEX->Morpho Acc: 0.1783\n",
      "  Morpho->GEX Acc: 0.1550\n",
      "  Average Acc: 0.1667\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UnionCom:  80%|████████  | 400/500 [08:17<02:06,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 400/500\n",
      "  Total Loss: 0.5355\n",
      "  Structure Loss: 0.4081\n",
      "  Feature Loss: 0.1105\n",
      "  Domain Loss: 0.0168\n",
      "  GEX->Morpho Acc: 0.1783\n",
      "  Morpho->GEX Acc: 0.1597\n",
      "  Average Acc: 0.1690\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UnionCom:  85%|████████▌ | 425/500 [08:48<01:25,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 425/500\n",
      "  Total Loss: 0.4773\n",
      "  Structure Loss: 0.3573\n",
      "  Feature Loss: 0.1031\n",
      "  Domain Loss: 0.0170\n",
      "  GEX->Morpho Acc: 0.1798\n",
      "  Morpho->GEX Acc: 0.1581\n",
      "  Average Acc: 0.1690\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UnionCom:  90%|█████████ | 450/500 [09:26<01:29,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 450/500\n",
      "  Total Loss: 0.4302\n",
      "  Structure Loss: 0.3148\n",
      "  Feature Loss: 0.0985\n",
      "  Domain Loss: 0.0169\n",
      "  GEX->Morpho Acc: 0.1876\n",
      "  Morpho->GEX Acc: 0.1581\n",
      "  Average Acc: 0.1729\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UnionCom:  95%|█████████▌| 475/500 [10:02<00:33,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 475/500\n",
      "  Total Loss: 0.3923\n",
      "  Structure Loss: 0.2794\n",
      "  Feature Loss: 0.0965\n",
      "  Domain Loss: 0.0164\n",
      "  GEX->Morpho Acc: 0.1953\n",
      "  Morpho->GEX Acc: 0.1566\n",
      "  Average Acc: 0.1760\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training UnionCom: 100%|██████████| 500/500 [10:41<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 500/500\n",
      "  Total Loss: 0.3565\n",
      "  Structure Loss: 0.2481\n",
      "  Feature Loss: 0.0918\n",
      "  Domain Loss: 0.0166\n",
      "  GEX->Morpho Acc: 0.1907\n",
      "  Morpho->GEX Acc: 0.1550\n",
      "  Average Acc: 0.1729\n",
      "--------------------------------------------------\n",
      "\n",
      "Getting latent space embeddings...\n",
      "\n",
      "============================================================\n",
      "FINAL UNIONCOM RESULTS:\n",
      "============================================================\n",
      "GEX -> Morpho Accuracy: 0.1907\n",
      "Morpho -> GEX Accuracy: 0.1550\n",
      "Average Accuracy: 0.1729\n",
      "============================================================\n",
      "\n",
      "Performing UMAP dimensionality reduction...\n",
      "  - Computing GEX UMAP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - GEX UMAP saved to: /home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/writeup20/UnionCom/gex_umap.csv\n",
      "  - Computing Morpho UMAP...\n",
      "  - Morpho UMAP saved to: /home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/writeup20/UnionCom/morpho_umap.csv\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "class UnionComIntegrator:\n",
    "    \"\"\"\n",
    "    UnionCom implementation for multi-modal data integration\n",
    "    Based on the UnionCom algorithm for single-cell multi-omics integration\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim=50, lambda_s=1.0, lambda_f=1.0, lambda_d=1.0, \n",
    "                 knn_k=10, max_iter=200, lr=0.01, device='cuda'):\n",
    "        \"\"\"\n",
    "        Initialize UnionCom integrator\n",
    "        \n",
    "        Args:\n",
    "            latent_dim: Dimension of the integrated latent space\n",
    "            lambda_s: Weight for structure preservation loss\n",
    "            lambda_f: Weight for feature matching loss  \n",
    "            lambda_d: Weight for domain alignment loss\n",
    "            knn_k: Number of neighbors for KNN graph construction\n",
    "            max_iter: Maximum number of iterations\n",
    "            lr: Learning rate\n",
    "            device: Computing device\n",
    "        \"\"\"\n",
    "        self.latent_dim = latent_dim\n",
    "        self.lambda_s = lambda_s\n",
    "        self.lambda_f = lambda_f\n",
    "        self.lambda_d = lambda_d\n",
    "        self.knn_k = knn_k\n",
    "        self.max_iter = max_iter\n",
    "        self.lr = lr\n",
    "        self.device = device if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Will be initialized after loading data\n",
    "        self.encoder_gex = None\n",
    "        self.encoder_morpho = None\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load multi-modal data\"\"\"\n",
    "        # Gene expression data\n",
    "        gene_expression_path = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/scala/exon_data_top2000.csv\"\n",
    "        gex_df = pd.read_csv(gene_expression_path, header=None)\n",
    "        self.gex_data = gex_df.iloc[:, 1:].to_numpy().astype(np.float32)\n",
    "        \n",
    "        # Morphology data\n",
    "        morphology_path = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/scala/gw_dist.csv\"\n",
    "        morpho_df = pd.read_csv(morphology_path, header=0)\n",
    "        self.morpho_data = morpho_df.iloc[:, 1:].to_numpy().astype(np.float32)\n",
    "        \n",
    "        # RNA family labels\n",
    "        rna_family_path = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/scala/rna_family_matched.csv\"\n",
    "        try:\n",
    "            rna_df = pd.read_csv(rna_family_path, header=0)\n",
    "            if rna_df.shape[1] == 1:\n",
    "                self.rna_family_labels = rna_df.iloc[:, 0].values\n",
    "            else:\n",
    "                self.rna_family_labels = rna_df.iloc[:, 1].values\n",
    "            \n",
    "            min_samples = min(len(self.gex_data), len(self.morpho_data))\n",
    "            self.rna_family_labels = self.rna_family_labels[:min_samples]\n",
    "            self.gex_data = self.gex_data[:min_samples]\n",
    "            self.morpho_data = self.morpho_data[:min_samples]\n",
    "            \n",
    "            print(f\"RNA family labels loaded: {len(np.unique(self.rna_family_labels))} unique types\")\n",
    "            print(f\"Data shapes - GEX: {self.gex_data.shape}, Morpho: {self.morpho_data.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not load RNA family labels: {e}\")\n",
    "            self.rna_family_labels = None\n",
    "        \n",
    "        # Data normalization\n",
    "        self.gex_mean = np.mean(self.gex_data, axis=0)\n",
    "        self.gex_std = np.std(self.gex_data, axis=0) + 1e-8\n",
    "        self.morpho_mean = np.mean(self.morpho_data, axis=0)\n",
    "        self.morpho_std = np.std(self.morpho_data, axis=0) + 1e-8\n",
    "        \n",
    "        self.gex_data = (self.gex_data - self.gex_mean) / self.gex_std\n",
    "        self.morpho_data = (self.morpho_data - self.morpho_mean) / self.morpho_std\n",
    "        \n",
    "        self.n_samples = len(self.gex_data)\n",
    "        self.gex_dim = self.gex_data.shape[1]\n",
    "        self.morpho_dim = self.morpho_data.shape[1]\n",
    "        \n",
    "        # Initialize encoders\n",
    "        self._initialize_encoders()\n",
    "        \n",
    "        # Convert to tensors\n",
    "        self.gex_tensor = torch.FloatTensor(self.gex_data).to(self.device)\n",
    "        self.morpho_tensor = torch.FloatTensor(self.morpho_data).to(self.device)\n",
    "        \n",
    "        # Build KNN graphs for structure preservation\n",
    "        self._build_knn_graphs()\n",
    "        \n",
    "    def _initialize_encoders(self):\n",
    "        \"\"\"Initialize encoder networks\"\"\"\n",
    "        \n",
    "        class Encoder(nn.Module):\n",
    "            def __init__(self, input_dim, output_dim):\n",
    "                super(Encoder, self).__init__()\n",
    "                hidden_dim = max(256, min(512, input_dim // 2))\n",
    "                self.network = nn.Sequential(\n",
    "                    nn.Linear(input_dim, hidden_dim),\n",
    "                    nn.BatchNorm1d(hidden_dim),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.2),\n",
    "                    nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "                    nn.BatchNorm1d(hidden_dim // 2),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.2),\n",
    "                    nn.Linear(hidden_dim // 2, output_dim)\n",
    "                )\n",
    "            \n",
    "            def forward(self, x):\n",
    "                return self.network(x)\n",
    "        \n",
    "        self.encoder_gex = Encoder(self.gex_dim, self.latent_dim).to(self.device)\n",
    "        self.encoder_morpho = Encoder(self.morpho_dim, self.latent_dim).to(self.device)\n",
    "        \n",
    "        # Initialize optimizers\n",
    "        self.optimizer = optim.Adam(\n",
    "            list(self.encoder_gex.parameters()) + list(self.encoder_morpho.parameters()),\n",
    "            lr=self.lr\n",
    "        )\n",
    "        \n",
    "    def _build_knn_graphs(self):\n",
    "        \"\"\"Build KNN graphs for structure preservation\"\"\"\n",
    "        print(\"Building KNN graphs...\")\n",
    "        \n",
    "        # Build KNN graph for GEX data\n",
    "        nbrs_gex = NearestNeighbors(n_neighbors=self.knn_k, metric='euclidean').fit(self.gex_data)\n",
    "        _, indices_gex = nbrs_gex.kneighbors(self.gex_data)\n",
    "        self.knn_indices_gex = indices_gex\n",
    "        \n",
    "        # Build KNN graph for Morpho data  \n",
    "        nbrs_morpho = NearestNeighbors(n_neighbors=self.knn_k, metric='euclidean').fit(self.morpho_data)\n",
    "        _, indices_morpho = nbrs_morpho.kneighbors(self.morpho_data)\n",
    "        self.knn_indices_morpho = indices_morpho\n",
    "        \n",
    "        print(f\"KNN graphs built with k={self.knn_k}\")\n",
    "        \n",
    "    def _structure_preservation_loss(self, embeddings_gex, embeddings_morpho):\n",
    "        \"\"\"Calculate structure preservation loss\"\"\"\n",
    "        loss = 0.0\n",
    "        \n",
    "        # Structure preservation for GEX\n",
    "        for i in range(len(embeddings_gex)):\n",
    "            anchor_emb = embeddings_gex[i]\n",
    "            neighbor_indices = self.knn_indices_gex[i]\n",
    "            \n",
    "            # Calculate distances in original space\n",
    "            anchor_orig = self.gex_tensor[i]\n",
    "            neighbors_orig = self.gex_tensor[neighbor_indices]\n",
    "            orig_distances = torch.norm(neighbors_orig - anchor_orig.unsqueeze(0), dim=1)\n",
    "            \n",
    "            # Calculate distances in embedding space\n",
    "            neighbors_emb = embeddings_gex[neighbor_indices]\n",
    "            emb_distances = torch.norm(neighbors_emb - anchor_emb.unsqueeze(0), dim=1)\n",
    "            \n",
    "            # Structure preservation loss (preserve relative distances)\n",
    "            loss += torch.mean((orig_distances - emb_distances) ** 2)\n",
    "            \n",
    "        # Structure preservation for Morpho\n",
    "        for i in range(len(embeddings_morpho)):\n",
    "            anchor_emb = embeddings_morpho[i]\n",
    "            neighbor_indices = self.knn_indices_morpho[i]\n",
    "            \n",
    "            # Calculate distances in original space\n",
    "            anchor_orig = self.morpho_tensor[i]\n",
    "            neighbors_orig = self.morpho_tensor[neighbor_indices]\n",
    "            orig_distances = torch.norm(neighbors_orig - anchor_orig.unsqueeze(0), dim=1)\n",
    "            \n",
    "            # Calculate distances in embedding space\n",
    "            neighbors_emb = embeddings_morpho[neighbor_indices]\n",
    "            emb_distances = torch.norm(neighbors_emb - anchor_emb.unsqueeze(0), dim=1)\n",
    "            \n",
    "            # Structure preservation loss\n",
    "            loss += torch.mean((orig_distances - emb_distances) ** 2)\n",
    "            \n",
    "        return loss / (2 * self.n_samples)\n",
    "    \n",
    "    def _feature_matching_loss(self, embeddings_gex, embeddings_morpho):\n",
    "        \"\"\"Calculate feature matching loss between modalities\"\"\"\n",
    "        # Calculate mean embeddings for each modality\n",
    "        mean_gex = torch.mean(embeddings_gex, dim=0)\n",
    "        mean_morpho = torch.mean(embeddings_morpho, dim=0)\n",
    "        \n",
    "        # Feature matching loss (align distributions)\n",
    "        feature_loss = torch.mean((mean_gex - mean_morpho) ** 2)\n",
    "        \n",
    "        # Add covariance alignment\n",
    "        cov_gex = torch.cov(embeddings_gex.T)\n",
    "        cov_morpho = torch.cov(embeddings_morpho.T)\n",
    "        cov_loss = torch.mean((cov_gex - cov_morpho) ** 2)\n",
    "        \n",
    "        return feature_loss + 0.1 * cov_loss\n",
    "    \n",
    "    def _domain_alignment_loss(self, embeddings_gex, embeddings_morpho):\n",
    "        \"\"\"Calculate domain alignment loss using Maximum Mean Discrepancy (MMD)\"\"\"\n",
    "        \n",
    "        def compute_kernel(x, y, sigma=1.0):\n",
    "            \"\"\"Compute RBF kernel matrix\"\"\"\n",
    "            x_size = x.size(0)\n",
    "            y_size = y.size(0)\n",
    "            dim = x.size(1)\n",
    "            \n",
    "            x = x.unsqueeze(1)  # (x_size, 1, dim)\n",
    "            y = y.unsqueeze(0)  # (1, y_size, dim)\n",
    "            \n",
    "            tiled_x = x.expand(x_size, y_size, dim)\n",
    "            tiled_y = y.expand(x_size, y_size, dim)\n",
    "            \n",
    "            kernel_input = (tiled_x - tiled_y).pow(2).mean(2) / float(dim)\n",
    "            return torch.exp(-kernel_input / sigma)\n",
    "        \n",
    "        # Compute MMD loss\n",
    "        x_kernel = compute_kernel(embeddings_gex, embeddings_gex)\n",
    "        y_kernel = compute_kernel(embeddings_morpho, embeddings_morpho) \n",
    "        xy_kernel = compute_kernel(embeddings_gex, embeddings_morpho)\n",
    "        \n",
    "        mmd_loss = torch.mean(x_kernel) + torch.mean(y_kernel) - 2 * torch.mean(xy_kernel)\n",
    "        return mmd_loss\n",
    "    \n",
    "    def train_step(self):\n",
    "        \"\"\"Perform one training step\"\"\"\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        embeddings_gex = self.encoder_gex(self.gex_tensor)\n",
    "        embeddings_morpho = self.encoder_morpho(self.morpho_tensor)\n",
    "        \n",
    "        # Calculate losses\n",
    "        structure_loss = self._structure_preservation_loss(embeddings_gex, embeddings_morpho)\n",
    "        feature_loss = self._feature_matching_loss(embeddings_gex, embeddings_morpho)\n",
    "        domain_loss = self._domain_alignment_loss(embeddings_gex, embeddings_morpho)\n",
    "        \n",
    "        # Total loss\n",
    "        total_loss = (self.lambda_s * structure_loss + \n",
    "                     self.lambda_f * feature_loss + \n",
    "                     self.lambda_d * domain_loss)\n",
    "        \n",
    "        # Backward pass\n",
    "        total_loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return total_loss.item(), structure_loss.item(), feature_loss.item(), domain_loss.item()\n",
    "    \n",
    "    def get_integrated_embeddings(self):\n",
    "        \"\"\"Get integrated embeddings\"\"\"\n",
    "        self.encoder_gex.eval()\n",
    "        self.encoder_morpho.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            gex_embeddings = self.encoder_gex(self.gex_tensor).cpu().numpy()\n",
    "            morpho_embeddings = self.encoder_morpho(self.morpho_tensor).cpu().numpy()\n",
    "        \n",
    "        return gex_embeddings, morpho_embeddings\n",
    "    \n",
    "    def calculate_celltype_accuracy(self, gex_embeddings, morpho_embeddings):\n",
    "        \"\"\"Calculate cell type matching accuracy\"\"\"\n",
    "        if self.rna_family_labels is None:\n",
    "            print(\"No RNA family labels available for accuracy calculation\")\n",
    "            return None, None, None\n",
    "        \n",
    "        # Use nearest neighbor search\n",
    "        nbrs_morpho = NearestNeighbors(n_neighbors=1, metric='euclidean').fit(morpho_embeddings)\n",
    "        nbrs_gex = NearestNeighbors(n_neighbors=1, metric='euclidean').fit(gex_embeddings)\n",
    "        \n",
    "        # GEX to Morpho matching accuracy\n",
    "        _, indices_gex2morpho = nbrs_morpho.kneighbors(gex_embeddings)\n",
    "        gex2morpho_matches = 0\n",
    "        for i, nearest_idx in enumerate(indices_gex2morpho.flatten()):\n",
    "            if self.rna_family_labels[i] == self.rna_family_labels[nearest_idx]:\n",
    "                gex2morpho_matches += 1\n",
    "        gex2morpho_accuracy = gex2morpho_matches / len(self.rna_family_labels)\n",
    "        \n",
    "        # Morpho to GEX matching accuracy\n",
    "        _, indices_morpho2gex = nbrs_gex.kneighbors(morpho_embeddings)\n",
    "        morpho2gex_matches = 0\n",
    "        for i, nearest_idx in enumerate(indices_morpho2gex.flatten()):\n",
    "            if self.rna_family_labels[i] == self.rna_family_labels[nearest_idx]:\n",
    "                morpho2gex_matches += 1\n",
    "        morpho2gex_accuracy = morpho2gex_matches / len(self.rna_family_labels)\n",
    "        \n",
    "        # Average matching accuracy\n",
    "        average_accuracy = (gex2morpho_accuracy + morpho2gex_accuracy) / 2\n",
    "        \n",
    "        return gex2morpho_accuracy, morpho2gex_accuracy, average_accuracy\n",
    "    \n",
    "    def train(self, verbose_interval=20):\n",
    "        \"\"\"Train UnionCom model\"\"\"\n",
    "        print(\"Starting UnionCom training...\")\n",
    "        \n",
    "        for iteration in tqdm(range(self.max_iter), desc=\"Training UnionCom\"):\n",
    "            # Training step\n",
    "            total_loss, struct_loss, feat_loss, dom_loss = self.train_step()\n",
    "            \n",
    "            # Calculate accuracy periodically\n",
    "            if (iteration + 1) % verbose_interval == 0:\n",
    "                gex_emb, morpho_emb = self.get_integrated_embeddings()\n",
    "                gex2morpho_acc, morpho2gex_acc, avg_acc = self.calculate_celltype_accuracy(gex_emb, morpho_emb)\n",
    "                \n",
    "                print(f\"\\nIteration {iteration+1}/{self.max_iter}\")\n",
    "                print(f\"  Total Loss: {total_loss:.4f}\")\n",
    "                print(f\"  Structure Loss: {struct_loss:.4f}\")\n",
    "                print(f\"  Feature Loss: {feat_loss:.4f}\")\n",
    "                print(f\"  Domain Loss: {dom_loss:.4f}\")\n",
    "                if avg_acc is not None:\n",
    "                    print(f\"  GEX->Morpho Acc: {gex2morpho_acc:.4f}\")\n",
    "                    print(f\"  Morpho->GEX Acc: {morpho2gex_acc:.4f}\")\n",
    "                    print(f\"  Average Acc: {avg_acc:.4f}\")\n",
    "                print(\"-\" * 50)\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    # 创建输出目录\n",
    "    output_dir = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/writeup20/UnionCom/\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Initialize UnionCom integrator\n",
    "    integrator = UnionComIntegrator(\n",
    "        latent_dim=50,\n",
    "        lambda_s=1.0,\n",
    "        lambda_f=1.0,\n",
    "        lambda_d=1.0,\n",
    "        knn_k=10,\n",
    "        max_iter=500,\n",
    "        lr=0.001\n",
    "    )\n",
    "    \n",
    "    # Load data\n",
    "    integrator.load_data()\n",
    "    \n",
    "    # Train model\n",
    "    integrator.train(verbose_interval=25)\n",
    "    \n",
    "    # Get final integrated embeddings\n",
    "    print(\"\\nGetting latent space embeddings...\")\n",
    "    final_gex_embeddings, final_morpho_embeddings = integrator.get_integrated_embeddings()\n",
    "    \n",
    "    # Calculate final accuracy\n",
    "    final_gex2morpho_acc, final_morpho2gex_acc, final_avg_acc = integrator.calculate_celltype_accuracy(\n",
    "        final_gex_embeddings, final_morpho_embeddings\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL UNIONCOM RESULTS:\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"GEX -> Morpho Accuracy: {final_gex2morpho_acc:.4f}\")\n",
    "    print(f\"Morpho -> GEX Accuracy: {final_morpho2gex_acc:.4f}\")\n",
    "    print(f\"Average Accuracy: {final_avg_acc:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # UMAP降维\n",
    "    print(\"\\nPerforming UMAP dimensionality reduction...\")\n",
    "    reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "    \n",
    "    # GEX UMAP\n",
    "    print(\"  - Computing GEX UMAP...\")\n",
    "    gex_umap = reducer.fit_transform(final_gex_embeddings)\n",
    "    gex_umap_df = pd.DataFrame(gex_umap, columns=['UMAP1', 'UMAP2'])\n",
    "    gex_umap_path = os.path.join(output_dir, \"gex_umap.csv\")\n",
    "    gex_umap_df.to_csv(gex_umap_path, index=False)\n",
    "    print(f\"  - GEX UMAP saved to: {gex_umap_path}\")\n",
    "    \n",
    "    # Morpho UMAP\n",
    "    print(\"  - Computing Morpho UMAP...\")\n",
    "    morpho_umap = reducer.fit_transform(final_morpho_embeddings)\n",
    "    morpho_umap_df = pd.DataFrame(morpho_umap, columns=['UMAP1', 'UMAP2'])\n",
    "    morpho_umap_path = os.path.join(output_dir, \"morpho_umap.csv\")\n",
    "    morpho_umap_df.to_csv(morpho_umap_path, index=False)\n",
    "    print(f\"  - Morpho UMAP saved to: {morpho_umap_path}\")\n",
    "    \n",
    "    print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d00922",
   "metadata": {},
   "source": [
    "## SCIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fdf30aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded successfully:\n",
      "  - GEX data shape: (645, 2000)\n",
      "  - Morpho data shape: (645, 645)\n",
      "  - RNA family labels: 10 unique types\n",
      "\n",
      "Initializing SCIM model...\n",
      "Initializing SCIM with dimensions: GEX=2000, Morpho=645, Latent=128\n",
      "SCIM initialization completed!\n",
      "Training SCIM model...\n",
      "Preprocessing data...\n",
      "Starting SCIM training for 200 epochs...\n",
      "Epoch [20/200], Loss: -3.788324\n",
      "Epoch [40/200], Loss: -21.455040\n",
      "Epoch [60/200], Loss: -21.932619\n",
      "Epoch [80/200], Loss: -22.007526\n",
      "Epoch [100/200], Loss: -22.477897\n",
      "Epoch [120/200], Loss: -22.579822\n",
      "Epoch [140/200], Loss: -22.593367\n",
      "Epoch [160/200], Loss: -22.637714\n",
      "Epoch [180/200], Loss: -22.654634\n",
      "Epoch [200/200], Loss: -22.637306\n",
      "Loaded best model with loss: -22.742101\n",
      "\n",
      "Transforming data to SCIM representation space...\n",
      "Encoded data shapes:\n",
      "  - GEX encoded: (645, 128)\n",
      "  - Morpho encoded: (645, 128)\n",
      "\n",
      "Calculating celltype accuracy...\n",
      "\n",
      "============================================================\n",
      "SCIM INTEGRATION RESULTS:\n",
      "============================================================\n",
      "  Morpho to GEX accuracy: 0.6558\n",
      "  GEX to Morpho accuracy: 0.5814\n",
      "  Average accuracy: 0.6186\n",
      "============================================================\n",
      "\n",
      "Performing UMAP dimensionality reduction...\n",
      "  - Computing GEX UMAP...\n",
      "  - GEX UMAP saved to: /home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/writeup20/SCIM/gex_umap.csv\n",
      "  - Computing Morpho UMAP...\n",
      "  - Morpho UMAP saved to: /home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/writeup20/SCIM/morpho_umap.csv\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import umap\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class MutualInformationLoss(nn.Module):\n",
    "    \"\"\"互信息损失函数\"\"\"\n",
    "    def __init__(self, sigma=1.0, num_bins=50):\n",
    "        super(MutualInformationLoss, self).__init__()\n",
    "        self.sigma = sigma\n",
    "        self.num_bins = num_bins\n",
    "    \n",
    "    def gaussian_kernel(self, x, y, sigma):\n",
    "        \"\"\"高斯核函数\"\"\"\n",
    "        dist = torch.cdist(x, y, p=2)\n",
    "        return torch.exp(-dist**2 / (2 * sigma**2))\n",
    "    \n",
    "    def entropy_estimate_kde(self, x):\n",
    "        \"\"\"使用核密度估计计算熵\"\"\"\n",
    "        n = x.size(0)\n",
    "        K = self.gaussian_kernel(x, x, self.sigma)\n",
    "        K = K - torch.eye(n, device=x.device)\n",
    "        density = torch.sum(K, dim=1) / (n - 1)\n",
    "        density = torch.clamp(density, min=1e-10)\n",
    "        entropy = -torch.mean(torch.log(density))\n",
    "        return entropy\n",
    "    \n",
    "    def mutual_information_kde(self, x, y):\n",
    "        \"\"\"使用核密度估计计算互信息\"\"\"\n",
    "        h_x = self.entropy_estimate_kde(x)\n",
    "        h_y = self.entropy_estimate_kde(y)\n",
    "        \n",
    "        xy = torch.cat([x, y], dim=1)\n",
    "        h_xy = self.entropy_estimate_kde(xy)\n",
    "        \n",
    "        mi = h_x + h_y - h_xy\n",
    "        return mi\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        \"\"\"计算负互信息作为损失\"\"\"\n",
    "        mi = self.mutual_information_kde(x, y)\n",
    "        return -mi\n",
    "\n",
    "\n",
    "class SCIMEncoder(nn.Module):\n",
    "    \"\"\"SCIM编码器网络\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim, dropout_rate=0.1):\n",
    "        super(SCIMEncoder, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for i, hidden_dim in enumerate(hidden_dims):\n",
    "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "            layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            if i < len(hidden_dims) - 1:\n",
    "                layers.append(nn.Dropout(dropout_rate))\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "        \n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "        \n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight, gain=0.1)\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, nn.BatchNorm1d):\n",
    "            nn.init.constant_(module.weight, 1)\n",
    "            nn.init.constant_(module.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    \"\"\"对比学习损失函数\"\"\"\n",
    "    def __init__(self, temperature=0.1):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "    \n",
    "    def forward(self, z1, z2):\n",
    "        batch_size = z1.size(0)\n",
    "        \n",
    "        z1 = nn.functional.normalize(z1, dim=1)\n",
    "        z2 = nn.functional.normalize(z2, dim=1)\n",
    "        \n",
    "        similarity_matrix = torch.matmul(z1, z2.t()) / self.temperature\n",
    "        \n",
    "        positive_samples = torch.diag(similarity_matrix)\n",
    "        \n",
    "        mask = torch.eye(batch_size, device=z1.device).bool()\n",
    "        negative_samples = similarity_matrix.masked_select(~mask).view(batch_size, -1)\n",
    "        \n",
    "        logits = torch.cat([positive_samples.unsqueeze(1), negative_samples], dim=1)\n",
    "        labels = torch.zeros(batch_size, dtype=torch.long, device=z1.device)\n",
    "        \n",
    "        loss = nn.functional.cross_entropy(logits, labels)\n",
    "        return loss\n",
    "\n",
    "\n",
    "class SCIMIntegrator:\n",
    "    \"\"\"SCIM多模态数据整合器\"\"\"\n",
    "    \n",
    "    def __init__(self, gex_dim, morpho_dim, latent_dim=128, hidden_dims=None, \n",
    "                 mi_weight=1.0, contrastive_weight=0.5,\n",
    "                 device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.device = device\n",
    "        self.latent_dim = latent_dim\n",
    "        self.mi_weight = mi_weight\n",
    "        self.contrastive_weight = contrastive_weight\n",
    "        \n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [256, 128]\n",
    "        \n",
    "        print(f\"Initializing SCIM with dimensions: GEX={gex_dim}, Morpho={morpho_dim}, Latent={latent_dim}\")\n",
    "        \n",
    "        self.gex_encoder = SCIMEncoder(gex_dim, hidden_dims, latent_dim).to(device)\n",
    "        self.morpho_encoder = SCIMEncoder(morpho_dim, hidden_dims, latent_dim).to(device)\n",
    "        \n",
    "        self.mi_loss = MutualInformationLoss(sigma=1.0).to(device)\n",
    "        self.contrastive_loss = ContrastiveLoss(temperature=0.1).to(device)\n",
    "        self.reconstruction_loss = nn.MSELoss()\n",
    "        \n",
    "        self.gex_decoder = self._create_decoder(latent_dim, hidden_dims, gex_dim).to(device)\n",
    "        self.morpho_decoder = self._create_decoder(latent_dim, hidden_dims, morpho_dim).to(device)\n",
    "        \n",
    "        all_params = (list(self.gex_encoder.parameters()) + \n",
    "                     list(self.morpho_encoder.parameters()) +\n",
    "                     list(self.gex_decoder.parameters()) +\n",
    "                     list(self.morpho_decoder.parameters()))\n",
    "        \n",
    "        self.optimizer = optim.Adam(all_params, lr=0.001, weight_decay=1e-4)\n",
    "        \n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer, mode='min', patience=15, factor=0.5, verbose=True\n",
    "        )\n",
    "        \n",
    "        self.gex_scaler = StandardScaler()\n",
    "        self.morpho_scaler = StandardScaler()\n",
    "        \n",
    "        print(\"SCIM initialization completed!\")\n",
    "    \n",
    "    def _create_decoder(self, input_dim, hidden_dims, output_dim):\n",
    "        \"\"\"创建重构解码器\"\"\"\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for hidden_dim in reversed(hidden_dims):\n",
    "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "            layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(0.1))\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def train(self, gex_data, morpho_data, epochs=200, batch_size=64, \n",
    "              reconstruction_weight=0.1, verbose=True):\n",
    "        \"\"\"训练SCIM模型\"\"\"\n",
    "        \n",
    "        print(\"Preprocessing data...\")\n",
    "        \n",
    "        gex_data = np.nan_to_num(gex_data, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "        morpho_data = np.nan_to_num(morpho_data, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "        \n",
    "        gex_data_norm = self.gex_scaler.fit_transform(gex_data)\n",
    "        morpho_data_norm = self.morpho_scaler.fit_transform(morpho_data)\n",
    "        \n",
    "        gex_tensor = torch.FloatTensor(gex_data_norm).to(self.device)\n",
    "        morpho_tensor = torch.FloatTensor(morpho_data_norm).to(self.device)\n",
    "        \n",
    "        dataset = TensorDataset(gex_tensor, morpho_tensor)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "        \n",
    "        print(f\"Starting SCIM training for {epochs} epochs...\")\n",
    "        \n",
    "        best_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            epoch_total_loss = 0.0\n",
    "            num_batches = 0\n",
    "            \n",
    "            self.gex_encoder.train()\n",
    "            self.morpho_encoder.train()\n",
    "            self.gex_decoder.train()\n",
    "            self.morpho_decoder.train()\n",
    "            \n",
    "            for batch_idx, (gex_batch, morpho_batch) in enumerate(dataloader):\n",
    "                if gex_batch.size(0) < 8:\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    gex_encoded = self.gex_encoder(gex_batch)\n",
    "                    morpho_encoded = self.morpho_encoder(morpho_batch)\n",
    "                    \n",
    "                    if torch.isnan(gex_encoded).any() or torch.isnan(morpho_encoded).any():\n",
    "                        continue\n",
    "                    \n",
    "                    mi_loss = self.mi_loss(gex_encoded, morpho_encoded)\n",
    "                    contrastive_loss = self.contrastive_loss(gex_encoded, morpho_encoded)\n",
    "                    \n",
    "                    gex_reconstructed = self.gex_decoder(gex_encoded)\n",
    "                    morpho_reconstructed = self.morpho_decoder(morpho_encoded)\n",
    "                    \n",
    "                    recon_loss_gex = self.reconstruction_loss(gex_reconstructed, gex_batch)\n",
    "                    recon_loss_morpho = self.reconstruction_loss(morpho_reconstructed, morpho_batch)\n",
    "                    reconstruction_loss = (recon_loss_gex + recon_loss_morpho) / 2\n",
    "                    \n",
    "                    total_loss = (self.mi_weight * mi_loss + \n",
    "                                 self.contrastive_weight * contrastive_loss +\n",
    "                                 reconstruction_weight * reconstruction_loss)\n",
    "                    \n",
    "                    if torch.isnan(total_loss) or torch.isinf(total_loss):\n",
    "                        continue\n",
    "                    \n",
    "                    self.optimizer.zero_grad()\n",
    "                    total_loss.backward()\n",
    "                    \n",
    "                    torch.nn.utils.clip_grad_norm_(\n",
    "                        list(self.gex_encoder.parameters()) + \n",
    "                        list(self.morpho_encoder.parameters()) +\n",
    "                        list(self.gex_decoder.parameters()) +\n",
    "                        list(self.morpho_decoder.parameters()), \n",
    "                        max_norm=1.0\n",
    "                    )\n",
    "                    \n",
    "                    self.optimizer.step()\n",
    "                    \n",
    "                    epoch_total_loss += total_loss.item()\n",
    "                    num_batches += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    continue\n",
    "            \n",
    "            if num_batches == 0:\n",
    "                continue\n",
    "            \n",
    "            avg_loss = epoch_total_loss / num_batches\n",
    "            \n",
    "            self.scheduler.step(avg_loss)\n",
    "            \n",
    "            if avg_loss < best_loss:\n",
    "                best_loss = avg_loss\n",
    "                patience_counter = 0\n",
    "                self.best_gex_encoder_state = self.gex_encoder.state_dict().copy()\n",
    "                self.best_morpho_encoder_state = self.morpho_encoder.state_dict().copy()\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            if verbose and (epoch + 1) % 20 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.6f}')\n",
    "            \n",
    "            if patience_counter >= 40:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "        \n",
    "        if hasattr(self, 'best_gex_encoder_state'):\n",
    "            self.gex_encoder.load_state_dict(self.best_gex_encoder_state)\n",
    "            self.morpho_encoder.load_state_dict(self.best_morpho_encoder_state)\n",
    "            print(f\"Loaded best model with loss: {best_loss:.6f}\")\n",
    "    \n",
    "    def transform(self, gex_data, morpho_data):\n",
    "        \"\"\"将数据转换到SCIM学习的表示空间\"\"\"\n",
    "        self.gex_encoder.eval()\n",
    "        self.morpho_encoder.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            gex_data_norm = self.gex_scaler.transform(gex_data)\n",
    "            morpho_data_norm = self.morpho_scaler.transform(morpho_data)\n",
    "            \n",
    "            gex_tensor = torch.FloatTensor(gex_data_norm).to(self.device)\n",
    "            morpho_tensor = torch.FloatTensor(morpho_data_norm).to(self.device)\n",
    "            \n",
    "            gex_encoded = self.gex_encoder(gex_tensor).cpu().numpy()\n",
    "            morpho_encoded = self.morpho_encoder(morpho_tensor).cpu().numpy()\n",
    "            \n",
    "        return gex_encoded, morpho_encoded\n",
    "\n",
    "\n",
    "def calculate_celltype_accuracy(gex_encoded, morpho_encoded, rna_family_labels, k=1):\n",
    "    \"\"\"计算细胞类型匹配准确率\"\"\"\n",
    "    \n",
    "    nbrs_gex = NearestNeighbors(n_neighbors=k+1, algorithm='ball_tree').fit(gex_encoded)\n",
    "    distances_m2g, indices_m2g = nbrs_gex.kneighbors(morpho_encoded)\n",
    "    \n",
    "    nearest_gex_indices = indices_m2g[:, 0]\n",
    "    nearest_gex_labels = rna_family_labels[nearest_gex_indices]\n",
    "    morpho_labels = rna_family_labels\n",
    "    \n",
    "    matches_m2g = np.sum(morpho_labels == nearest_gex_labels)\n",
    "    morpho_to_gex_accuracy = matches_m2g / len(morpho_labels)\n",
    "    \n",
    "    nbrs_morpho = NearestNeighbors(n_neighbors=k+1, algorithm='ball_tree').fit(morpho_encoded)\n",
    "    distances_g2m, indices_g2m = nbrs_morpho.kneighbors(gex_encoded)\n",
    "    \n",
    "    nearest_morpho_indices = indices_g2m[:, 0]\n",
    "    nearest_morpho_labels = rna_family_labels[nearest_morpho_indices]\n",
    "    gex_labels = rna_family_labels\n",
    "    \n",
    "    matches_g2m = np.sum(gex_labels == nearest_morpho_labels)\n",
    "    gex_to_morpho_accuracy = matches_g2m / len(gex_labels)\n",
    "    \n",
    "    average_accuracy = (morpho_to_gex_accuracy + gex_to_morpho_accuracy) / 2\n",
    "    \n",
    "    return morpho_to_gex_accuracy, gex_to_morpho_accuracy, average_accuracy\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数：完整的SCIM整合流程\"\"\"\n",
    "    \n",
    "    # 数据路径\n",
    "    gene_expression_path = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/scala/exon_data_top2000.csv\"\n",
    "    morphology_path = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/scala/gw_dist.csv\"\n",
    "    rna_family_path = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/scala/rna_family_matched.csv\"\n",
    "    \n",
    "    # 输出路径\n",
    "    output_dir = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/writeup20/SCIM/\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"Loading data...\")\n",
    "    \n",
    "    # 加载基因表达数据\n",
    "    gex_df = pd.read_csv(gene_expression_path, header=None)\n",
    "    gex_data = gex_df.iloc[:, 1:].to_numpy().astype(np.float32)\n",
    "    \n",
    "    # 加载形态学数据\n",
    "    morpho_df = pd.read_csv(morphology_path, header=0)\n",
    "    morpho_data = morpho_df.iloc[:, 1:].to_numpy().astype(np.float32)\n",
    "    \n",
    "    # 加载RNA family标签\n",
    "    try:\n",
    "        rna_df = pd.read_csv(rna_family_path, header=0)\n",
    "        if rna_df.shape[1] == 1:\n",
    "            rna_family_labels = rna_df.iloc[:, 0].values\n",
    "        else:\n",
    "            rna_family_labels = rna_df.iloc[:, 1].values\n",
    "        \n",
    "        min_samples = min(len(gex_data), len(morpho_data), len(rna_family_labels))\n",
    "        gex_data = gex_data[:min_samples]\n",
    "        morpho_data = morpho_data[:min_samples]\n",
    "        rna_family_labels = rna_family_labels[:min_samples]\n",
    "        \n",
    "        print(f\"Data loaded successfully:\")\n",
    "        print(f\"  - GEX data shape: {gex_data.shape}\")\n",
    "        print(f\"  - Morpho data shape: {morpho_data.shape}\")\n",
    "        print(f\"  - RNA family labels: {len(np.unique(rna_family_labels))} unique types\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading RNA family labels: {e}\")\n",
    "        return\n",
    "    \n",
    "    # 创建并训练SCIM模型\n",
    "    print(\"\\nInitializing SCIM model...\")\n",
    "    integrator = SCIMIntegrator(\n",
    "        gex_dim=gex_data.shape[1],\n",
    "        morpho_dim=morpho_data.shape[1],\n",
    "        latent_dim=128,\n",
    "        hidden_dims=[256, 128],\n",
    "        mi_weight=1.0,\n",
    "        contrastive_weight=0.5\n",
    "    )\n",
    "    \n",
    "    print(\"Training SCIM model...\")\n",
    "    integrator.train(\n",
    "        gex_data, morpho_data,\n",
    "        epochs=200,\n",
    "        batch_size=32,\n",
    "        reconstruction_weight=0.1,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # 转换数据到SCIM表示空间\n",
    "    print(\"\\nTransforming data to SCIM representation space...\")\n",
    "    gex_encoded, morpho_encoded = integrator.transform(gex_data, morpho_data)\n",
    "    \n",
    "    print(f\"Encoded data shapes:\")\n",
    "    print(f\"  - GEX encoded: {gex_encoded.shape}\")\n",
    "    print(f\"  - Morpho encoded: {morpho_encoded.shape}\")\n",
    "    \n",
    "    # 计算细胞类型匹配准确率\n",
    "    print(\"\\nCalculating celltype accuracy...\")\n",
    "    morpho_to_gex_acc, gex_to_morpho_acc, avg_acc = calculate_celltype_accuracy(\n",
    "        gex_encoded, morpho_encoded, rna_family_labels\n",
    "    )\n",
    "    \n",
    "    # 输出结果\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(f\"SCIM INTEGRATION RESULTS:\")\n",
    "    print(f\"=\"*60)\n",
    "    print(f\"  Morpho to GEX accuracy: {morpho_to_gex_acc:.4f}\")\n",
    "    print(f\"  GEX to Morpho accuracy: {gex_to_morpho_acc:.4f}\")\n",
    "    print(f\"  Average accuracy: {avg_acc:.4f}\")\n",
    "    print(f\"=\"*60)\n",
    "    \n",
    "    # UMAP降维\n",
    "    print(\"\\nPerforming UMAP dimensionality reduction...\")\n",
    "    reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "    \n",
    "    # GEX UMAP\n",
    "    print(\"  - Computing GEX UMAP...\")\n",
    "    gex_umap = reducer.fit_transform(gex_encoded)\n",
    "    gex_umap_df = pd.DataFrame(gex_umap, columns=['UMAP1', 'UMAP2'])\n",
    "    gex_umap_path = os.path.join(output_dir, \"gex_umap.csv\")\n",
    "    gex_umap_df.to_csv(gex_umap_path, index=False)\n",
    "    print(f\"  - GEX UMAP saved to: {gex_umap_path}\")\n",
    "    \n",
    "    # Morpho UMAP\n",
    "    print(\"  - Computing Morpho UMAP...\")\n",
    "    morpho_umap = reducer.fit_transform(morpho_encoded)\n",
    "    morpho_umap_df = pd.DataFrame(morpho_umap, columns=['UMAP1', 'UMAP2'])\n",
    "    morpho_umap_path = os.path.join(output_dir, \"morpho_umap.csv\")\n",
    "    morpho_umap_df.to_csv(morpho_umap_path, index=False)\n",
    "    print(f\"  - Morpho UMAP saved to: {morpho_umap_path}\")\n",
    "    \n",
    "    print(\"\\nDone!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a258b4",
   "metadata": {},
   "source": [
    "## SCJoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78d4fb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "RNA family labels loaded: 10 unique types\n",
      "Data shapes - GEX: (645, 2000), Morpho: (645, 645)\n",
      "Networks initialized successfully\n",
      "Data loaded and normalized. Shape: GEX torch.Size([645, 2000]), Morpho torch.Size([645, 645])\n",
      "Starting scJoint training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training scJoint:  10%|█         | 20/200 [00:28<04:04,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/200\n",
      "  Autoencoder Loss: 2271037.8551\n",
      "  Discriminator Loss: 0.2504\n",
      "  GEX->Morpho Acc: 0.3333\n",
      "  Morpho->GEX Acc: 0.3364\n",
      "  Average Acc: 0.3349\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training scJoint:  20%|██        | 40/200 [00:52<03:18,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40/200\n",
      "  Autoencoder Loss: 2196729.4290\n",
      "  Discriminator Loss: 0.1589\n",
      "  GEX->Morpho Acc: 0.3969\n",
      "  Morpho->GEX Acc: 0.4202\n",
      "  Average Acc: 0.4085\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training scJoint:  30%|███       | 60/200 [01:20<03:34,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 60/200\n",
      "  Autoencoder Loss: 2157874.6080\n",
      "  Discriminator Loss: 0.0517\n",
      "  GEX->Morpho Acc: 0.4295\n",
      "  Morpho->GEX Acc: 0.4946\n",
      "  Average Acc: 0.4620\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training scJoint:  40%|████      | 80/200 [01:53<03:17,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 80/200\n",
      "  Autoencoder Loss: 2119367.9517\n",
      "  Discriminator Loss: 0.0912\n",
      "  GEX->Morpho Acc: 0.3829\n",
      "  Morpho->GEX Acc: 0.5023\n",
      "  Average Acc: 0.4426\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training scJoint:  50%|█████     | 100/200 [02:20<02:24,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100/200\n",
      "  Autoencoder Loss: 2077106.3750\n",
      "  Discriminator Loss: 0.0685\n",
      "  GEX->Morpho Acc: 0.4062\n",
      "  Morpho->GEX Acc: 0.4574\n",
      "  Average Acc: 0.4318\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training scJoint:  60%|██████    | 120/200 [02:43<01:46,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 120/200\n",
      "  Autoencoder Loss: 2026913.9219\n",
      "  Discriminator Loss: 0.0414\n",
      "  GEX->Morpho Acc: 0.4248\n",
      "  Morpho->GEX Acc: 0.4636\n",
      "  Average Acc: 0.4442\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training scJoint:  70%|███████   | 140/200 [03:09<01:27,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 140/200\n",
      "  Autoencoder Loss: 1997084.4105\n",
      "  Discriminator Loss: 0.0722\n",
      "  GEX->Morpho Acc: 0.4248\n",
      "  Morpho->GEX Acc: 0.4589\n",
      "  Average Acc: 0.4419\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training scJoint:  80%|████████  | 160/200 [03:34<00:55,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 160/200\n",
      "  Autoencoder Loss: 1975421.4432\n",
      "  Discriminator Loss: 0.0476\n",
      "  GEX->Morpho Acc: 0.4171\n",
      "  Morpho->GEX Acc: 0.4837\n",
      "  Average Acc: 0.4504\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training scJoint:  90%|█████████ | 180/200 [03:58<00:21,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 180/200\n",
      "  Autoencoder Loss: 1929905.3295\n",
      "  Discriminator Loss: 0.0930\n",
      "  GEX->Morpho Acc: 0.4016\n",
      "  Morpho->GEX Acc: 0.4884\n",
      "  Average Acc: 0.4450\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training scJoint: 100%|██████████| 200/200 [04:24<00:00,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 200/200\n",
      "  Autoencoder Loss: 1897902.4403\n",
      "  Discriminator Loss: 0.0491\n",
      "  GEX->Morpho Acc: 0.4062\n",
      "  Morpho->GEX Acc: 0.4930\n",
      "  Average Acc: 0.4496\n",
      "--------------------------------------------------\n",
      "\n",
      "Getting latent space embeddings...\n",
      "\n",
      "============================================================\n",
      "FINAL scJOINT RESULTS:\n",
      "============================================================\n",
      "GEX -> Morpho Accuracy: 0.4062\n",
      "Morpho -> GEX Accuracy: 0.4930\n",
      "Average Accuracy: 0.4496\n",
      "============================================================\n",
      "\n",
      "Performing UMAP dimensionality reduction...\n",
      "  - Computing GEX UMAP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - GEX UMAP saved to: /home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/writeup20/scJoint/gex_umap.csv\n",
      "  - Computing Morpho UMAP...\n",
      "  - Morpho UMAP saved to: /home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/writeup20/scJoint/morpho_umap.csv\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "class scJointIntegrator:\n",
    "    \"\"\"\n",
    "    scJoint implementation for multi-modal data integration\n",
    "    Based on the scJoint algorithm using transfer learning and adversarial training\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim=64, hidden_dims=[512, 256], lambda_adv=1.0, lambda_recon=10.0,\n",
    "                 lambda_kl=1.0, max_epochs=200, batch_size=64, lr=0.001, device='cuda'):\n",
    "        \"\"\"\n",
    "        Initialize scJoint integrator\n",
    "        \n",
    "        Args:\n",
    "            latent_dim: Dimension of the shared latent space\n",
    "            hidden_dims: Hidden layer dimensions\n",
    "            lambda_adv: Weight for adversarial loss\n",
    "            lambda_recon: Weight for reconstruction loss\n",
    "            lambda_kl: Weight for KL divergence loss\n",
    "            max_epochs: Maximum training epochs\n",
    "            batch_size: Training batch size\n",
    "            lr: Learning rate\n",
    "            device: Computing device\n",
    "        \"\"\"\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.lambda_adv = lambda_adv\n",
    "        self.lambda_recon = lambda_recon\n",
    "        self.lambda_kl = lambda_kl\n",
    "        self.max_epochs = max_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.device = device if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Will be initialized after loading data\n",
    "        self.encoder_gex = None\n",
    "        self.encoder_morpho = None\n",
    "        self.decoder_gex = None\n",
    "        self.decoder_morpho = None\n",
    "        self.discriminator = None\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load multi-modal data\"\"\"\n",
    "        # Gene expression data\n",
    "        gene_expression_path = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/scala/exon_data_top2000.csv\"\n",
    "        gex_df = pd.read_csv(gene_expression_path, header=None)\n",
    "        self.gex_data = gex_df.iloc[:, 1:].to_numpy().astype(np.float32)\n",
    "        \n",
    "        # Morphology data\n",
    "        morphology_path = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/scala/gw_dist.csv\"\n",
    "        morpho_df = pd.read_csv(morphology_path, header=0)\n",
    "        self.morpho_data = morpho_df.iloc[:, 1:].to_numpy().astype(np.float32)\n",
    "        \n",
    "        # RNA family labels\n",
    "        rna_family_path = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/scala/rna_family_matched.csv\"\n",
    "        try:\n",
    "            rna_df = pd.read_csv(rna_family_path, header=0)\n",
    "            if rna_df.shape[1] == 1:\n",
    "                self.rna_family_labels = rna_df.iloc[:, 0].values\n",
    "            else:\n",
    "                self.rna_family_labels = rna_df.iloc[:, 1].values\n",
    "            \n",
    "            min_samples = min(len(self.gex_data), len(self.morpho_data))\n",
    "            self.rna_family_labels = self.rna_family_labels[:min_samples]\n",
    "            self.gex_data = self.gex_data[:min_samples]\n",
    "            self.morpho_data = self.morpho_data[:min_samples]\n",
    "            \n",
    "            print(f\"RNA family labels loaded: {len(np.unique(self.rna_family_labels))} unique types\")\n",
    "            print(f\"Data shapes - GEX: {self.gex_data.shape}, Morpho: {self.morpho_data.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not load RNA family labels: {e}\")\n",
    "            self.rna_family_labels = None\n",
    "        \n",
    "        # Data normalization\n",
    "        self.gex_mean = np.mean(self.gex_data, axis=0)\n",
    "        self.gex_std = np.std(self.gex_data, axis=0) + 1e-8\n",
    "        self.morpho_mean = np.mean(self.morpho_data, axis=0)\n",
    "        self.morpho_std = np.std(self.morpho_data, axis=0) + 1e-8\n",
    "        \n",
    "        self.gex_data_norm = (self.gex_data - self.gex_mean) / self.gex_std\n",
    "        self.morpho_data_norm = (self.morpho_data - self.morpho_mean) / self.morpho_std\n",
    "        \n",
    "        self.n_samples = len(self.gex_data)\n",
    "        self.gex_dim = self.gex_data.shape[1]\n",
    "        self.morpho_dim = self.morpho_data.shape[1]\n",
    "        \n",
    "        # Initialize networks\n",
    "        self._initialize_networks()\n",
    "        \n",
    "        # Convert to tensors\n",
    "        self.gex_tensor = torch.FloatTensor(self.gex_data_norm).to(self.device)\n",
    "        self.morpho_tensor = torch.FloatTensor(self.morpho_data_norm).to(self.device)\n",
    "        \n",
    "        print(f\"Data loaded and normalized. Shape: GEX {self.gex_tensor.shape}, Morpho {self.morpho_tensor.shape}\")\n",
    "        \n",
    "    def _initialize_networks(self):\n",
    "        \"\"\"Initialize encoder, decoder, and discriminator networks\"\"\"\n",
    "        \n",
    "        class Encoder(nn.Module):\n",
    "            def __init__(self, input_dim, latent_dim, hidden_dims):\n",
    "                super(Encoder, self).__init__()\n",
    "                layers = []\n",
    "                prev_dim = input_dim\n",
    "                \n",
    "                for hidden_dim in hidden_dims:\n",
    "                    layers.extend([\n",
    "                        nn.Linear(prev_dim, hidden_dim),\n",
    "                        nn.BatchNorm1d(hidden_dim),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(0.2)\n",
    "                    ])\n",
    "                    prev_dim = hidden_dim\n",
    "                \n",
    "                self.encoder = nn.Sequential(*layers)\n",
    "                \n",
    "                # Variational components\n",
    "                self.mu_layer = nn.Linear(prev_dim, latent_dim)\n",
    "                self.logvar_layer = nn.Linear(prev_dim, latent_dim)\n",
    "                \n",
    "            def forward(self, x):\n",
    "                h = self.encoder(x)\n",
    "                mu = self.mu_layer(h)\n",
    "                logvar = self.logvar_layer(h)\n",
    "                return mu, logvar\n",
    "            \n",
    "            def reparameterize(self, mu, logvar):\n",
    "                if self.training:\n",
    "                    std = torch.exp(0.5 * logvar)\n",
    "                    eps = torch.randn_like(std)\n",
    "                    return mu + eps * std\n",
    "                else:\n",
    "                    return mu\n",
    "        \n",
    "        class Decoder(nn.Module):\n",
    "            def __init__(self, latent_dim, output_dim, hidden_dims):\n",
    "                super(Decoder, self).__init__()\n",
    "                layers = []\n",
    "                prev_dim = latent_dim\n",
    "                \n",
    "                # Reverse the hidden dimensions for decoder\n",
    "                reversed_hidden_dims = hidden_dims[::-1]\n",
    "                \n",
    "                for hidden_dim in reversed_hidden_dims:\n",
    "                    layers.extend([\n",
    "                        nn.Linear(prev_dim, hidden_dim),\n",
    "                        nn.BatchNorm1d(hidden_dim),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(0.2)\n",
    "                    ])\n",
    "                    prev_dim = hidden_dim\n",
    "                \n",
    "                layers.append(nn.Linear(prev_dim, output_dim))\n",
    "                self.decoder = nn.Sequential(*layers)\n",
    "                \n",
    "            def forward(self, z):\n",
    "                return self.decoder(z)\n",
    "        \n",
    "        class Discriminator(nn.Module):\n",
    "            def __init__(self, latent_dim):\n",
    "                super(Discriminator, self).__init__()\n",
    "                self.discriminator = nn.Sequential(\n",
    "                    nn.Linear(latent_dim, 128),\n",
    "                    nn.LeakyReLU(0.2),\n",
    "                    nn.Dropout(0.3),\n",
    "                    nn.Linear(128, 64),\n",
    "                    nn.LeakyReLU(0.2),\n",
    "                    nn.Dropout(0.3),\n",
    "                    nn.Linear(64, 32),\n",
    "                    nn.LeakyReLU(0.2),\n",
    "                    nn.Dropout(0.3),\n",
    "                    nn.Linear(32, 1),\n",
    "                    nn.Sigmoid()\n",
    "                )\n",
    "                \n",
    "            def forward(self, z):\n",
    "                return self.discriminator(z)\n",
    "        \n",
    "        # Initialize networks\n",
    "        self.encoder_gex = Encoder(self.gex_dim, self.latent_dim, self.hidden_dims).to(self.device)\n",
    "        self.encoder_morpho = Encoder(self.morpho_dim, self.latent_dim, self.hidden_dims).to(self.device)\n",
    "        self.decoder_gex = Decoder(self.latent_dim, self.gex_dim, self.hidden_dims).to(self.device)\n",
    "        self.decoder_morpho = Decoder(self.latent_dim, self.morpho_dim, self.hidden_dims).to(self.device)\n",
    "        self.discriminator = Discriminator(self.latent_dim).to(self.device)\n",
    "        \n",
    "        # Initialize optimizers\n",
    "        self.optimizer_ae = optim.Adam(\n",
    "            list(self.encoder_gex.parameters()) + \n",
    "            list(self.encoder_morpho.parameters()) +\n",
    "            list(self.decoder_gex.parameters()) + \n",
    "            list(self.decoder_morpho.parameters()),\n",
    "            lr=self.lr, betas=(0.5, 0.999)\n",
    "        )\n",
    "        \n",
    "        self.optimizer_disc = optim.Adam(\n",
    "            self.discriminator.parameters(),\n",
    "            lr=self.lr, betas=(0.5, 0.999)\n",
    "        )\n",
    "        \n",
    "        print(\"Networks initialized successfully\")\n",
    "        \n",
    "    def _kl_divergence(self, mu, logvar):\n",
    "        \"\"\"Calculate KL divergence loss\"\"\"\n",
    "        return -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    def _reconstruction_loss(self, recon, original):\n",
    "        \"\"\"Calculate reconstruction loss\"\"\"\n",
    "        return F.mse_loss(recon, original, reduction='sum')\n",
    "    \n",
    "    def train_epoch(self, epoch):\n",
    "        \"\"\"Train one epoch\"\"\"\n",
    "        self.encoder_gex.train()\n",
    "        self.encoder_morpho.train()\n",
    "        self.decoder_gex.train()\n",
    "        self.decoder_morpho.train()\n",
    "        self.discriminator.train()\n",
    "        \n",
    "        # Create data indices\n",
    "        indices = torch.randperm(self.n_samples)\n",
    "        n_batches = (self.n_samples + self.batch_size - 1) // self.batch_size\n",
    "        \n",
    "        total_ae_loss = 0\n",
    "        total_disc_loss = 0\n",
    "        \n",
    "        for batch_idx in range(n_batches):\n",
    "            start_idx = batch_idx * self.batch_size\n",
    "            end_idx = min((batch_idx + 1) * self.batch_size, self.n_samples)\n",
    "            batch_indices = indices[start_idx:end_idx]\n",
    "            \n",
    "            gex_batch = self.gex_tensor[batch_indices]\n",
    "            morpho_batch = self.morpho_tensor[batch_indices]\n",
    "            batch_size_actual = len(batch_indices)\n",
    "            \n",
    "            # ==========================================\n",
    "            # Train Autoencoder (Generators)\n",
    "            # ==========================================\n",
    "            self.optimizer_ae.zero_grad()\n",
    "            \n",
    "            # Encode\n",
    "            gex_mu, gex_logvar = self.encoder_gex(gex_batch)\n",
    "            morpho_mu, morpho_logvar = self.encoder_morpho(morpho_batch)\n",
    "            \n",
    "            # Reparameterize\n",
    "            gex_z = self.encoder_gex.reparameterize(gex_mu, gex_logvar)\n",
    "            morpho_z = self.encoder_morpho.reparameterize(morpho_mu, morpho_logvar)\n",
    "            \n",
    "            # Decode (reconstruction)\n",
    "            gex_recon = self.decoder_gex(gex_z)\n",
    "            morpho_recon = self.decoder_morpho(morpho_z)\n",
    "            \n",
    "            # Cross-modal reconstruction (transfer learning)\n",
    "            gex_cross_recon = self.decoder_gex(morpho_z)\n",
    "            morpho_cross_recon = self.decoder_morpho(gex_z)\n",
    "            \n",
    "            # Reconstruction losses\n",
    "            gex_recon_loss = self._reconstruction_loss(gex_recon, gex_batch)\n",
    "            morpho_recon_loss = self._reconstruction_loss(morpho_recon, morpho_batch)\n",
    "            \n",
    "            # Cross-modal reconstruction losses\n",
    "            gex_cross_loss = self._reconstruction_loss(gex_cross_recon, gex_batch)\n",
    "            morpho_cross_loss = self._reconstruction_loss(morpho_cross_recon, morpho_batch)\n",
    "            \n",
    "            # KL divergence losses\n",
    "            gex_kl_loss = self._kl_divergence(gex_mu, gex_logvar)\n",
    "            morpho_kl_loss = self._kl_divergence(morpho_mu, morpho_logvar)\n",
    "            \n",
    "            # Adversarial losses (fool the discriminator)\n",
    "            gex_disc_fake = self.discriminator(gex_z)\n",
    "            morpho_disc_fake = self.discriminator(morpho_z)\n",
    "            \n",
    "            # Labels for adversarial training\n",
    "            valid_labels = torch.ones(batch_size_actual, 1).to(self.device)\n",
    "            \n",
    "            gex_adv_loss = F.binary_cross_entropy(gex_disc_fake, valid_labels)\n",
    "            morpho_adv_loss = F.binary_cross_entropy(morpho_disc_fake, valid_labels)\n",
    "            \n",
    "            # Total autoencoder loss\n",
    "            ae_loss = (self.lambda_recon * (gex_recon_loss + morpho_recon_loss + \n",
    "                                          gex_cross_loss + morpho_cross_loss) +\n",
    "                      self.lambda_kl * (gex_kl_loss + morpho_kl_loss) +\n",
    "                      self.lambda_adv * (gex_adv_loss + morpho_adv_loss))\n",
    "            \n",
    "            ae_loss.backward()\n",
    "            self.optimizer_ae.step()\n",
    "            \n",
    "            # ==========================================\n",
    "            # Train Discriminator\n",
    "            # ==========================================\n",
    "            self.optimizer_disc.zero_grad()\n",
    "            \n",
    "            # Real samples (from prior distribution)\n",
    "            real_z = torch.randn(batch_size_actual, self.latent_dim).to(self.device)\n",
    "            real_labels = torch.ones(batch_size_actual, 1).to(self.device)\n",
    "            fake_labels = torch.zeros(batch_size_actual, 1).to(self.device)\n",
    "            \n",
    "            # Discriminator on real samples\n",
    "            real_disc = self.discriminator(real_z)\n",
    "            real_loss = F.binary_cross_entropy(real_disc, real_labels)\n",
    "            \n",
    "            # Discriminator on fake samples (detached to avoid gradients to encoder)\n",
    "            fake_gex_z = self.encoder_gex.reparameterize(gex_mu.detach(), gex_logvar.detach())\n",
    "            fake_morpho_z = self.encoder_morpho.reparameterize(morpho_mu.detach(), morpho_logvar.detach())\n",
    "            \n",
    "            fake_gex_disc = self.discriminator(fake_gex_z)\n",
    "            fake_morpho_disc = self.discriminator(fake_morpho_z)\n",
    "            \n",
    "            fake_gex_loss = F.binary_cross_entropy(fake_gex_disc, fake_labels)\n",
    "            fake_morpho_loss = F.binary_cross_entropy(fake_morpho_disc, fake_labels)\n",
    "            \n",
    "            # Total discriminator loss\n",
    "            disc_loss = real_loss + (fake_gex_loss + fake_morpho_loss) / 2\n",
    "            \n",
    "            disc_loss.backward()\n",
    "            self.optimizer_disc.step()\n",
    "            \n",
    "            total_ae_loss += ae_loss.item()\n",
    "            total_disc_loss += disc_loss.item()\n",
    "        \n",
    "        return total_ae_loss / n_batches, total_disc_loss / n_batches\n",
    "    \n",
    "    def get_integrated_embeddings(self):\n",
    "        \"\"\"Get integrated embeddings in the shared latent space\"\"\"\n",
    "        self.encoder_gex.eval()\n",
    "        self.encoder_morpho.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            gex_mu, _ = self.encoder_gex(self.gex_tensor)\n",
    "            morpho_mu, _ = self.encoder_morpho(self.morpho_tensor)\n",
    "            \n",
    "            # Use mean (mu) as the embedding for deterministic results\n",
    "            gex_embeddings = gex_mu.cpu().numpy()\n",
    "            morpho_embeddings = morpho_mu.cpu().numpy()\n",
    "        \n",
    "        return gex_embeddings, morpho_embeddings\n",
    "    \n",
    "    def calculate_celltype_accuracy(self, gex_embeddings, morpho_embeddings):\n",
    "        \"\"\"Calculate cell type matching accuracy\"\"\"\n",
    "        if self.rna_family_labels is None:\n",
    "            print(\"No RNA family labels available for accuracy calculation\")\n",
    "            return None, None, None\n",
    "        \n",
    "        # Use nearest neighbor search\n",
    "        nbrs_morpho = NearestNeighbors(n_neighbors=1, metric='euclidean').fit(morpho_embeddings)\n",
    "        nbrs_gex = NearestNeighbors(n_neighbors=1, metric='euclidean').fit(gex_embeddings)\n",
    "        \n",
    "        # GEX to Morpho matching accuracy\n",
    "        _, indices_gex2morpho = nbrs_morpho.kneighbors(gex_embeddings)\n",
    "        gex2morpho_matches = 0\n",
    "        for i, nearest_idx in enumerate(indices_gex2morpho.flatten()):\n",
    "            if self.rna_family_labels[i] == self.rna_family_labels[nearest_idx]:\n",
    "                gex2morpho_matches += 1\n",
    "        gex2morpho_accuracy = gex2morpho_matches / len(self.rna_family_labels)\n",
    "        \n",
    "        # Morpho to GEX matching accuracy\n",
    "        _, indices_morpho2gex = nbrs_gex.kneighbors(morpho_embeddings)\n",
    "        morpho2gex_matches = 0\n",
    "        for i, nearest_idx in enumerate(indices_morpho2gex.flatten()):\n",
    "            if self.rna_family_labels[i] == self.rna_family_labels[nearest_idx]:\n",
    "                morpho2gex_matches += 1\n",
    "        morpho2gex_accuracy = morpho2gex_matches / len(self.rna_family_labels)\n",
    "        \n",
    "        # Average matching accuracy\n",
    "        average_accuracy = (gex2morpho_accuracy + morpho2gex_accuracy) / 2\n",
    "        \n",
    "        return gex2morpho_accuracy, morpho2gex_accuracy, average_accuracy\n",
    "    \n",
    "    def train(self, verbose_interval=20):\n",
    "        \"\"\"Train scJoint model\"\"\"\n",
    "        print(\"Starting scJoint training...\")\n",
    "        \n",
    "        for epoch in tqdm(range(self.max_epochs), desc=\"Training scJoint\"):\n",
    "            ae_loss, disc_loss = self.train_epoch(epoch)\n",
    "            \n",
    "            # Calculate accuracy periodically\n",
    "            if (epoch + 1) % verbose_interval == 0:\n",
    "                gex_emb, morpho_emb = self.get_integrated_embeddings()\n",
    "                gex2morpho_acc, morpho2gex_acc, avg_acc = self.calculate_celltype_accuracy(gex_emb, morpho_emb)\n",
    "                \n",
    "                print(f\"\\nEpoch {epoch+1}/{self.max_epochs}\")\n",
    "                print(f\"  Autoencoder Loss: {ae_loss:.4f}\")\n",
    "                print(f\"  Discriminator Loss: {disc_loss:.4f}\")\n",
    "                if avg_acc is not None:\n",
    "                    print(f\"  GEX->Morpho Acc: {gex2morpho_acc:.4f}\")\n",
    "                    print(f\"  Morpho->GEX Acc: {morpho2gex_acc:.4f}\")\n",
    "                    print(f\"  Average Acc: {avg_acc:.4f}\")\n",
    "                print(\"-\" * 50)\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    # 创建输出目录\n",
    "    output_dir = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/writeup20/scJoint/\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Initialize scJoint integrator\n",
    "    integrator = scJointIntegrator(\n",
    "        latent_dim=64,\n",
    "        hidden_dims=[512, 256],\n",
    "        lambda_adv=1.0,\n",
    "        lambda_recon=10.0,\n",
    "        lambda_kl=1.0,\n",
    "        max_epochs=200,\n",
    "        batch_size=64,\n",
    "        lr=0.001\n",
    "    )\n",
    "    \n",
    "    # Load data\n",
    "    integrator.load_data()\n",
    "    \n",
    "    # Train model\n",
    "    integrator.train(verbose_interval=20)\n",
    "    \n",
    "    # Get final integrated embeddings\n",
    "    print(\"\\nGetting latent space embeddings...\")\n",
    "    final_gex_embeddings, final_morpho_embeddings = integrator.get_integrated_embeddings()\n",
    "    \n",
    "    # Calculate final accuracy\n",
    "    final_gex2morpho_acc, final_morpho2gex_acc, final_avg_acc = integrator.calculate_celltype_accuracy(\n",
    "        final_gex_embeddings, final_morpho_embeddings\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL scJOINT RESULTS:\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"GEX -> Morpho Accuracy: {final_gex2morpho_acc:.4f}\")\n",
    "    print(f\"Morpho -> GEX Accuracy: {final_morpho2gex_acc:.4f}\")\n",
    "    print(f\"Average Accuracy: {final_avg_acc:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # UMAP降维\n",
    "    print(\"\\nPerforming UMAP dimensionality reduction...\")\n",
    "    reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "    \n",
    "    # GEX UMAP\n",
    "    print(\"  - Computing GEX UMAP...\")\n",
    "    gex_umap = reducer.fit_transform(final_gex_embeddings)\n",
    "    gex_umap_df = pd.DataFrame(gex_umap, columns=['UMAP1', 'UMAP2'])\n",
    "    gex_umap_path = os.path.join(output_dir, \"gex_umap.csv\")\n",
    "    gex_umap_df.to_csv(gex_umap_path, index=False)\n",
    "    print(f\"  - GEX UMAP saved to: {gex_umap_path}\")\n",
    "    \n",
    "    # Morpho UMAP\n",
    "    print(\"  - Computing Morpho UMAP...\")\n",
    "    morpho_umap = reducer.fit_transform(final_morpho_embeddings)\n",
    "    morpho_umap_df = pd.DataFrame(morpho_umap, columns=['UMAP1', 'UMAP2'])\n",
    "    morpho_umap_path = os.path.join(output_dir, \"morpho_umap.csv\")\n",
    "    morpho_umap_df.to_csv(morpho_umap_path, index=False)\n",
    "    print(f\"  - Morpho UMAP saved to: {morpho_umap_path}\")\n",
    "    \n",
    "    print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56a776e",
   "metadata": {},
   "source": [
    "## SciCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5915deaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "RNA family labels loaded: 10 unique types\n",
      "Data shapes - GEX: (645, 2000), Morpho: (645, 645)\n",
      "sciCAN networks initialized successfully\n",
      "Data loaded and normalized. Shape: GEX torch.Size([645, 2000]), Morpho torch.Size([645, 645])\n",
      "Starting sciCAN training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training sciCAN:   0%|          | 1/200 [00:02<06:53,  2.08s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training sciCAN:  10%|█         | 20/200 [00:46<06:56,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/200\n",
      "  Generator Loss: 23.8070\n",
      "  Discriminator Loss: 0.3552\n",
      "  CCA Space - GEX->Morpho: 0.2822, Morpho->GEX: 0.3085, Avg: 0.2953\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training sciCAN:  20%|██        | 40/200 [01:30<05:31,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40/200\n",
      "  Generator Loss: 22.9078\n",
      "  Discriminator Loss: 0.2704\n",
      "  CCA Space - GEX->Morpho: 0.3256, Morpho->GEX: 0.3349, Avg: 0.3302\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training sciCAN:  30%|███       | 60/200 [02:17<05:26,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 60/200\n",
      "  Generator Loss: 21.6729\n",
      "  Discriminator Loss: 0.2382\n",
      "  CCA Space - GEX->Morpho: 0.2496, Morpho->GEX: 0.2388, Avg: 0.2442\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training sciCAN:  40%|████      | 80/200 [03:01<04:37,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 80/200\n",
      "  Generator Loss: 22.2730\n",
      "  Discriminator Loss: 0.2998\n",
      "  CCA Space - GEX->Morpho: 0.2403, Morpho->GEX: 0.2682, Avg: 0.2543\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training sciCAN:  50%|█████     | 100/200 [03:45<03:26,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100/200\n",
      "  Generator Loss: 22.0953\n",
      "  Discriminator Loss: 0.2922\n",
      "  CCA Space - GEX->Morpho: 0.2605, Morpho->GEX: 0.2667, Avg: 0.2636\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training sciCAN:  60%|██████    | 120/200 [04:29<03:01,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 120/200\n",
      "  Generator Loss: 24.2103\n",
      "  Discriminator Loss: 0.2308\n",
      "  CCA Space - GEX->Morpho: 0.2140, Morpho->GEX: 0.3457, Avg: 0.2798\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training sciCAN:  70%|███████   | 140/200 [05:14<02:15,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 140/200\n",
      "  Generator Loss: 21.4291\n",
      "  Discriminator Loss: 0.3290\n",
      "  CCA Space - GEX->Morpho: 0.2388, Morpho->GEX: 0.2481, Avg: 0.2434\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training sciCAN:  80%|████████  | 160/200 [05:58<01:38,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 160/200\n",
      "  Generator Loss: 22.7924\n",
      "  Discriminator Loss: 0.3033\n",
      "  CCA Space - GEX->Morpho: 0.2698, Morpho->GEX: 0.2620, Avg: 0.2659\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training sciCAN:  90%|█████████ | 180/200 [06:38<00:43,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 180/200\n",
      "  Generator Loss: 23.6537\n",
      "  Discriminator Loss: 0.3259\n",
      "  CCA Space - GEX->Morpho: 0.2837, Morpho->GEX: 0.2527, Avg: 0.2682\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training sciCAN: 100%|██████████| 200/200 [07:21<00:00,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 200/200\n",
      "  Generator Loss: 23.0546\n",
      "  Discriminator Loss: 0.2644\n",
      "  CCA Space - GEX->Morpho: 0.2264, Morpho->GEX: 0.2884, Avg: 0.2574\n",
      "--------------------------------------------------\n",
      "\n",
      "Getting latent space embeddings (CCA space)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL sciCAN RESULTS (CCA Space):\n",
      "============================================================\n",
      "GEX -> Morpho Accuracy: 0.2264\n",
      "Morpho -> GEX Accuracy: 0.2884\n",
      "Average Accuracy: 0.2574\n",
      "============================================================\n",
      "\n",
      "Performing UMAP dimensionality reduction...\n",
      "  - Computing GEX UMAP...\n",
      "  - GEX UMAP saved to: /home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/writeup20/sciCAN/gex_umap.csv\n",
      "  - Computing Morpho UMAP...\n",
      "  - Morpho UMAP saved to: /home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/writeup20/sciCAN/morpho_umap.csv\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "class sciCANIntegrator:\n",
    "    \"\"\"\n",
    "    sciCAN implementation for multi-modal data integration\n",
    "    Based on the sciCAN algorithm using Canonical Correlation Analysis and \n",
    "    Adversarial Networks for single-cell multi-omics integration\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cca_dim=50, adversarial_dim=128, hidden_dims=[512, 256], \n",
    "                 lambda_cca=1.0, lambda_adv=1.0, lambda_recon=10.0, lambda_cycle=5.0,\n",
    "                 max_epochs=200, batch_size=64, lr=0.001, device='cuda'):\n",
    "        \"\"\"\n",
    "        Initialize sciCAN integrator\n",
    "        \n",
    "        Args:\n",
    "            cca_dim: Dimension of CCA space\n",
    "            adversarial_dim: Dimension of adversarial feature space\n",
    "            hidden_dims: Hidden layer dimensions\n",
    "            lambda_cca: Weight for CCA loss\n",
    "            lambda_adv: Weight for adversarial loss\n",
    "            lambda_recon: Weight for reconstruction loss\n",
    "            lambda_cycle: Weight for cycle consistency loss\n",
    "            max_epochs: Maximum training epochs\n",
    "            batch_size: Training batch size\n",
    "            lr: Learning rate\n",
    "            device: Computing device\n",
    "        \"\"\"\n",
    "        self.cca_dim = cca_dim\n",
    "        self.adversarial_dim = adversarial_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.lambda_cca = lambda_cca\n",
    "        self.lambda_adv = lambda_adv\n",
    "        self.lambda_recon = lambda_recon\n",
    "        self.lambda_cycle = lambda_cycle\n",
    "        self.max_epochs = max_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.device = device if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Networks will be initialized after loading data\n",
    "        self.encoder_gex = None\n",
    "        self.encoder_morpho = None\n",
    "        self.decoder_gex = None\n",
    "        self.decoder_morpho = None\n",
    "        self.cca_projector_gex = None\n",
    "        self.cca_projector_morpho = None\n",
    "        self.discriminator = None\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load multi-modal data\"\"\"\n",
    "        # Gene expression data\n",
    "        gene_expression_path = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/scala/exon_data_top2000.csv\"\n",
    "        gex_df = pd.read_csv(gene_expression_path, header=None)\n",
    "        self.gex_data = gex_df.iloc[:, 1:].to_numpy().astype(np.float32)\n",
    "        \n",
    "        # Morphology data\n",
    "        morphology_path = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/scala/gw_dist.csv\"\n",
    "        morpho_df = pd.read_csv(morphology_path, header=0)\n",
    "        self.morpho_data = morpho_df.iloc[:, 1:].to_numpy().astype(np.float32)\n",
    "        \n",
    "        # RNA family labels\n",
    "        rna_family_path = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/scala/rna_family_matched.csv\"\n",
    "        try:\n",
    "            rna_df = pd.read_csv(rna_family_path, header=0)\n",
    "            if rna_df.shape[1] == 1:\n",
    "                self.rna_family_labels = rna_df.iloc[:, 0].values\n",
    "            else:\n",
    "                self.rna_family_labels = rna_df.iloc[:, 1].values\n",
    "            \n",
    "            min_samples = min(len(self.gex_data), len(self.morpho_data))\n",
    "            self.rna_family_labels = self.rna_family_labels[:min_samples]\n",
    "            self.gex_data = self.gex_data[:min_samples]\n",
    "            self.morpho_data = self.morpho_data[:min_samples]\n",
    "            \n",
    "            print(f\"RNA family labels loaded: {len(np.unique(self.rna_family_labels))} unique types\")\n",
    "            print(f\"Data shapes - GEX: {self.gex_data.shape}, Morpho: {self.morpho_data.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not load RNA family labels: {e}\")\n",
    "            self.rna_family_labels = None\n",
    "        \n",
    "        # Data normalization\n",
    "        self.gex_mean = np.mean(self.gex_data, axis=0)\n",
    "        self.gex_std = np.std(self.gex_data, axis=0) + 1e-8\n",
    "        self.morpho_mean = np.mean(self.morpho_data, axis=0)\n",
    "        self.morpho_std = np.std(self.morpho_data, axis=0) + 1e-8\n",
    "        \n",
    "        self.gex_data_norm = (self.gex_data - self.gex_mean) / self.gex_std\n",
    "        self.morpho_data_norm = (self.morpho_data - self.morpho_mean) / self.morpho_std\n",
    "        \n",
    "        self.n_samples = len(self.gex_data)\n",
    "        self.gex_dim = self.gex_data.shape[1]\n",
    "        self.morpho_dim = self.morpho_data.shape[1]\n",
    "        \n",
    "        # Initialize networks\n",
    "        self._initialize_networks()\n",
    "        \n",
    "        # Convert to tensors\n",
    "        self.gex_tensor = torch.FloatTensor(self.gex_data_norm).to(self.device)\n",
    "        self.morpho_tensor = torch.FloatTensor(self.morpho_data_norm).to(self.device)\n",
    "        \n",
    "        print(f\"Data loaded and normalized. Shape: GEX {self.gex_tensor.shape}, Morpho {self.morpho_tensor.shape}\")\n",
    "        \n",
    "    def _initialize_networks(self):\n",
    "        \"\"\"Initialize neural networks for sciCAN\"\"\"\n",
    "        \n",
    "        class Encoder(nn.Module):\n",
    "            def __init__(self, input_dim, hidden_dims, output_dim):\n",
    "                super(Encoder, self).__init__()\n",
    "                layers = []\n",
    "                prev_dim = input_dim\n",
    "                \n",
    "                for hidden_dim in hidden_dims:\n",
    "                    layers.extend([\n",
    "                        nn.Linear(prev_dim, hidden_dim),\n",
    "                        nn.BatchNorm1d(hidden_dim),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(0.2)\n",
    "                    ])\n",
    "                    prev_dim = hidden_dim\n",
    "                \n",
    "                layers.append(nn.Linear(prev_dim, output_dim))\n",
    "                layers.append(nn.Tanh())\n",
    "                self.encoder = nn.Sequential(*layers)\n",
    "                \n",
    "            def forward(self, x):\n",
    "                return self.encoder(x)\n",
    "        \n",
    "        class Decoder(nn.Module):\n",
    "            def __init__(self, input_dim, hidden_dims, output_dim):\n",
    "                super(Decoder, self).__init__()\n",
    "                layers = []\n",
    "                prev_dim = input_dim\n",
    "                \n",
    "                reversed_hidden_dims = hidden_dims[::-1]\n",
    "                \n",
    "                for hidden_dim in reversed_hidden_dims:\n",
    "                    layers.extend([\n",
    "                        nn.Linear(prev_dim, hidden_dim),\n",
    "                        nn.BatchNorm1d(hidden_dim),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(0.2)\n",
    "                    ])\n",
    "                    prev_dim = hidden_dim\n",
    "                \n",
    "                layers.append(nn.Linear(prev_dim, output_dim))\n",
    "                self.decoder = nn.Sequential(*layers)\n",
    "                \n",
    "            def forward(self, x):\n",
    "                return self.decoder(x)\n",
    "        \n",
    "        class CCAProjector(nn.Module):\n",
    "            def __init__(self, input_dim, cca_dim):\n",
    "                super(CCAProjector, self).__init__()\n",
    "                self.projector = nn.Sequential(\n",
    "                    nn.Linear(input_dim, cca_dim),\n",
    "                    nn.BatchNorm1d(cca_dim)\n",
    "                )\n",
    "                \n",
    "            def forward(self, x):\n",
    "                return self.projector(x)\n",
    "        \n",
    "        class Discriminator(nn.Module):\n",
    "            def __init__(self, input_dim):\n",
    "                super(Discriminator, self).__init__()\n",
    "                self.discriminator = nn.Sequential(\n",
    "                    nn.Linear(input_dim, 256),\n",
    "                    nn.LeakyReLU(0.2),\n",
    "                    nn.Dropout(0.3),\n",
    "                    nn.Linear(256, 128),\n",
    "                    nn.LeakyReLU(0.2),\n",
    "                    nn.Dropout(0.3),\n",
    "                    nn.Linear(128, 64),\n",
    "                    nn.LeakyReLU(0.2),\n",
    "                    nn.Dropout(0.3),\n",
    "                    nn.Linear(64, 1),\n",
    "                    nn.Sigmoid()\n",
    "                )\n",
    "                \n",
    "            def forward(self, x):\n",
    "                return self.discriminator(x)\n",
    "        \n",
    "        # Initialize networks\n",
    "        self.encoder_gex = Encoder(self.gex_dim, self.hidden_dims, self.adversarial_dim).to(self.device)\n",
    "        self.encoder_morpho = Encoder(self.morpho_dim, self.hidden_dims, self.adversarial_dim).to(self.device)\n",
    "        \n",
    "        self.decoder_gex = Decoder(self.adversarial_dim, self.hidden_dims, self.gex_dim).to(self.device)\n",
    "        self.decoder_morpho = Decoder(self.adversarial_dim, self.hidden_dims, self.morpho_dim).to(self.device)\n",
    "        \n",
    "        self.cca_projector_gex = CCAProjector(self.adversarial_dim, self.cca_dim).to(self.device)\n",
    "        self.cca_projector_morpho = CCAProjector(self.adversarial_dim, self.cca_dim).to(self.device)\n",
    "        \n",
    "        self.discriminator = Discriminator(self.adversarial_dim).to(self.device)\n",
    "        \n",
    "        # Initialize optimizers\n",
    "        self.optimizer_generators = optim.Adam(\n",
    "            list(self.encoder_gex.parameters()) + \n",
    "            list(self.encoder_morpho.parameters()) +\n",
    "            list(self.decoder_gex.parameters()) + \n",
    "            list(self.decoder_morpho.parameters()) +\n",
    "            list(self.cca_projector_gex.parameters()) +\n",
    "            list(self.cca_projector_morpho.parameters()),\n",
    "            lr=self.lr, betas=(0.5, 0.999)\n",
    "        )\n",
    "        \n",
    "        self.optimizer_discriminator = optim.Adam(\n",
    "            self.discriminator.parameters(),\n",
    "            lr=self.lr, betas=(0.5, 0.999)\n",
    "        )\n",
    "        \n",
    "        print(\"sciCAN networks initialized successfully\")\n",
    "        \n",
    "    def _canonical_correlation_loss(self, h1, h2):\n",
    "        \"\"\"Calculate Canonical Correlation Analysis loss\"\"\"\n",
    "        h1_centered = h1 - torch.mean(h1, dim=0, keepdim=True)\n",
    "        h2_centered = h2 - torch.mean(h2, dim=0, keepdim=True)\n",
    "        \n",
    "        n = h1.size(0)\n",
    "        c11 = torch.mm(h1_centered.t(), h1_centered) / (n - 1)\n",
    "        c22 = torch.mm(h2_centered.t(), h2_centered) / (n - 1)\n",
    "        c12 = torch.mm(h1_centered.t(), h2_centered) / (n - 1)\n",
    "        \n",
    "        eps = 1e-4\n",
    "        c11 = c11 + eps * torch.eye(c11.size(0)).to(self.device)\n",
    "        c22 = c22 + eps * torch.eye(c22.size(0)).to(self.device)\n",
    "        \n",
    "        correlation = torch.trace(c12) / (torch.sqrt(torch.trace(c11)) * torch.sqrt(torch.trace(c22)) + 1e-8)\n",
    "        \n",
    "        return -correlation\n",
    "    \n",
    "    def _reconstruction_loss(self, recon, original):\n",
    "        \"\"\"Calculate reconstruction loss\"\"\"\n",
    "        return F.mse_loss(recon, original)\n",
    "    \n",
    "    def _cycle_consistency_loss(self, cycle_recon, original):\n",
    "        \"\"\"Calculate cycle consistency loss\"\"\"\n",
    "        return F.l1_loss(cycle_recon, original)\n",
    "    \n",
    "    def train_epoch(self, epoch):\n",
    "        \"\"\"Train one epoch\"\"\"\n",
    "        self.encoder_gex.train()\n",
    "        self.encoder_morpho.train()\n",
    "        self.decoder_gex.train()\n",
    "        self.decoder_morpho.train()\n",
    "        self.cca_projector_gex.train()\n",
    "        self.cca_projector_morpho.train()\n",
    "        self.discriminator.train()\n",
    "        \n",
    "        indices = torch.randperm(self.n_samples)\n",
    "        n_batches = (self.n_samples + self.batch_size - 1) // self.batch_size\n",
    "        \n",
    "        total_gen_loss = 0\n",
    "        total_disc_loss = 0\n",
    "        \n",
    "        for batch_idx in range(n_batches):\n",
    "            start_idx = batch_idx * self.batch_size\n",
    "            end_idx = min((batch_idx + 1) * self.batch_size, self.n_samples)\n",
    "            batch_indices = indices[start_idx:end_idx]\n",
    "            \n",
    "            gex_batch = self.gex_tensor[batch_indices]\n",
    "            morpho_batch = self.morpho_tensor[batch_indices]\n",
    "            batch_size_actual = len(batch_indices)\n",
    "            \n",
    "            valid = torch.ones(batch_size_actual, 1).to(self.device)\n",
    "            fake = torch.zeros(batch_size_actual, 1).to(self.device)\n",
    "            \n",
    "            # Train Generators\n",
    "            self.optimizer_generators.zero_grad()\n",
    "            \n",
    "            gex_features = self.encoder_gex(gex_batch)\n",
    "            morpho_features = self.encoder_morpho(morpho_batch)\n",
    "            \n",
    "            gex_cca = self.cca_projector_gex(gex_features)\n",
    "            morpho_cca = self.cca_projector_morpho(morpho_features)\n",
    "            \n",
    "            gex_recon = self.decoder_gex(gex_features)\n",
    "            morpho_recon = self.decoder_morpho(morpho_features)\n",
    "            \n",
    "            gex_recon_loss = self._reconstruction_loss(gex_recon, gex_batch)\n",
    "            morpho_recon_loss = self._reconstruction_loss(morpho_recon, morpho_batch)\n",
    "            \n",
    "            gex_from_morpho = self.decoder_gex(morpho_features)\n",
    "            morpho_from_gex = self.decoder_morpho(gex_features)\n",
    "            \n",
    "            morpho_features_cycle = self.encoder_morpho(morpho_from_gex)\n",
    "            gex_features_cycle = self.encoder_gex(gex_from_morpho)\n",
    "            \n",
    "            gex_cycle_recon = self.decoder_gex(gex_features_cycle)\n",
    "            morpho_cycle_recon = self.decoder_morpho(morpho_features_cycle)\n",
    "            \n",
    "            gex_cycle_loss = self._cycle_consistency_loss(gex_cycle_recon, gex_batch)\n",
    "            morpho_cycle_loss = self._cycle_consistency_loss(morpho_cycle_recon, morpho_batch)\n",
    "            \n",
    "            cca_loss = self._canonical_correlation_loss(gex_cca, morpho_cca)\n",
    "            \n",
    "            gex_disc_fake = self.discriminator(gex_features)\n",
    "            morpho_disc_fake = self.discriminator(morpho_features)\n",
    "            \n",
    "            gex_adv_loss = F.binary_cross_entropy(gex_disc_fake, valid)\n",
    "            morpho_adv_loss = F.binary_cross_entropy(morpho_disc_fake, valid)\n",
    "            \n",
    "            gen_loss = (self.lambda_recon * (gex_recon_loss + morpho_recon_loss) +\n",
    "                       self.lambda_cycle * (gex_cycle_loss + morpho_cycle_loss) +\n",
    "                       self.lambda_cca * cca_loss +\n",
    "                       self.lambda_adv * (gex_adv_loss + morpho_adv_loss))\n",
    "            \n",
    "            gen_loss.backward()\n",
    "            self.optimizer_generators.step()\n",
    "            \n",
    "            # Train Discriminator\n",
    "            self.optimizer_discriminator.zero_grad()\n",
    "            \n",
    "            real_features = torch.randn(batch_size_actual, self.adversarial_dim).to(self.device)\n",
    "            \n",
    "            real_pred = self.discriminator(real_features)\n",
    "            real_loss = F.binary_cross_entropy(real_pred, valid)\n",
    "            \n",
    "            fake_gex_features = self.encoder_gex(gex_batch).detach()\n",
    "            fake_morpho_features = self.encoder_morpho(morpho_batch).detach()\n",
    "            \n",
    "            fake_gex_pred = self.discriminator(fake_gex_features)\n",
    "            fake_morpho_pred = self.discriminator(fake_morpho_features)\n",
    "            \n",
    "            fake_gex_loss = F.binary_cross_entropy(fake_gex_pred, fake)\n",
    "            fake_morpho_loss = F.binary_cross_entropy(fake_morpho_pred, fake)\n",
    "            \n",
    "            disc_loss = real_loss + (fake_gex_loss + fake_morpho_loss) / 2\n",
    "            \n",
    "            disc_loss.backward()\n",
    "            self.optimizer_discriminator.step()\n",
    "            \n",
    "            total_gen_loss += gen_loss.item()\n",
    "            total_disc_loss += disc_loss.item()\n",
    "        \n",
    "        return total_gen_loss / n_batches, total_disc_loss / n_batches\n",
    "    \n",
    "    def get_integrated_embeddings(self):\n",
    "        \"\"\"Get integrated embeddings in the CCA space\"\"\"\n",
    "        self.encoder_gex.eval()\n",
    "        self.encoder_morpho.eval()\n",
    "        self.cca_projector_gex.eval()\n",
    "        self.cca_projector_morpho.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            gex_features = self.encoder_gex(self.gex_tensor)\n",
    "            morpho_features = self.encoder_morpho(self.morpho_tensor)\n",
    "            \n",
    "            gex_embeddings = self.cca_projector_gex(gex_features).cpu().numpy()\n",
    "            morpho_embeddings = self.cca_projector_morpho(morpho_features).cpu().numpy()\n",
    "        \n",
    "        return gex_embeddings, morpho_embeddings\n",
    "    \n",
    "    def calculate_celltype_accuracy(self, gex_embeddings, morpho_embeddings):\n",
    "        \"\"\"Calculate cell type matching accuracy\"\"\"\n",
    "        if self.rna_family_labels is None:\n",
    "            print(\"No RNA family labels available for accuracy calculation\")\n",
    "            return None, None, None\n",
    "        \n",
    "        nbrs_morpho = NearestNeighbors(n_neighbors=1, metric='euclidean').fit(morpho_embeddings)\n",
    "        nbrs_gex = NearestNeighbors(n_neighbors=1, metric='euclidean').fit(gex_embeddings)\n",
    "        \n",
    "        _, indices_gex2morpho = nbrs_morpho.kneighbors(gex_embeddings)\n",
    "        gex2morpho_matches = 0\n",
    "        for i, nearest_idx in enumerate(indices_gex2morpho.flatten()):\n",
    "            if self.rna_family_labels[i] == self.rna_family_labels[nearest_idx]:\n",
    "                gex2morpho_matches += 1\n",
    "        gex2morpho_accuracy = gex2morpho_matches / len(self.rna_family_labels)\n",
    "        \n",
    "        _, indices_morpho2gex = nbrs_gex.kneighbors(morpho_embeddings)\n",
    "        morpho2gex_matches = 0\n",
    "        for i, nearest_idx in enumerate(indices_morpho2gex.flatten()):\n",
    "            if self.rna_family_labels[i] == self.rna_family_labels[nearest_idx]:\n",
    "                morpho2gex_matches += 1\n",
    "        morpho2gex_accuracy = morpho2gex_matches / len(self.rna_family_labels)\n",
    "        \n",
    "        average_accuracy = (gex2morpho_accuracy + morpho2gex_accuracy) / 2\n",
    "        \n",
    "        return gex2morpho_accuracy, morpho2gex_accuracy, average_accuracy\n",
    "    \n",
    "    def train(self, verbose_interval=20):\n",
    "        \"\"\"Train sciCAN model\"\"\"\n",
    "        print(\"Starting sciCAN training...\")\n",
    "        \n",
    "        for epoch in tqdm(range(self.max_epochs), desc=\"Training sciCAN\"):\n",
    "            gen_loss, disc_loss = self.train_epoch(epoch)\n",
    "            \n",
    "            if (epoch + 1) % verbose_interval == 0:\n",
    "                gex_emb_cca, morpho_emb_cca = self.get_integrated_embeddings()\n",
    "                gex2morpho_acc_cca, morpho2gex_acc_cca, avg_acc_cca = self.calculate_celltype_accuracy(\n",
    "                    gex_emb_cca, morpho_emb_cca)\n",
    "                \n",
    "                print(f\"\\nEpoch {epoch+1}/{self.max_epochs}\")\n",
    "                print(f\"  Generator Loss: {gen_loss:.4f}\")\n",
    "                print(f\"  Discriminator Loss: {disc_loss:.4f}\")\n",
    "                if avg_acc_cca is not None:\n",
    "                    print(f\"  CCA Space - GEX->Morpho: {gex2morpho_acc_cca:.4f}, Morpho->GEX: {morpho2gex_acc_cca:.4f}, Avg: {avg_acc_cca:.4f}\")\n",
    "                print(\"-\" * 50)\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    # 创建输出目录\n",
    "    output_dir = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/writeup20/sciCAN/\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Initialize sciCAN integrator\n",
    "    integrator = sciCANIntegrator(\n",
    "        cca_dim=50,\n",
    "        adversarial_dim=128,\n",
    "        hidden_dims=[512, 256],\n",
    "        lambda_cca=1.0,\n",
    "        lambda_adv=1.0,\n",
    "        lambda_recon=10.0,\n",
    "        lambda_cycle=5.0,\n",
    "        max_epochs=200,\n",
    "        batch_size=64,\n",
    "        lr=0.001\n",
    "    )\n",
    "    \n",
    "    # Load data\n",
    "    integrator.load_data()\n",
    "    \n",
    "    # Train model\n",
    "    integrator.train(verbose_interval=20)\n",
    "    \n",
    "    # Get final integrated embeddings (CCA space)\n",
    "    print(\"\\nGetting latent space embeddings (CCA space)...\")\n",
    "    final_gex_embeddings, final_morpho_embeddings = integrator.get_integrated_embeddings()\n",
    "    \n",
    "    # Calculate final accuracy\n",
    "    final_gex2morpho_acc, final_morpho2gex_acc, final_avg_acc = integrator.calculate_celltype_accuracy(\n",
    "        final_gex_embeddings, final_morpho_embeddings\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL sciCAN RESULTS (CCA Space):\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"GEX -> Morpho Accuracy: {final_gex2morpho_acc:.4f}\")\n",
    "    print(f\"Morpho -> GEX Accuracy: {final_morpho2gex_acc:.4f}\")\n",
    "    print(f\"Average Accuracy: {final_avg_acc:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # UMAP降维\n",
    "    print(\"\\nPerforming UMAP dimensionality reduction...\")\n",
    "    reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "    \n",
    "    # GEX UMAP\n",
    "    print(\"  - Computing GEX UMAP...\")\n",
    "    gex_umap = reducer.fit_transform(final_gex_embeddings)\n",
    "    gex_umap_df = pd.DataFrame(gex_umap, columns=['UMAP1', 'UMAP2'])\n",
    "    gex_umap_path = os.path.join(output_dir, \"gex_umap.csv\")\n",
    "    gex_umap_df.to_csv(gex_umap_path, index=False)\n",
    "    print(f\"  - GEX UMAP saved to: {gex_umap_path}\")\n",
    "    \n",
    "    # Morpho UMAP\n",
    "    print(\"  - Computing Morpho UMAP...\")\n",
    "    morpho_umap = reducer.fit_transform(final_morpho_embeddings)\n",
    "    morpho_umap_df = pd.DataFrame(morpho_umap, columns=['UMAP1', 'UMAP2'])\n",
    "    morpho_umap_path = os.path.join(output_dir, \"morpho_umap.csv\")\n",
    "    morpho_umap_df.to_csv(morpho_umap_path, index=False)\n",
    "    print(f\"  - Morpho UMAP saved to: {morpho_umap_path}\")\n",
    "    \n",
    "    print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2acb29",
   "metadata": {},
   "source": [
    "## ScDART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9bbbcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "RNA family labels loaded: 10 unique types\n",
      "Data shapes - GEX: (645, 2000), Morpho: (645, 645)\n",
      "scDART networks initialized successfully\n",
      "Data loaded and normalized. Shape: GEX torch.Size([645, 2000]), Morpho torch.Size([645, 645])\n",
      "Starting scDART training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training scDART:  10%|█         | 20/200 [00:26<04:02,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/200\n",
      "  Main Loss: 2.8273\n",
      "  Domain Loss: 0.7019\n",
      "  GEX->Morpho Acc: 0.2202\n",
      "  Morpho->GEX Acc: 0.3318\n",
      "  Average Acc: 0.2760\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training scDART:  14%|█▍        | 28/200 [00:38<04:06,  1.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training scDART:  20%|██        | 40/200 [00:55<03:47,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40/200\n",
      "  Main Loss: 2.6777\n",
      "  Domain Loss: 0.6097\n",
      "  GEX->Morpho Acc: 0.2791\n",
      "  Morpho->GEX Acc: 0.3054\n",
      "  Average Acc: 0.2922\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training scDART:  30%|███       | 60/200 [01:21<03:18,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 60/200\n",
      "  Main Loss: 2.7183\n",
      "  Domain Loss: 0.6246\n",
      "  GEX->Morpho Acc: 0.2698\n",
      "  Morpho->GEX Acc: 0.2946\n",
      "  Average Acc: 0.2822\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training scDART:  40%|████      | 80/200 [01:49<02:36,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 80/200\n",
      "  Main Loss: 2.5507\n",
      "  Domain Loss: 0.5971\n",
      "  GEX->Morpho Acc: 0.3132\n",
      "  Morpho->GEX Acc: 0.2512\n",
      "  Average Acc: 0.2822\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training scDART:  50%|█████     | 100/200 [02:17<02:16,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100/200\n",
      "  Main Loss: 2.6574\n",
      "  Domain Loss: 0.7248\n",
      "  GEX->Morpho Acc: 0.2775\n",
      "  Morpho->GEX Acc: 0.3008\n",
      "  Average Acc: 0.2891\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training scDART:  60%|██████    | 120/200 [02:50<01:54,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 120/200\n",
      "  Main Loss: 2.6673\n",
      "  Domain Loss: 0.6804\n",
      "  GEX->Morpho Acc: 0.3194\n",
      "  Morpho->GEX Acc: 0.3163\n",
      "  Average Acc: 0.3178\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training scDART:  70%|███████   | 140/200 [03:17<01:23,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 140/200\n",
      "  Main Loss: 2.7772\n",
      "  Domain Loss: 0.7212\n",
      "  GEX->Morpho Acc: 0.3411\n",
      "  Morpho->GEX Acc: 0.2202\n",
      "  Average Acc: 0.2806\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training scDART:  80%|████████  | 160/200 [03:45<00:53,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 160/200\n",
      "  Main Loss: 2.8382\n",
      "  Domain Loss: 0.7134\n",
      "  GEX->Morpho Acc: 0.3411\n",
      "  Morpho->GEX Acc: 0.3318\n",
      "  Average Acc: 0.3364\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training scDART:  90%|█████████ | 180/200 [04:13<00:27,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 180/200\n",
      "  Main Loss: 2.6912\n",
      "  Domain Loss: 0.6995\n",
      "  GEX->Morpho Acc: 0.3581\n",
      "  Morpho->GEX Acc: 0.3969\n",
      "  Average Acc: 0.3775\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training scDART: 100%|██████████| 200/200 [04:42<00:00,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 200/200\n",
      "  Main Loss: 2.5664\n",
      "  Domain Loss: 0.6722\n",
      "  GEX->Morpho Acc: 0.3690\n",
      "  Morpho->GEX Acc: 0.3953\n",
      "  Average Acc: 0.3822\n",
      "--------------------------------------------------\n",
      "\n",
      "Getting latent space embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL scDART RESULTS:\n",
      "============================================================\n",
      "GEX -> Morpho Accuracy: 0.3690\n",
      "Morpho -> GEX Accuracy: 0.3953\n",
      "Average Accuracy: 0.3822\n",
      "============================================================\n",
      "\n",
      "Performing UMAP dimensionality reduction...\n",
      "  - Computing GEX UMAP...\n",
      "  - GEX UMAP saved to: /home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/writeup20/scDART/gex_umap.csv\n",
      "  - Computing Morpho UMAP...\n",
      "  - Morpho UMAP saved to: /home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/writeup20/scDART/morpho_umap.csv\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "class scDARTIntegrator:\n",
    "    \"\"\"\n",
    "    scDART implementation for multi-modal data integration\n",
    "    Based on the scDART algorithm using domain adversarial neural networks\n",
    "    for single-cell multi-omics data integration\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim=128, feature_dims=[512, 256], domain_dims=[256, 128], \n",
    "                 lambda_domain=1.0, lambda_recon=1.0, lambda_cluster=0.1, lambda_entropy=0.01,\n",
    "                 max_epochs=200, batch_size=64, lr=0.001, gradient_reversal_alpha=1.0, device='cuda'):\n",
    "        \"\"\"\n",
    "        Initialize scDART integrator\n",
    "        \n",
    "        Args:\n",
    "            latent_dim: Dimension of the shared feature space\n",
    "            feature_dims: Hidden dimensions for feature extractor\n",
    "            domain_dims: Hidden dimensions for domain classifier\n",
    "            lambda_domain: Weight for domain adversarial loss\n",
    "            lambda_recon: Weight for reconstruction loss\n",
    "            lambda_cluster: Weight for clustering loss\n",
    "            lambda_entropy: Weight for entropy loss\n",
    "            max_epochs: Maximum training epochs\n",
    "            batch_size: Training batch size\n",
    "            lr: Learning rate\n",
    "            gradient_reversal_alpha: Strength of gradient reversal\n",
    "            device: Computing device\n",
    "        \"\"\"\n",
    "        self.latent_dim = latent_dim\n",
    "        self.feature_dims = feature_dims\n",
    "        self.domain_dims = domain_dims\n",
    "        self.lambda_domain = lambda_domain\n",
    "        self.lambda_recon = lambda_recon\n",
    "        self.lambda_cluster = lambda_cluster\n",
    "        self.lambda_entropy = lambda_entropy\n",
    "        self.max_epochs = max_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.gradient_reversal_alpha = gradient_reversal_alpha\n",
    "        self.device = device if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Networks will be initialized after loading data\n",
    "        self.feature_extractor = None\n",
    "        self.domain_classifier = None\n",
    "        self.decoder_gex = None\n",
    "        self.decoder_morpho = None\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load multi-modal data\"\"\"\n",
    "        # Gene expression data\n",
    "        gene_expression_path = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/scala/exon_data_top2000.csv\"\n",
    "        gex_df = pd.read_csv(gene_expression_path, header=None)\n",
    "        self.gex_data = gex_df.iloc[:, 1:].to_numpy().astype(np.float32)\n",
    "        \n",
    "        # Morphology data\n",
    "        morphology_path = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/scala/gw_dist.csv\"\n",
    "        morpho_df = pd.read_csv(morphology_path, header=0)\n",
    "        self.morpho_data = morpho_df.iloc[:, 1:].to_numpy().astype(np.float32)\n",
    "        \n",
    "        # RNA family labels\n",
    "        rna_family_path = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/scala/rna_family_matched.csv\"\n",
    "        try:\n",
    "            rna_df = pd.read_csv(rna_family_path, header=0)\n",
    "            if rna_df.shape[1] == 1:\n",
    "                self.rna_family_labels = rna_df.iloc[:, 0].values\n",
    "            else:\n",
    "                self.rna_family_labels = rna_df.iloc[:, 1].values\n",
    "            \n",
    "            min_samples = min(len(self.gex_data), len(self.morpho_data))\n",
    "            self.rna_family_labels = self.rna_family_labels[:min_samples]\n",
    "            self.gex_data = self.gex_data[:min_samples]\n",
    "            self.morpho_data = self.morpho_data[:min_samples]\n",
    "            \n",
    "            # Convert labels to numeric for clustering loss\n",
    "            unique_labels = np.unique(self.rna_family_labels)\n",
    "            self.label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "            self.numeric_labels = np.array([self.label_to_idx[label] for label in self.rna_family_labels])\n",
    "            self.n_classes = len(unique_labels)\n",
    "            \n",
    "            print(f\"RNA family labels loaded: {self.n_classes} unique types\")\n",
    "            print(f\"Data shapes - GEX: {self.gex_data.shape}, Morpho: {self.morpho_data.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not load RNA family labels: {e}\")\n",
    "            self.rna_family_labels = None\n",
    "            self.n_classes = 10  # Default number of clusters\n",
    "        \n",
    "        # Data normalization\n",
    "        self.gex_mean = np.mean(self.gex_data, axis=0)\n",
    "        self.gex_std = np.std(self.gex_data, axis=0) + 1e-8\n",
    "        self.morpho_mean = np.mean(self.morpho_data, axis=0)\n",
    "        self.morpho_std = np.std(self.morpho_data, axis=0) + 1e-8\n",
    "        \n",
    "        self.gex_data_norm = (self.gex_data - self.gex_mean) / self.gex_std\n",
    "        self.morpho_data_norm = (self.morpho_data - self.morpho_mean) / self.morpho_std\n",
    "        \n",
    "        self.n_samples = len(self.gex_data)\n",
    "        self.gex_dim = self.gex_data.shape[1]\n",
    "        self.morpho_dim = self.morpho_data.shape[1]\n",
    "        \n",
    "        # Initialize networks\n",
    "        self._initialize_networks()\n",
    "        \n",
    "        # Convert to tensors\n",
    "        self.gex_tensor = torch.FloatTensor(self.gex_data_norm).to(self.device)\n",
    "        self.morpho_tensor = torch.FloatTensor(self.morpho_data_norm).to(self.device)\n",
    "        \n",
    "        # Domain labels (0 for GEX, 1 for Morpho)\n",
    "        self.domain_labels_gex = torch.zeros(self.n_samples, dtype=torch.long).to(self.device)\n",
    "        self.domain_labels_morpho = torch.ones(self.n_samples, dtype=torch.long).to(self.device)\n",
    "        \n",
    "        print(f\"Data loaded and normalized. Shape: GEX {self.gex_tensor.shape}, Morpho {self.morpho_tensor.shape}\")\n",
    "        \n",
    "    def _initialize_networks(self):\n",
    "        \"\"\"Initialize neural networks\"\"\"\n",
    "        \n",
    "        class GradientReversalLayer(torch.autograd.Function):\n",
    "            \"\"\"Gradient Reversal Layer for domain adversarial training\"\"\"\n",
    "            @staticmethod\n",
    "            def forward(ctx, x, alpha):\n",
    "                ctx.alpha = alpha\n",
    "                return x.view_as(x)\n",
    "            \n",
    "            @staticmethod\n",
    "            def backward(ctx, grad_output):\n",
    "                return grad_output.neg() * ctx.alpha, None\n",
    "        \n",
    "        def grad_reverse(x, alpha):\n",
    "            return GradientReversalLayer.apply(x, alpha)\n",
    "        \n",
    "        class FeatureExtractor(nn.Module):\n",
    "            def __init__(self, gex_dim, morpho_dim, latent_dim, hidden_dims):\n",
    "                super(FeatureExtractor, self).__init__()\n",
    "                \n",
    "                # Separate encoders for each modality\n",
    "                self.gex_encoder = self._build_encoder(gex_dim, hidden_dims, latent_dim)\n",
    "                self.morpho_encoder = self._build_encoder(morpho_dim, hidden_dims, latent_dim)\n",
    "                \n",
    "            def _build_encoder(self, input_dim, hidden_dims, output_dim):\n",
    "                layers = []\n",
    "                prev_dim = input_dim\n",
    "                \n",
    "                for hidden_dim in hidden_dims:\n",
    "                    layers.extend([\n",
    "                        nn.Linear(prev_dim, hidden_dim),\n",
    "                        nn.BatchNorm1d(hidden_dim),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(0.2)\n",
    "                    ])\n",
    "                    prev_dim = hidden_dim\n",
    "                \n",
    "                layers.append(nn.Linear(prev_dim, output_dim))\n",
    "                return nn.Sequential(*layers)\n",
    "            \n",
    "            def forward(self, x, modality):\n",
    "                if modality == 'gex':\n",
    "                    return self.gex_encoder(x)\n",
    "                elif modality == 'morpho':\n",
    "                    return self.morpho_encoder(x)\n",
    "                else:\n",
    "                    raise ValueError(\"Modality must be 'gex' or 'morpho'\")\n",
    "        \n",
    "        class DomainClassifier(nn.Module):\n",
    "            def __init__(self, latent_dim, hidden_dims):\n",
    "                super(DomainClassifier, self).__init__()\n",
    "                layers = []\n",
    "                prev_dim = latent_dim\n",
    "                \n",
    "                for hidden_dim in hidden_dims:\n",
    "                    layers.extend([\n",
    "                        nn.Linear(prev_dim, hidden_dim),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(0.3)\n",
    "                    ])\n",
    "                    prev_dim = hidden_dim\n",
    "                \n",
    "                layers.append(nn.Linear(prev_dim, 2))  # Binary classification: GEX vs Morpho\n",
    "                self.classifier = nn.Sequential(*layers)\n",
    "                \n",
    "            def forward(self, x, alpha):\n",
    "                x = grad_reverse(x, alpha)\n",
    "                return self.classifier(x)\n",
    "        \n",
    "        class Decoder(nn.Module):\n",
    "            def __init__(self, latent_dim, output_dim, hidden_dims):\n",
    "                super(Decoder, self).__init__()\n",
    "                layers = []\n",
    "                prev_dim = latent_dim\n",
    "                \n",
    "                # Reverse hidden dimensions for decoder\n",
    "                reversed_hidden_dims = hidden_dims[::-1]\n",
    "                \n",
    "                for hidden_dim in reversed_hidden_dims:\n",
    "                    layers.extend([\n",
    "                        nn.Linear(prev_dim, hidden_dim),\n",
    "                        nn.BatchNorm1d(hidden_dim),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(0.2)\n",
    "                    ])\n",
    "                    prev_dim = hidden_dim\n",
    "                \n",
    "                layers.append(nn.Linear(prev_dim, output_dim))\n",
    "                self.decoder = nn.Sequential(*layers)\n",
    "                \n",
    "            def forward(self, z):\n",
    "                return self.decoder(z)\n",
    "        \n",
    "        class ClusteringHead(nn.Module):\n",
    "            def __init__(self, latent_dim, n_clusters):\n",
    "                super(ClusteringHead, self).__init__()\n",
    "                self.cluster_head = nn.Sequential(\n",
    "                    nn.Linear(latent_dim, 128),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.2),\n",
    "                    nn.Linear(128, n_clusters),\n",
    "                    nn.Softmax(dim=1)\n",
    "                )\n",
    "                \n",
    "            def forward(self, x):\n",
    "                return self.cluster_head(x)\n",
    "        \n",
    "        # Initialize networks\n",
    "        self.feature_extractor = FeatureExtractor(\n",
    "            self.gex_dim, self.morpho_dim, self.latent_dim, self.feature_dims\n",
    "        ).to(self.device)\n",
    "        \n",
    "        self.domain_classifier = DomainClassifier(\n",
    "            self.latent_dim, self.domain_dims\n",
    "        ).to(self.device)\n",
    "        \n",
    "        self.decoder_gex = Decoder(\n",
    "            self.latent_dim, self.gex_dim, self.feature_dims\n",
    "        ).to(self.device)\n",
    "        \n",
    "        self.decoder_morpho = Decoder(\n",
    "            self.latent_dim, self.morpho_dim, self.feature_dims\n",
    "        ).to(self.device)\n",
    "        \n",
    "        self.clustering_head = ClusteringHead(\n",
    "            self.latent_dim, self.n_classes\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Store gradient reversal function\n",
    "        self.grad_reverse = grad_reverse\n",
    "        \n",
    "        # Initialize optimizers\n",
    "        self.optimizer_main = optim.Adam(\n",
    "            list(self.feature_extractor.parameters()) + \n",
    "            list(self.decoder_gex.parameters()) + \n",
    "            list(self.decoder_morpho.parameters()) +\n",
    "            list(self.clustering_head.parameters()),\n",
    "            lr=self.lr, betas=(0.5, 0.999)\n",
    "        )\n",
    "        \n",
    "        self.optimizer_domain = optim.Adam(\n",
    "            self.domain_classifier.parameters(),\n",
    "            lr=self.lr, betas=(0.5, 0.999)\n",
    "        )\n",
    "        \n",
    "        print(\"scDART networks initialized successfully\")\n",
    "        \n",
    "    def _clustering_loss(self, features, target_distribution=None):\n",
    "        \"\"\"Calculate clustering loss using target distribution\"\"\"\n",
    "        cluster_probs = self.clustering_head(features)\n",
    "        \n",
    "        if target_distribution is None:\n",
    "            # Use uniform distribution as target\n",
    "            target_distribution = torch.ones_like(cluster_probs) / self.n_classes\n",
    "        \n",
    "        # KL divergence loss\n",
    "        kl_loss = F.kl_div(\n",
    "            torch.log(cluster_probs + 1e-8), \n",
    "            target_distribution, \n",
    "            reduction='batchmean'\n",
    "        )\n",
    "        \n",
    "        return kl_loss\n",
    "    \n",
    "    def _entropy_loss(self, features):\n",
    "        \"\"\"Calculate entropy loss to encourage confident predictions\"\"\"\n",
    "        cluster_probs = self.clustering_head(features)\n",
    "        entropy = -torch.sum(cluster_probs * torch.log(cluster_probs + 1e-8), dim=1)\n",
    "        return torch.mean(entropy)\n",
    "    \n",
    "    def train_epoch(self, epoch):\n",
    "        \"\"\"Train one epoch\"\"\"\n",
    "        self.feature_extractor.train()\n",
    "        self.domain_classifier.train()\n",
    "        self.decoder_gex.train()\n",
    "        self.decoder_morpho.train()\n",
    "        self.clustering_head.train()\n",
    "        \n",
    "        # Create data indices\n",
    "        indices = torch.randperm(self.n_samples)\n",
    "        n_batches = (self.n_samples + self.batch_size - 1) // self.batch_size\n",
    "        \n",
    "        total_main_loss = 0\n",
    "        total_domain_loss = 0\n",
    "        \n",
    "        # Adaptive alpha for gradient reversal\n",
    "        p = float(epoch) / self.max_epochs\n",
    "        alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "        alpha *= self.gradient_reversal_alpha\n",
    "        \n",
    "        for batch_idx in range(n_batches):\n",
    "            start_idx = batch_idx * self.batch_size\n",
    "            end_idx = min((batch_idx + 1) * self.batch_size, self.n_samples)\n",
    "            batch_indices = indices[start_idx:end_idx]\n",
    "            \n",
    "            gex_batch = self.gex_tensor[batch_indices]\n",
    "            morpho_batch = self.morpho_tensor[batch_indices]\n",
    "            domain_labels_gex_batch = self.domain_labels_gex[batch_indices]\n",
    "            domain_labels_morpho_batch = self.domain_labels_morpho[batch_indices]\n",
    "            \n",
    "            batch_size_actual = len(batch_indices)\n",
    "            \n",
    "            # Train Main Networks\n",
    "            self.optimizer_main.zero_grad()\n",
    "            \n",
    "            # Extract features\n",
    "            gex_features = self.feature_extractor(gex_batch, 'gex')\n",
    "            morpho_features = self.feature_extractor(morpho_batch, 'morpho')\n",
    "            \n",
    "            # Reconstruction\n",
    "            gex_recon = self.decoder_gex(gex_features)\n",
    "            morpho_recon = self.decoder_morpho(morpho_features)\n",
    "            \n",
    "            # Cross-modal reconstruction\n",
    "            gex_cross_recon = self.decoder_gex(morpho_features)\n",
    "            morpho_cross_recon = self.decoder_morpho(gex_features)\n",
    "            \n",
    "            # Reconstruction losses\n",
    "            gex_recon_loss = F.mse_loss(gex_recon, gex_batch)\n",
    "            morpho_recon_loss = F.mse_loss(morpho_recon, morpho_batch)\n",
    "            gex_cross_loss = F.mse_loss(gex_cross_recon, gex_batch)\n",
    "            morpho_cross_loss = F.mse_loss(morpho_cross_recon, morpho_batch)\n",
    "            \n",
    "            total_recon_loss = (gex_recon_loss + morpho_recon_loss + \n",
    "                              gex_cross_loss + morpho_cross_loss)\n",
    "            \n",
    "            # Domain adversarial loss\n",
    "            all_features = torch.cat([gex_features, morpho_features], dim=0)\n",
    "            all_domain_labels = torch.cat([domain_labels_gex_batch, domain_labels_morpho_batch], dim=0)\n",
    "            \n",
    "            domain_pred = self.domain_classifier(all_features, alpha)\n",
    "            domain_adv_loss = F.cross_entropy(domain_pred, all_domain_labels)\n",
    "            \n",
    "            # Clustering losses\n",
    "            gex_cluster_loss = self._clustering_loss(gex_features)\n",
    "            morpho_cluster_loss = self._clustering_loss(morpho_features)\n",
    "            total_cluster_loss = gex_cluster_loss + morpho_cluster_loss\n",
    "            \n",
    "            # Entropy losses\n",
    "            gex_entropy_loss = self._entropy_loss(gex_features)\n",
    "            morpho_entropy_loss = self._entropy_loss(morpho_features)\n",
    "            total_entropy_loss = gex_entropy_loss + morpho_entropy_loss\n",
    "            \n",
    "            # Total main loss\n",
    "            main_loss = (self.lambda_recon * total_recon_loss +\n",
    "                        self.lambda_domain * domain_adv_loss +\n",
    "                        self.lambda_cluster * total_cluster_loss +\n",
    "                        self.lambda_entropy * total_entropy_loss)\n",
    "            \n",
    "            main_loss.backward()\n",
    "            self.optimizer_main.step()\n",
    "            \n",
    "            # Train Domain Classifier\n",
    "            self.optimizer_domain.zero_grad()\n",
    "            \n",
    "            gex_features_detached = self.feature_extractor(gex_batch, 'gex').detach()\n",
    "            morpho_features_detached = self.feature_extractor(morpho_batch, 'morpho').detach()\n",
    "            \n",
    "            all_features_detached = torch.cat([gex_features_detached, morpho_features_detached], dim=0)\n",
    "            \n",
    "            domain_pred_real = self.domain_classifier(all_features_detached, 0.0)\n",
    "            domain_loss = F.cross_entropy(domain_pred_real, all_domain_labels)\n",
    "            \n",
    "            domain_loss.backward()\n",
    "            self.optimizer_domain.step()\n",
    "            \n",
    "            total_main_loss += main_loss.item()\n",
    "            total_domain_loss += domain_loss.item()\n",
    "        \n",
    "        return total_main_loss / n_batches, total_domain_loss / n_batches\n",
    "    \n",
    "    def get_integrated_embeddings(self):\n",
    "        \"\"\"Get integrated embeddings in the shared feature space\"\"\"\n",
    "        self.feature_extractor.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            gex_embeddings = self.feature_extractor(self.gex_tensor, 'gex').cpu().numpy()\n",
    "            morpho_embeddings = self.feature_extractor(self.morpho_tensor, 'morpho').cpu().numpy()\n",
    "        \n",
    "        return gex_embeddings, morpho_embeddings\n",
    "    \n",
    "    def calculate_celltype_accuracy(self, gex_embeddings, morpho_embeddings):\n",
    "        \"\"\"Calculate cell type matching accuracy\"\"\"\n",
    "        if self.rna_family_labels is None:\n",
    "            print(\"No RNA family labels available for accuracy calculation\")\n",
    "            return None, None, None\n",
    "        \n",
    "        nbrs_morpho = NearestNeighbors(n_neighbors=1, metric='euclidean').fit(morpho_embeddings)\n",
    "        nbrs_gex = NearestNeighbors(n_neighbors=1, metric='euclidean').fit(gex_embeddings)\n",
    "        \n",
    "        _, indices_gex2morpho = nbrs_morpho.kneighbors(gex_embeddings)\n",
    "        gex2morpho_matches = 0\n",
    "        for i, nearest_idx in enumerate(indices_gex2morpho.flatten()):\n",
    "            if self.rna_family_labels[i] == self.rna_family_labels[nearest_idx]:\n",
    "                gex2morpho_matches += 1\n",
    "        gex2morpho_accuracy = gex2morpho_matches / len(self.rna_family_labels)\n",
    "        \n",
    "        _, indices_morpho2gex = nbrs_gex.kneighbors(morpho_embeddings)\n",
    "        morpho2gex_matches = 0\n",
    "        for i, nearest_idx in enumerate(indices_morpho2gex.flatten()):\n",
    "            if self.rna_family_labels[i] == self.rna_family_labels[nearest_idx]:\n",
    "                morpho2gex_matches += 1\n",
    "        morpho2gex_accuracy = morpho2gex_matches / len(self.rna_family_labels)\n",
    "        \n",
    "        average_accuracy = (gex2morpho_accuracy + morpho2gex_accuracy) / 2\n",
    "        \n",
    "        return gex2morpho_accuracy, morpho2gex_accuracy, average_accuracy\n",
    "    \n",
    "    def train(self, verbose_interval=20):\n",
    "        \"\"\"Train scDART model\"\"\"\n",
    "        print(\"Starting scDART training...\")\n",
    "        \n",
    "        for epoch in tqdm(range(self.max_epochs), desc=\"Training scDART\"):\n",
    "            main_loss, domain_loss = self.train_epoch(epoch)\n",
    "            \n",
    "            if (epoch + 1) % verbose_interval == 0:\n",
    "                gex_emb, morpho_emb = self.get_integrated_embeddings()\n",
    "                gex2morpho_acc, morpho2gex_acc, avg_acc = self.calculate_celltype_accuracy(gex_emb, morpho_emb)\n",
    "                \n",
    "                print(f\"\\nEpoch {epoch+1}/{self.max_epochs}\")\n",
    "                print(f\"  Main Loss: {main_loss:.4f}\")\n",
    "                print(f\"  Domain Loss: {domain_loss:.4f}\")\n",
    "                if avg_acc is not None:\n",
    "                    print(f\"  GEX->Morpho Acc: {gex2morpho_acc:.4f}\")\n",
    "                    print(f\"  Morpho->GEX Acc: {morpho2gex_acc:.4f}\")\n",
    "                    print(f\"  Average Acc: {avg_acc:.4f}\")\n",
    "                print(\"-\" * 50)\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    # 创建输出目录\n",
    "    output_dir = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/writeup20/scDART/\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Initialize scDART integrator\n",
    "    integrator = scDARTIntegrator(\n",
    "        latent_dim=128,\n",
    "        feature_dims=[512, 256],\n",
    "        domain_dims=[256, 128],\n",
    "        lambda_domain=1.0,\n",
    "        lambda_recon=1.0,\n",
    "        lambda_cluster=0.1,\n",
    "        lambda_entropy=0.01,\n",
    "        max_epochs=200,\n",
    "        batch_size=64,\n",
    "        lr=0.001,\n",
    "        gradient_reversal_alpha=1.0\n",
    "    )\n",
    "    \n",
    "    # Load data\n",
    "    integrator.load_data()\n",
    "    \n",
    "    # Train model\n",
    "    integrator.train(verbose_interval=20)\n",
    "    \n",
    "    # Get final integrated embeddings\n",
    "    print(\"\\nGetting latent space embeddings...\")\n",
    "    final_gex_embeddings, final_morpho_embeddings = integrator.get_integrated_embeddings()\n",
    "    \n",
    "    # Calculate final accuracy\n",
    "    final_gex2morpho_acc, final_morpho2gex_acc, final_avg_acc = integrator.calculate_celltype_accuracy(\n",
    "        final_gex_embeddings, final_morpho_embeddings\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL scDART RESULTS:\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"GEX -> Morpho Accuracy: {final_gex2morpho_acc:.4f}\")\n",
    "    print(f\"Morpho -> GEX Accuracy: {final_morpho2gex_acc:.4f}\")\n",
    "    print(f\"Average Accuracy: {final_avg_acc:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # UMAP降维\n",
    "    print(\"\\nPerforming UMAP dimensionality reduction...\")\n",
    "    reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "    \n",
    "    # GEX UMAP\n",
    "    print(\"  - Computing GEX UMAP...\")\n",
    "    gex_umap = reducer.fit_transform(final_gex_embeddings)\n",
    "    gex_umap_df = pd.DataFrame(gex_umap, columns=['UMAP1', 'UMAP2'])\n",
    "    gex_umap_path = os.path.join(output_dir, \"gex_umap.csv\")\n",
    "    gex_umap_df.to_csv(gex_umap_path, index=False)\n",
    "    print(f\"  - GEX UMAP saved to: {gex_umap_path}\")\n",
    "    \n",
    "    # Morpho UMAP\n",
    "    print(\"  - Computing Morpho UMAP...\")\n",
    "    morpho_umap = reducer.fit_transform(final_morpho_embeddings)\n",
    "    morpho_umap_df = pd.DataFrame(morpho_umap, columns=['UMAP1', 'UMAP2'])\n",
    "    morpho_umap_path = os.path.join(output_dir, \"morpho_umap.csv\")\n",
    "    morpho_umap_df.to_csv(morpho_umap_path, index=False)\n",
    "    print(f\"  - Morpho UMAP saved to: {morpho_umap_path}\")\n",
    "    \n",
    "    print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c814c03",
   "metadata": {},
   "source": [
    "## STACI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fbb7164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "RNA family labels loaded: 10 unique types\n",
      "Data shapes - GEX: (645, 2000), Morpho: (645, 645)\n",
      "STACI networks initialized successfully\n",
      "Data loaded and normalized. Shape: GEX torch.Size([645, 2000]), Morpho torch.Size([645, 645])\n",
      "Starting STACI training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training STACI:  10%|█         | 20/200 [00:30<04:43,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/200\n",
      "  Total Loss: 0.7844\n",
      "  GEX->Morpho Acc: 0.5209\n",
      "  Morpho->GEX Acc: 0.5209\n",
      "  Average Acc: 0.5209\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training STACI:  17%|█▋        | 34/200 [00:53<04:16,  1.55s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training STACI:  20%|██        | 40/200 [01:03<04:42,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40/200\n",
      "  Total Loss: 0.6066\n",
      "  GEX->Morpho Acc: 0.5008\n",
      "  Morpho->GEX Acc: 0.4651\n",
      "  Average Acc: 0.4829\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training STACI:  30%|███       | 60/200 [01:35<04:10,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 60/200\n",
      "  Total Loss: 0.5140\n",
      "  GEX->Morpho Acc: 0.5333\n",
      "  Morpho->GEX Acc: 0.4822\n",
      "  Average Acc: 0.5078\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training STACI:  40%|████      | 80/200 [02:11<03:08,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 80/200\n",
      "  Total Loss: 0.4555\n",
      "  GEX->Morpho Acc: 0.5845\n",
      "  Morpho->GEX Acc: 0.4884\n",
      "  Average Acc: 0.5364\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training STACI:  50%|█████     | 100/200 [02:42<02:30,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100/200\n",
      "  Total Loss: 0.4360\n",
      "  GEX->Morpho Acc: 0.5628\n",
      "  Morpho->GEX Acc: 0.5178\n",
      "  Average Acc: 0.5403\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training STACI:  60%|██████    | 120/200 [03:13<02:07,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 120/200\n",
      "  Total Loss: 0.3928\n",
      "  GEX->Morpho Acc: 0.6047\n",
      "  Morpho->GEX Acc: 0.5349\n",
      "  Average Acc: 0.5698\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training STACI:  70%|███████   | 140/200 [03:45<01:32,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 140/200\n",
      "  Total Loss: 0.3689\n",
      "  GEX->Morpho Acc: 0.6047\n",
      "  Morpho->GEX Acc: 0.5411\n",
      "  Average Acc: 0.5729\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training STACI:  80%|████████  | 160/200 [04:17<01:01,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 160/200\n",
      "  Total Loss: 0.3593\n",
      "  GEX->Morpho Acc: 0.6202\n",
      "  Morpho->GEX Acc: 0.5240\n",
      "  Average Acc: 0.5721\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training STACI:  90%|█████████ | 180/200 [04:51<00:31,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 180/200\n",
      "  Total Loss: 0.3330\n",
      "  GEX->Morpho Acc: 0.6512\n",
      "  Morpho->GEX Acc: 0.5333\n",
      "  Average Acc: 0.5922\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training STACI: 100%|██████████| 200/200 [05:24<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 200/200\n",
      "  Total Loss: 0.3162\n",
      "  GEX->Morpho Acc: 0.6589\n",
      "  Morpho->GEX Acc: 0.5767\n",
      "  Average Acc: 0.6178\n",
      "--------------------------------------------------\n",
      "\n",
      "Getting latent space embeddings...\n",
      "\n",
      "============================================================\n",
      "FINAL STACI RESULTS:\n",
      "============================================================\n",
      "GEX -> Morpho Accuracy: 0.6589\n",
      "Morpho -> GEX Accuracy: 0.5767\n",
      "Average Accuracy: 0.6178\n",
      "============================================================\n",
      "\n",
      "Performing UMAP dimensionality reduction...\n",
      "  - Computing GEX UMAP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - GEX UMAP saved to: /home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/writeup20/STACI/gex_umap.csv\n",
      "  - Computing Morpho UMAP...\n",
      "  - Morpho UMAP saved to: /home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/writeup20/STACI/morpho_umap.csv\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "class STACIIntegrator:\n",
    "    \"\"\"\n",
    "    STACI implementation for multi-modal data integration\n",
    "    Based on the STACI (Spatial-Temporal Attention for Cross-modal Integration) algorithm\n",
    "    using attention mechanisms and contrastive learning for single-cell multi-omics integration\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_dim=128, attention_heads=8, attention_layers=3, \n",
    "                 temperature=0.1, lambda_contrast=1.0, lambda_recon=1.0, lambda_attention=0.5,\n",
    "                 max_epochs=200, batch_size=64, lr=0.001, device='cuda'):\n",
    "        \"\"\"\n",
    "        Initialize STACI integrator\n",
    "        \n",
    "        Args:\n",
    "            embedding_dim: Dimension of the shared embedding space\n",
    "            attention_heads: Number of attention heads\n",
    "            attention_layers: Number of attention layers\n",
    "            temperature: Temperature parameter for contrastive loss\n",
    "            lambda_contrast: Weight for contrastive loss\n",
    "            lambda_recon: Weight for reconstruction loss\n",
    "            lambda_attention: Weight for attention alignment loss\n",
    "            max_epochs: Maximum training epochs\n",
    "            batch_size: Training batch size\n",
    "            lr: Learning rate\n",
    "            device: Computing device\n",
    "        \"\"\"\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.attention_heads = attention_heads\n",
    "        self.attention_layers = attention_layers\n",
    "        self.temperature = temperature\n",
    "        self.lambda_contrast = lambda_contrast\n",
    "        self.lambda_recon = lambda_recon\n",
    "        self.lambda_attention = lambda_attention\n",
    "        self.max_epochs = max_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.device = device if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Networks will be initialized after loading data\n",
    "        self.encoder_gex = None\n",
    "        self.encoder_morpho = None\n",
    "        self.decoder_gex = None\n",
    "        self.decoder_morpho = None\n",
    "        self.cross_attention = None\n",
    "        self.projector_gex = None\n",
    "        self.projector_morpho = None\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load multi-modal data\"\"\"\n",
    "        # Gene expression data\n",
    "        gene_expression_path = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/scala/exon_data_top2000.csv\"\n",
    "        gex_df = pd.read_csv(gene_expression_path, header=None)\n",
    "        self.gex_data = gex_df.iloc[:, 1:].to_numpy().astype(np.float32)\n",
    "        \n",
    "        # Morphology data\n",
    "        morphology_path = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/scala/gw_dist.csv\"\n",
    "        morpho_df = pd.read_csv(morphology_path, header=0)\n",
    "        self.morpho_data = morpho_df.iloc[:, 1:].to_numpy().astype(np.float32)\n",
    "        \n",
    "        # RNA family labels\n",
    "        rna_family_path = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/scala/rna_family_matched.csv\"\n",
    "        try:\n",
    "            rna_df = pd.read_csv(rna_family_path, header=0)\n",
    "            if rna_df.shape[1] == 1:\n",
    "                self.rna_family_labels = rna_df.iloc[:, 0].values\n",
    "            else:\n",
    "                self.rna_family_labels = rna_df.iloc[:, 1].values\n",
    "            \n",
    "            min_samples = min(len(self.gex_data), len(self.morpho_data))\n",
    "            self.rna_family_labels = self.rna_family_labels[:min_samples]\n",
    "            self.gex_data = self.gex_data[:min_samples]\n",
    "            self.morpho_data = self.morpho_data[:min_samples]\n",
    "            \n",
    "            print(f\"RNA family labels loaded: {len(np.unique(self.rna_family_labels))} unique types\")\n",
    "            print(f\"Data shapes - GEX: {self.gex_data.shape}, Morpho: {self.morpho_data.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not load RNA family labels: {e}\")\n",
    "            self.rna_family_labels = None\n",
    "        \n",
    "        # Data normalization\n",
    "        self.gex_mean = np.mean(self.gex_data, axis=0)\n",
    "        self.gex_std = np.std(self.gex_data, axis=0) + 1e-8\n",
    "        self.morpho_mean = np.mean(self.morpho_data, axis=0)\n",
    "        self.morpho_std = np.std(self.morpho_data, axis=0) + 1e-8\n",
    "        \n",
    "        self.gex_data_norm = (self.gex_data - self.gex_mean) / self.gex_std\n",
    "        self.morpho_data_norm = (self.morpho_data - self.morpho_mean) / self.morpho_std\n",
    "        \n",
    "        self.n_samples = len(self.gex_data)\n",
    "        self.gex_dim = self.gex_data.shape[1]\n",
    "        self.morpho_dim = self.morpho_data.shape[1]\n",
    "        \n",
    "        # Initialize networks\n",
    "        self._initialize_networks()\n",
    "        \n",
    "        # Convert to tensors\n",
    "        self.gex_tensor = torch.FloatTensor(self.gex_data_norm).to(self.device)\n",
    "        self.morpho_tensor = torch.FloatTensor(self.morpho_data_norm).to(self.device)\n",
    "        \n",
    "        print(f\"Data loaded and normalized. Shape: GEX {self.gex_tensor.shape}, Morpho {self.morpho_tensor.shape}\")\n",
    "        \n",
    "    def _initialize_networks(self):\n",
    "        \"\"\"Initialize neural networks for STACI\"\"\"\n",
    "        \n",
    "        class Encoder(nn.Module):\n",
    "            def __init__(self, input_dim, embedding_dim):\n",
    "                super(Encoder, self).__init__()\n",
    "                hidden_dim = max(256, min(512, input_dim // 2))\n",
    "                self.encoder = nn.Sequential(\n",
    "                    nn.Linear(input_dim, hidden_dim),\n",
    "                    nn.LayerNorm(hidden_dim),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.1),\n",
    "                    nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "                    nn.LayerNorm(hidden_dim // 2),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.1),\n",
    "                    nn.Linear(hidden_dim // 2, embedding_dim),\n",
    "                    nn.LayerNorm(embedding_dim)\n",
    "                )\n",
    "                \n",
    "            def forward(self, x):\n",
    "                return self.encoder(x)\n",
    "        \n",
    "        class Decoder(nn.Module):\n",
    "            def __init__(self, embedding_dim, output_dim):\n",
    "                super(Decoder, self).__init__()\n",
    "                hidden_dim = max(256, min(512, output_dim // 2))\n",
    "                self.decoder = nn.Sequential(\n",
    "                    nn.Linear(embedding_dim, hidden_dim // 2),\n",
    "                    nn.LayerNorm(hidden_dim // 2),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.1),\n",
    "                    nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "                    nn.LayerNorm(hidden_dim),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.1),\n",
    "                    nn.Linear(hidden_dim, output_dim)\n",
    "                )\n",
    "                \n",
    "            def forward(self, x):\n",
    "                return self.decoder(x)\n",
    "        \n",
    "        class CrossModalAttention(nn.Module):\n",
    "            def __init__(self, embedding_dim, num_heads, num_layers):\n",
    "                super(CrossModalAttention, self).__init__()\n",
    "                self.embedding_dim = embedding_dim\n",
    "                self.num_heads = num_heads\n",
    "                \n",
    "                encoder_layer = nn.TransformerEncoderLayer(\n",
    "                    d_model=embedding_dim,\n",
    "                    nhead=num_heads,\n",
    "                    dim_feedforward=embedding_dim * 2,\n",
    "                    dropout=0.1,\n",
    "                    activation='relu',\n",
    "                    batch_first=True\n",
    "                )\n",
    "                self.attention_layers = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "                \n",
    "                self.query_proj = nn.Linear(embedding_dim, embedding_dim)\n",
    "                self.key_proj = nn.Linear(embedding_dim, embedding_dim)\n",
    "                self.value_proj = nn.Linear(embedding_dim, embedding_dim)\n",
    "                \n",
    "                self.output_proj = nn.Linear(embedding_dim, embedding_dim)\n",
    "                \n",
    "            def forward(self, gex_embeddings, morpho_embeddings):\n",
    "                batch_size = gex_embeddings.size(0)\n",
    "                \n",
    "                gex_seq = gex_embeddings.unsqueeze(1)\n",
    "                morpho_seq = morpho_embeddings.unsqueeze(1)\n",
    "                \n",
    "                joint_seq = torch.cat([gex_seq, morpho_seq], dim=1)\n",
    "                \n",
    "                attended = self.attention_layers(joint_seq)\n",
    "                \n",
    "                gex_attended = attended[:, 0, :]\n",
    "                morpho_attended = attended[:, 1, :]\n",
    "                \n",
    "                gex_query = self.query_proj(gex_attended)\n",
    "                morpho_key = self.key_proj(morpho_attended)\n",
    "                morpho_value = self.value_proj(morpho_attended)\n",
    "                \n",
    "                gex_cross_attended = self._cross_attention(gex_query, morpho_key, morpho_value)\n",
    "                \n",
    "                morpho_query = self.query_proj(morpho_attended)\n",
    "                gex_key = self.key_proj(gex_attended)\n",
    "                gex_value = self.value_proj(gex_attended)\n",
    "                \n",
    "                morpho_cross_attended = self._cross_attention(morpho_query, gex_key, gex_value)\n",
    "                \n",
    "                gex_final = self.output_proj(gex_cross_attended + gex_attended)\n",
    "                morpho_final = self.output_proj(morpho_cross_attended + morpho_attended)\n",
    "                \n",
    "                return gex_final, morpho_final\n",
    "            \n",
    "            def _cross_attention(self, query, key, value):\n",
    "                attention_weights = torch.softmax(\n",
    "                    torch.sum(query * key, dim=-1, keepdim=True) / np.sqrt(self.embedding_dim), \n",
    "                    dim=-1\n",
    "                )\n",
    "                return attention_weights * value\n",
    "        \n",
    "        class ContrastiveProjector(nn.Module):\n",
    "            def __init__(self, embedding_dim, projection_dim=128):\n",
    "                super(ContrastiveProjector, self).__init__()\n",
    "                self.projector = nn.Sequential(\n",
    "                    nn.Linear(embedding_dim, projection_dim),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(projection_dim, projection_dim),\n",
    "                    nn.LayerNorm(projection_dim)\n",
    "                )\n",
    "                \n",
    "            def forward(self, x):\n",
    "                return F.normalize(self.projector(x), dim=-1)\n",
    "        \n",
    "        # Initialize networks\n",
    "        self.encoder_gex = Encoder(self.gex_dim, self.embedding_dim).to(self.device)\n",
    "        self.encoder_morpho = Encoder(self.morpho_dim, self.embedding_dim).to(self.device)\n",
    "        \n",
    "        self.decoder_gex = Decoder(self.embedding_dim, self.gex_dim).to(self.device)\n",
    "        self.decoder_morpho = Decoder(self.embedding_dim, self.morpho_dim).to(self.device)\n",
    "        \n",
    "        self.cross_attention = CrossModalAttention(\n",
    "            self.embedding_dim, self.attention_heads, self.attention_layers\n",
    "        ).to(self.device)\n",
    "        \n",
    "        self.projector_gex = ContrastiveProjector(self.embedding_dim).to(self.device)\n",
    "        self.projector_morpho = ContrastiveProjector(self.embedding_dim).to(self.device)\n",
    "        \n",
    "        # Initialize optimizer\n",
    "        self.optimizer = optim.AdamW(\n",
    "            list(self.encoder_gex.parameters()) + \n",
    "            list(self.encoder_morpho.parameters()) +\n",
    "            list(self.decoder_gex.parameters()) + \n",
    "            list(self.decoder_morpho.parameters()) +\n",
    "            list(self.cross_attention.parameters()) +\n",
    "            list(self.projector_gex.parameters()) +\n",
    "            list(self.projector_morpho.parameters()),\n",
    "            lr=self.lr, weight_decay=1e-4\n",
    "        )\n",
    "        \n",
    "        print(\"STACI networks initialized successfully\")\n",
    "        \n",
    "    def _contrastive_loss(self, gex_proj, morpho_proj):\n",
    "        \"\"\"Calculate contrastive loss between paired samples\"\"\"\n",
    "        batch_size = gex_proj.size(0)\n",
    "        \n",
    "        similarity_matrix = torch.mm(gex_proj, morpho_proj.t()) / self.temperature\n",
    "        \n",
    "        labels = torch.arange(batch_size).to(self.device)\n",
    "        \n",
    "        loss_gex_to_morpho = F.cross_entropy(similarity_matrix, labels)\n",
    "        loss_morpho_to_gex = F.cross_entropy(similarity_matrix.t(), labels)\n",
    "        \n",
    "        return (loss_gex_to_morpho + loss_morpho_to_gex) / 2\n",
    "    \n",
    "    def _attention_alignment_loss(self, gex_embeddings, morpho_embeddings, \n",
    "                                 gex_attended, morpho_attended):\n",
    "        \"\"\"Calculate attention alignment loss to encourage meaningful cross-modal attention\"\"\"\n",
    "        gex_attention_change = F.mse_loss(gex_attended, gex_embeddings)\n",
    "        morpho_attention_change = F.mse_loss(morpho_attended, morpho_embeddings)\n",
    "        \n",
    "        target_change = 0.1\n",
    "        gex_alignment_loss = (gex_attention_change - target_change) ** 2\n",
    "        morpho_alignment_loss = (morpho_attention_change - target_change) ** 2\n",
    "        \n",
    "        return (gex_alignment_loss + morpho_alignment_loss) / 2\n",
    "    \n",
    "    def _reconstruction_loss(self, recon, original):\n",
    "        \"\"\"Calculate reconstruction loss\"\"\"\n",
    "        return F.mse_loss(recon, original)\n",
    "    \n",
    "    def train_epoch(self, epoch):\n",
    "        \"\"\"Train one epoch\"\"\"\n",
    "        self.encoder_gex.train()\n",
    "        self.encoder_morpho.train()\n",
    "        self.decoder_gex.train()\n",
    "        self.decoder_morpho.train()\n",
    "        self.cross_attention.train()\n",
    "        self.projector_gex.train()\n",
    "        self.projector_morpho.train()\n",
    "        \n",
    "        indices = torch.randperm(self.n_samples)\n",
    "        n_batches = (self.n_samples + self.batch_size - 1) // self.batch_size\n",
    "        \n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch_idx in range(n_batches):\n",
    "            start_idx = batch_idx * self.batch_size\n",
    "            end_idx = min((batch_idx + 1) * self.batch_size, self.n_samples)\n",
    "            batch_indices = indices[start_idx:end_idx]\n",
    "            \n",
    "            gex_batch = self.gex_tensor[batch_indices]\n",
    "            morpho_batch = self.morpho_tensor[batch_indices]\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            gex_embeddings = self.encoder_gex(gex_batch)\n",
    "            morpho_embeddings = self.encoder_morpho(morpho_batch)\n",
    "            \n",
    "            gex_attended, morpho_attended = self.cross_attention(gex_embeddings, morpho_embeddings)\n",
    "            \n",
    "            gex_recon = self.decoder_gex(gex_attended)\n",
    "            morpho_recon = self.decoder_morpho(morpho_attended)\n",
    "            \n",
    "            gex_cross_recon = self.decoder_gex(morpho_attended)\n",
    "            morpho_cross_recon = self.decoder_morpho(gex_attended)\n",
    "            \n",
    "            gex_proj = self.projector_gex(gex_attended)\n",
    "            morpho_proj = self.projector_morpho(morpho_attended)\n",
    "            \n",
    "            gex_recon_loss = self._reconstruction_loss(gex_recon, gex_batch)\n",
    "            morpho_recon_loss = self._reconstruction_loss(morpho_recon, morpho_batch)\n",
    "            gex_cross_loss = self._reconstruction_loss(gex_cross_recon, gex_batch)\n",
    "            morpho_cross_loss = self._reconstruction_loss(morpho_cross_recon, morpho_batch)\n",
    "            \n",
    "            recon_loss = (gex_recon_loss + morpho_recon_loss + \n",
    "                         gex_cross_loss + morpho_cross_loss) / 4\n",
    "            \n",
    "            contrast_loss = self._contrastive_loss(gex_proj, morpho_proj)\n",
    "            \n",
    "            attention_loss = self._attention_alignment_loss(\n",
    "                gex_embeddings, morpho_embeddings, gex_attended, morpho_attended\n",
    "            )\n",
    "            \n",
    "            total_batch_loss = (self.lambda_recon * recon_loss + \n",
    "                              self.lambda_contrast * contrast_loss +\n",
    "                              self.lambda_attention * attention_loss)\n",
    "            \n",
    "            total_batch_loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                list(self.encoder_gex.parameters()) + \n",
    "                list(self.encoder_morpho.parameters()) +\n",
    "                list(self.decoder_gex.parameters()) + \n",
    "                list(self.decoder_morpho.parameters()) +\n",
    "                list(self.cross_attention.parameters()) +\n",
    "                list(self.projector_gex.parameters()) +\n",
    "                list(self.projector_morpho.parameters()),\n",
    "                max_norm=1.0\n",
    "            )\n",
    "            \n",
    "            self.optimizer.step()\n",
    "            \n",
    "            total_loss += total_batch_loss.item()\n",
    "        \n",
    "        return total_loss / n_batches\n",
    "    \n",
    "    def get_integrated_embeddings(self):\n",
    "        \"\"\"Get integrated embeddings after cross-modal attention\"\"\"\n",
    "        self.encoder_gex.eval()\n",
    "        self.encoder_morpho.eval()\n",
    "        self.cross_attention.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            gex_embeddings = self.encoder_gex(self.gex_tensor)\n",
    "            morpho_embeddings = self.encoder_morpho(self.morpho_tensor)\n",
    "            \n",
    "            gex_attended, morpho_attended = self.cross_attention(gex_embeddings, morpho_embeddings)\n",
    "            \n",
    "            gex_final = gex_attended.cpu().numpy()\n",
    "            morpho_final = morpho_attended.cpu().numpy()\n",
    "        \n",
    "        return gex_final, morpho_final\n",
    "    \n",
    "    def calculate_celltype_accuracy(self, gex_embeddings, morpho_embeddings):\n",
    "        \"\"\"Calculate cell type matching accuracy\"\"\"\n",
    "        if self.rna_family_labels is None:\n",
    "            print(\"No RNA family labels available for accuracy calculation\")\n",
    "            return None, None, None\n",
    "        \n",
    "        nbrs_morpho = NearestNeighbors(n_neighbors=1, metric='euclidean').fit(morpho_embeddings)\n",
    "        nbrs_gex = NearestNeighbors(n_neighbors=1, metric='euclidean').fit(gex_embeddings)\n",
    "        \n",
    "        _, indices_gex2morpho = nbrs_morpho.kneighbors(gex_embeddings)\n",
    "        gex2morpho_matches = 0\n",
    "        for i, nearest_idx in enumerate(indices_gex2morpho.flatten()):\n",
    "            if self.rna_family_labels[i] == self.rna_family_labels[nearest_idx]:\n",
    "                gex2morpho_matches += 1\n",
    "        gex2morpho_accuracy = gex2morpho_matches / len(self.rna_family_labels)\n",
    "        \n",
    "        _, indices_morpho2gex = nbrs_gex.kneighbors(morpho_embeddings)\n",
    "        morpho2gex_matches = 0\n",
    "        for i, nearest_idx in enumerate(indices_morpho2gex.flatten()):\n",
    "            if self.rna_family_labels[i] == self.rna_family_labels[nearest_idx]:\n",
    "                morpho2gex_matches += 1\n",
    "        morpho2gex_accuracy = morpho2gex_matches / len(self.rna_family_labels)\n",
    "        \n",
    "        average_accuracy = (gex2morpho_accuracy + morpho2gex_accuracy) / 2\n",
    "        \n",
    "        return gex2morpho_accuracy, morpho2gex_accuracy, average_accuracy\n",
    "    \n",
    "    def train(self, verbose_interval=20):\n",
    "        \"\"\"Train STACI model\"\"\"\n",
    "        print(\"Starting STACI training...\")\n",
    "        \n",
    "        for epoch in tqdm(range(self.max_epochs), desc=\"Training STACI\"):\n",
    "            total_loss = self.train_epoch(epoch)\n",
    "            \n",
    "            if (epoch + 1) % verbose_interval == 0:\n",
    "                gex_emb, morpho_emb = self.get_integrated_embeddings()\n",
    "                gex2morpho_acc, morpho2gex_acc, avg_acc = self.calculate_celltype_accuracy(gex_emb, morpho_emb)\n",
    "                \n",
    "                print(f\"\\nEpoch {epoch+1}/{self.max_epochs}\")\n",
    "                print(f\"  Total Loss: {total_loss:.4f}\")\n",
    "                if avg_acc is not None:\n",
    "                    print(f\"  GEX->Morpho Acc: {gex2morpho_acc:.4f}\")\n",
    "                    print(f\"  Morpho->GEX Acc: {morpho2gex_acc:.4f}\")\n",
    "                    print(f\"  Average Acc: {avg_acc:.4f}\")\n",
    "                print(\"-\" * 50)\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    # 创建输出目录\n",
    "    output_dir = \"/home/users/turbodu/kzlinlab/projects/morpho_integration/out/turbo/writeup20/STACI/\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Initialize STACI integrator\n",
    "    integrator = STACIIntegrator(\n",
    "        embedding_dim=128,\n",
    "        attention_heads=8,\n",
    "        attention_layers=3,\n",
    "        temperature=0.1,\n",
    "        lambda_contrast=1.0,\n",
    "        lambda_recon=1.0,\n",
    "        lambda_attention=0.5,\n",
    "        max_epochs=200,\n",
    "        batch_size=64,\n",
    "        lr=0.001\n",
    "    )\n",
    "    \n",
    "    # Load data\n",
    "    integrator.load_data()\n",
    "    \n",
    "    # Train model\n",
    "    integrator.train(verbose_interval=20)\n",
    "    \n",
    "    # Get final integrated embeddings\n",
    "    print(\"\\nGetting latent space embeddings...\")\n",
    "    final_gex_embeddings, final_morpho_embeddings = integrator.get_integrated_embeddings()\n",
    "    \n",
    "    # Calculate final accuracy\n",
    "    final_gex2morpho_acc, final_morpho2gex_acc, final_avg_acc = integrator.calculate_celltype_accuracy(\n",
    "        final_gex_embeddings, final_morpho_embeddings\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL STACI RESULTS:\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"GEX -> Morpho Accuracy: {final_gex2morpho_acc:.4f}\")\n",
    "    print(f\"Morpho -> GEX Accuracy: {final_morpho2gex_acc:.4f}\")\n",
    "    print(f\"Average Accuracy: {final_avg_acc:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # UMAP降维\n",
    "    print(\"\\nPerforming UMAP dimensionality reduction...\")\n",
    "    reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "    \n",
    "    # GEX UMAP\n",
    "    print(\"  - Computing GEX UMAP...\")\n",
    "    gex_umap = reducer.fit_transform(final_gex_embeddings)\n",
    "    gex_umap_df = pd.DataFrame(gex_umap, columns=['UMAP1', 'UMAP2'])\n",
    "    gex_umap_path = os.path.join(output_dir, \"gex_umap.csv\")\n",
    "    gex_umap_df.to_csv(gex_umap_path, index=False)\n",
    "    print(f\"  - GEX UMAP saved to: {gex_umap_path}\")\n",
    "    \n",
    "    # Morpho UMAP\n",
    "    print(\"  - Computing Morpho UMAP...\")\n",
    "    morpho_umap = reducer.fit_transform(final_morpho_embeddings)\n",
    "    morpho_umap_df = pd.DataFrame(morpho_umap, columns=['UMAP1', 'UMAP2'])\n",
    "    morpho_umap_path = os.path.join(output_dir, \"morpho_umap.csv\")\n",
    "    morpho_umap_df.to_csv(morpho_umap_path, index=False)\n",
    "    print(f\"  - Morpho UMAP saved to: {morpho_umap_path}\")\n",
    "    \n",
    "    print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8472d06",
   "metadata": {},
   "source": [
    "## SCOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00652b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shapes - X: (644, 2000), Y: (644, 645)\n",
      "Generating 2D UMAP embeddings...\n",
      "✅ Saved:\n",
      "  /Users/apple/Desktop/SCOT/Y_umap.csv\n",
      "  /Users/apple/Desktop/SCOT/X_umap.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import ot\n",
    "from scipy.sparse.csgraph import dijkstra\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "import pandas as pd\n",
    "import umap\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "class SCOTv2(object):\n",
    "    \"\"\"Simplified SCOTv2 for cross-modal alignment.\"\"\"\n",
    "    def __init__(self, data):\n",
    "        assert isinstance(data, list) and len(data) >= 2, \"Input must be list of ≥2 numpy arrays\"\n",
    "        self.data = data\n",
    "        self.marginals = []\n",
    "        self.graphs = []\n",
    "        self.graphDists = []\n",
    "        self.couplings = []\n",
    "        self.integrated_data = []\n",
    "\n",
    "    def _init_marginals(self):\n",
    "        for i in range(len(self.data)):\n",
    "            n = self.data[i].shape[0]\n",
    "            self.marginals.append(torch.ones(n) / n)\n",
    "        return self.marginals\n",
    "\n",
    "    def _normalize(self, norm=\"l2\", bySample=True):\n",
    "        for i in range(len(self.data)):\n",
    "            if norm == \"zscore\":\n",
    "                scaler = StandardScaler()\n",
    "                self.data[i] = scaler.fit_transform(self.data[i])\n",
    "            else:\n",
    "                axis = 1 if bySample else 0\n",
    "                self.data[i] = normalize(self.data[i], norm=norm, axis=axis)\n",
    "        return self.data\n",
    "\n",
    "    def construct_graph(self, k=20, mode=\"connectivity\", metric=\"correlation\"):\n",
    "        include_self = True if mode == \"connectivity\" else False\n",
    "        for i in range(len(self.data)):\n",
    "            self.graphs.append(\n",
    "                kneighbors_graph(self.data[i], n_neighbors=k, mode=mode,\n",
    "                                 metric=metric, include_self=include_self)\n",
    "            )\n",
    "        return self.graphs\n",
    "\n",
    "    def init_graph_distances(self):\n",
    "        for i in range(len(self.data)):\n",
    "            sp = dijkstra(csgraph=csr_matrix(self.graphs[i]),\n",
    "                          directed=False, return_predecessors=False)\n",
    "            max_dist = np.nanmax(sp[sp != np.inf])\n",
    "            sp[sp > max_dist] = max_dist\n",
    "            self.graphDists.append(sp / sp.max())\n",
    "        return self.graphDists\n",
    "\n",
    "    def direct_balanced_ot(self, a, dx, b, dy, eps=0.1):\n",
    "        a_np, b_np, dx_np, dy_np = a.numpy(), b.numpy(), dx.numpy(), dy.numpy()\n",
    "        try:\n",
    "            coupling, log = ot.gromov.entropic_gromov_wasserstein(\n",
    "                dx_np, dy_np, a_np, b_np, epsilon=eps,\n",
    "                max_iter=10000, tol=1e-9, log=True, verbose=False\n",
    "            )\n",
    "            if np.any(np.isnan(coupling)):\n",
    "                coupling = np.outer(a_np, b_np)\n",
    "            coupling /= coupling.sum(axis=1, keepdims=True)\n",
    "            return torch.tensor(coupling), True\n",
    "        except Exception as e:\n",
    "            print(f\"GW OT failed: {e}\")\n",
    "            coupling = np.outer(a_np, b_np)\n",
    "            coupling /= coupling.sum(axis=1, keepdims=True)\n",
    "            return torch.tensor(coupling), False\n",
    "\n",
    "    def find_correspondences(self, normalize=True, norm=\"l2\", bySample=True, k=20,\n",
    "                             mode=\"connectivity\", metric=\"correlation\", eps=0.1):\n",
    "        if normalize:\n",
    "            self._normalize(norm=norm, bySample=bySample)\n",
    "        self._init_marginals()\n",
    "        self.construct_graph(k=k, mode=mode, metric=metric)\n",
    "        self.init_graph_distances()\n",
    "        a, b = torch.Tensor(self.marginals[0]), torch.Tensor(self.marginals[1])\n",
    "        dx, dy = torch.Tensor(self.graphDists[0]), torch.Tensor(self.graphDists[1])\n",
    "        coupling, _ = self.direct_balanced_ot(a, dx, b, dy, eps=eps)\n",
    "        self.couplings.append(coupling)\n",
    "        return self.couplings\n",
    "\n",
    "    def barycentric_projection(self):\n",
    "        aligned = [self.data[0]]\n",
    "        coupling = self.couplings[0].numpy()\n",
    "        projected = np.matmul(coupling, self.data[1])\n",
    "        aligned.append(projected)\n",
    "        self.integrated_data = aligned\n",
    "        return aligned\n",
    "\n",
    "    def align(self, normalize=True, norm=\"l2\", bySample=True, k=20,\n",
    "              mode=\"connectivity\", metric=\"correlation\", eps=0.1):\n",
    "        self.find_correspondences(normalize=normalize, norm=norm, bySample=bySample,\n",
    "                                  k=k, mode=mode, metric=metric, eps=eps)\n",
    "        return self.barycentric_projection()\n",
    "\n",
    "\n",
    "# ========== MAIN ==========\n",
    "if __name__ == \"__main__\":\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    # 输入路径\n",
    "    X_path = \"/Users/apple/Desktop/KLin_Group/Project_2024/data/Morpho_data/dataset/Scala/exon_data_top2000.csv\"\n",
    "    Y_path = \"/Users/apple/Desktop/KLin_Group/Project_2024/data/Morpho_data/dataset/Scala/gw_dist.csv\"\n",
    "\n",
    "    # 输出路径\n",
    "    output_dir = Path(\"/Users/apple/Desktop/SCOT\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # ===== 正确读取数据 =====\n",
    "    # 让 pandas 自动识别第一行 header\n",
    "    # 第一列为 cell ID，当 index 用，数据部分是剩下的 2000 列\n",
    "    X_df = pd.read_csv(X_path, index_col=0)   # header=0 默认\n",
    "    Y_df = pd.read_csv(Y_path, index_col=0)   # 距离矩阵，同样第一列是 index\n",
    "\n",
    "    X = X_df.to_numpy()   # 期望 (645, 2000)\n",
    "    Y = Y_df.to_numpy()   # 期望 (645, 645)\n",
    "\n",
    "    min_n = min(X.shape[0], Y.shape[0])\n",
    "    X, Y = X[:min_n, :], Y[:min_n, :]\n",
    "\n",
    "    print(f\"Dataset shapes - X: {X.shape}, Y: {Y.shape}\")\n",
    "    assert X.shape[0] == Y.shape[0], \"X 和 Y 的行数不一致，请检查输入文件是否匹配\"\n",
    "\n",
    "    # 运行 SCOT 对齐\n",
    "    SCOT = SCOTv2([Y, X])   # 我们把 X 对齐到 Y\n",
    "    aligned = SCOT.align(normalize=True, k=50, eps=0.1)\n",
    "\n",
    "    # 生成 UMAP\n",
    "    print(\"Generating 2D UMAP embeddings...\")\n",
    "    reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "    umap_Y = reducer.fit_transform(aligned[0])\n",
    "    umap_X = reducer.fit_transform(aligned[1])\n",
    "\n",
    "    # 保存结果\n",
    "    pd.DataFrame(umap_Y, columns=[\"UMAP1\", \"UMAP2\"]).to_csv(output_dir / \"Y_umap.csv\", index=False)\n",
    "    pd.DataFrame(umap_X, columns=[\"UMAP1\", \"UMAP2\"]).to_csv(output_dir / \"X_umap.csv\", index=False)\n",
    "\n",
    "    print(\"✅ Saved:\")\n",
    "    print(f\"  {output_dir}/Y_umap.csv\")\n",
    "    print(f\"  {output_dir}/X_umap.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cajal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
